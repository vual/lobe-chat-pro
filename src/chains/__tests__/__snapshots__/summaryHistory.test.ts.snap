// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`chainSummaryHistory > should use the default model if the token count is below the GPT-3.5 limit 1`] = `
{
  "messages": [
    {
      "content": "You're an assistant who's good at extracting key takeaways from conversations and summarizing them. Please summarize according to the user's needs. The content you need to summarize is located in the <chat_history> </chat_history> group of xml tags. The summary needs to maintain the original language.",
      "role": "system",
    },
    {
      "content": "<chat_history>
<assistant>Hello, how can I assist you?</assistant>
<user>I need help with my account.</user>
</chat_history>

Please summarize the above conversation and retain key information. The summarized content will be used as context for subsequent prompts, and should be limited to 400 tokens.",
      "role": "user",
    },
  ],
}
`;
