{
  "01-ai/yi-1.5-34b-chat": {
    "description": "Zero One Everything, en son açık kaynak ince ayar modelidir, 34 milyar parametreye sahiptir, ince ayar çeşitli diyalog senaryolarını destekler, yüksek kaliteli eğitim verileri ile insan tercihleri ile hizalanmıştır."
  },
  "01-ai/yi-1.5-9b-chat": {
    "description": "Zero One Everything, en son açık kaynak ince ayar modelidir, 9 milyar parametreye sahiptir, ince ayar çeşitli diyalog senaryolarını destekler, yüksek kaliteli eğitim verileri ile insan tercihleri ile hizalanmıştır."
  },
  "360/deepseek-r1": {
    "description": "[360 Dağıtım Versiyonu] DeepSeek-R1, son eğitim aşamasında geniş çapta pekiştirme öğrenimi teknikleri kullanarak, çok az etiketli veri ile modelin çıkarım yeteneğini büyük ölçüde artırmıştır. Matematik, kod, doğal dil çıkarımı gibi görevlerde, OpenAI o1 resmi sürümü ile benzer performans sergilemektedir."
  },
  "360gpt-pro": {
    "description": "360GPT Pro, 360 AI model serisinin önemli bir üyesi olarak, çeşitli doğal dil uygulama senaryolarını karşılamak için etkili metin işleme yeteneği sunar, uzun metin anlama ve çoklu diyalog gibi işlevleri destekler."
  },
  "360gpt-pro-trans": {
    "description": "Çeviri için özel olarak tasarlanmış model, derinlemesine ince ayar yapılmış ve çeviri sonuçları lider konumdadır."
  },
  "360gpt-turbo": {
    "description": "360GPT Turbo, güçlü hesaplama ve diyalog yetenekleri sunar, mükemmel anlam anlama ve oluşturma verimliliğine sahiptir, işletmeler ve geliştiriciler için ideal bir akıllı asistan çözümüdür."
  },
  "360gpt-turbo-responsibility-8k": {
    "description": "360GPT Turbo Responsibility 8K, anlam güvenliği ve sorumluluk odaklılığı vurgular, içerik güvenliği konusunda yüksek gereksinimlere sahip uygulama senaryoları için tasarlanmıştır, kullanıcı deneyiminin doğruluğunu ve sağlamlığını garanti eder."
  },
  "360gpt2-o1": {
    "description": "360gpt2-o1, düşünce zincirini ağaç arama ile inşa eder ve yansıtma mekanizmasını entegre eder, pekiştirme öğrenimi ile eğitilir, model kendini yansıtma ve hata düzeltme yeteneğine sahiptir."
  },
  "360gpt2-pro": {
    "description": "360GPT2 Pro, 360 şirketi tarafından sunulan yüksek düzeyde doğal dil işleme modelidir, mükemmel metin oluşturma ve anlama yeteneğine sahiptir, özellikle oluşturma ve yaratma alanında olağanüstü performans gösterir, karmaşık dil dönüşümleri ve rol canlandırma görevlerini işleyebilir."
  },
  "360zhinao2-o1": {
    "description": "360zhinao2-o1, düşünce zincirini oluşturmak için ağaç araması kullanır ve yansıtma mekanizmasını entegre eder, pekiştirme öğrenimi ile eğitilir, model kendini yansıtma ve hata düzeltme yeteneğine sahiptir."
  },
  "4.0Ultra": {
    "description": "Spark4.0 Ultra, Xinghuo büyük model serisinin en güçlü versiyonudur, çevrimiçi arama bağlantısını yükseltirken, metin içeriğini anlama ve özetleme yeteneğini artırır. Ofis verimliliğini artırmak ve taleplere doğru yanıt vermek için kapsamlı bir çözüm sunar, sektördeki akıllı ürünlerin öncüsüdür."
  },
  "Baichuan2-Turbo": {
    "description": "Arama artırma teknolojisi kullanarak büyük model ile alan bilgisi ve tüm ağ bilgisi arasında kapsamlı bir bağlantı sağlar. PDF, Word gibi çeşitli belge yüklemelerini ve URL girişini destekler, bilgi edinimi zamanında ve kapsamlıdır, çıktı sonuçları doğru ve profesyoneldir."
  },
  "Baichuan3-Turbo": {
    "description": "Kurumsal yüksek frekanslı senaryolar için optimize edilmiş, etkisi büyük ölçüde artırılmış ve yüksek maliyet etkinliği sunmaktadır. Baichuan2 modeline kıyasla, içerik üretimi %20, bilgi sorgulama %17, rol oynama yeteneği %40 oranında artmıştır. Genel performansı GPT3.5'ten daha iyidir."
  },
  "Baichuan3-Turbo-128k": {
    "description": "128K ultra uzun bağlam penceresine sahip, kurumsal yüksek frekanslı senaryolar için optimize edilmiş, etkisi büyük ölçüde artırılmış ve yüksek maliyet etkinliği sunmaktadır. Baichuan2 modeline kıyasla, içerik üretimi %20, bilgi sorgulama %17, rol oynama yeteneği %40 oranında artmıştır. Genel performansı GPT3.5'ten daha iyidir."
  },
  "Baichuan4": {
    "description": "Model yetenekleri ülke içinde birinci sırada, bilgi ansiklopedisi, uzun metinler, yaratıcı üretim gibi Çince görevlerde yurtdışındaki önde gelen modelleri geride bırakmaktadır. Ayrıca, sektör lideri çok modlu yeteneklere sahiptir ve birçok yetkili değerlendirme kriterinde mükemmel performans göstermektedir."
  },
  "Baichuan4-Air": {
    "description": "Model yetenekleri ülke içinde birinci, bilgi ansiklopedisi, uzun metinler, yaratıcı üretim gibi Çince görevlerde uluslararası ana akım modelleri aşmaktadır. Ayrıca, sektörde lider çok modlu yeteneklere sahip olup, birçok yetkili değerlendirme ölçütünde mükemmel performans sergilemektedir."
  },
  "Baichuan4-Turbo": {
    "description": "Model yetenekleri ülke içinde birinci, bilgi ansiklopedisi, uzun metinler, yaratıcı üretim gibi Çince görevlerde uluslararası ana akım modelleri aşmaktadır. Ayrıca, sektörde lider çok modlu yeteneklere sahip olup, birçok yetkili değerlendirme ölçütünde mükemmel performans sergilemektedir."
  },
  "DeepSeek-R1": {
    "description": "En gelişmiş verimli LLM, akıl yürütme, matematik ve programlama konularında uzmandır."
  },
  "DeepSeek-R1-Distill-Llama-70B": {
    "description": "DeepSeek R1 - DeepSeek setindeki daha büyük ve daha akıllı model - Llama 70B mimarisine damıtılmıştır. Kıyaslamalar ve insan değerlendirmelerine dayanarak, bu model orijinal Llama 70B'den daha akıllıdır, özellikle matematik ve gerçeklik doğruluğu gerektiren görevlerde mükemmel performans göstermektedir."
  },
  "DeepSeek-R1-Distill-Qwen-1.5B": {
    "description": "Qwen2.5-Math-1.5B temel alınarak oluşturulmuş DeepSeek-R1 damıtma modeli, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler."
  },
  "DeepSeek-R1-Distill-Qwen-14B": {
    "description": "Qwen2.5-14B temel alınarak oluşturulmuş DeepSeek-R1 damıtma modeli, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler."
  },
  "DeepSeek-R1-Distill-Qwen-32B": {
    "description": "DeepSeek-R1 serisi, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler, OpenAI-o1-mini seviyesini aşar."
  },
  "DeepSeek-R1-Distill-Qwen-7B": {
    "description": "Qwen2.5-Math-7B temel alınarak oluşturulmuş DeepSeek-R1 damıtma modeli, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler."
  },
  "DeepSeek-V3": {
    "description": "DeepSeek-V3, Derin Arayış şirketi tarafından geliştirilen bir MoE modelidir. DeepSeek-V3, birçok değerlendirmede Qwen2.5-72B ve Llama-3.1-405B gibi diğer açık kaynak modelleri geride bırakmış ve performans açısından dünya çapında en iyi kapalı kaynak model olan GPT-4o ve Claude-3.5-Sonnet ile eşit seviyededir."
  },
  "Doubao-1.5-thinking-pro-m": {
    "description": "Doubao-1.5, yeni derin düşünme modeli (m versiyonu yerel çok modlu derin akıl yürütme yeteneği ile birlikte gelir) ve matematik, programlama, bilimsel akıl yürütme gibi uzmanlık alanlarında ve yaratıcı yazım gibi genel görevlerde mükemmel performans sergilemektedir. AIME 2024, Codeforces, GPQA gibi birçok otoriter benchmarkta endüstri birinciliğine ulaşmakta veya yaklaşmaktadır. 128k bağlam penceresi ve 16k çıktı destekler."
  },
  "Doubao-1.5-thinking-vision-pro": {
    "description": "Tamamen yeni bir görsel derin düşünme modeli, daha güçlü genel çok modlu anlama ve akıl yürütme yeteneğine sahiptir; 59 kamu değerlendirme ölçütünden 37'sinde SOTA performansı elde etmiştir."
  },
  "Doubao-1.5-vision-pro": {
    "description": "Doubao-1.5-vision-pro, yeni güncellenmiş çok modlu büyük modeldir, herhangi bir çözünürlük ve aşırı en-boy oranı görüntü tanıma desteği sunar, görsel çıkarım, belge tanıma, detay bilgisi anlama ve talimat takibi yeteneklerini artırır."
  },
  "Doubao-1.5-vision-pro-32k": {
    "description": "Doubao-1.5-vision-pro, tamamen yenilenen çok modlu büyük modeldir, herhangi bir çözünürlük ve aşırı en-boy oranına sahip görüntü tanıma desteği sunar, görsel akıl yürütme, belge tanıma, detay bilgisi anlama ve talimatları takip etme yeteneklerini artırır."
  },
  "Doubao-lite-128k": {
    "description": "Doubao-lite, mükemmel yanıt hızı ve daha iyi maliyet Performansı ile müşterilere farklı senaryolar için daha esnek seçenekler sunar. 128k bağlam penceresi çıkarım ve ince ayar destekler."
  },
  "Doubao-lite-32k": {
    "description": "Doubao-lite, mükemmel yanıt hızı ve daha iyi maliyet Performansı ile müşterilere farklı senaryolar için daha esnek seçenekler sunar. 32k bağlam penceresi çıkarım ve ince ayar destekler."
  },
  "Doubao-lite-4k": {
    "description": "Doubao-lite, mükemmel yanıt hızı ve daha iyi maliyet Performansı ile müşterilere farklı senaryolar için daha esnek seçenekler sunar. 4k bağlam penceresi çıkarım ve ince ayar destekler."
  },
  "Doubao-pro-128k": {
    "description": "En iyi performans gösteren ana model, karmaşık görevleri işlemek için uygundur; referanslı soru-cevap, özetleme, yaratım, metin sınıflandırma, rol yapma gibi senaryolar için iyi sonuçlar verir. 128k bağlam penceresi çıkarım ve ince ayar destekler."
  },
  "Doubao-pro-256k": {
    "description": "En iyi performansa sahip ana modeldir, karmaşık görevleri işlemek için uygundur, referans cevaplama, özetleme, yaratım, metin sınıflandırma, rol oynama gibi senaryolarda oldukça iyi sonuçlar vermektedir. 256k bağlam penceresi ile akıl yürütme ve ince ayar desteği sunmaktadır."
  },
  "Doubao-pro-32k": {
    "description": "En iyi performans gösteren ana model, karmaşık görevleri işlemek için uygundur; referanslı soru-cevap, özetleme, yaratım, metin sınıflandırma, rol yapma gibi senaryolar için iyi sonuçlar verir. 32k bağlam penceresi çıkarım ve ince ayar destekler."
  },
  "Doubao-pro-4k": {
    "description": "En iyi performans gösteren ana model, karmaşık görevleri işlemek için uygundur; referanslı soru-cevap, özetleme, yaratım, metin sınıflandırma, rol yapma gibi senaryolar için iyi sonuçlar verir. 4k bağlam penceresi çıkarım ve ince ayar destekler."
  },
  "Doubao-vision-lite-32k": {
    "description": "Doubao-vision modeli, Doubao tarafından sunulan çok modlu büyük modeldir, güçlü görüntü anlama ve akıl yürütme yeteneklerine sahip olup, kesin talimat anlama yeteneği sunmaktadır. Model, görüntü metin bilgisi çıkarımı ve görüntü tabanlı akıl yürütme görevlerinde güçlü bir performans sergilemekte, daha karmaşık ve daha geniş görsel soru-cevap görevlerine uygulanabilmektedir."
  },
  "Doubao-vision-pro-32k": {
    "description": "Doubao-vision modeli, Doubao tarafından sunulan çok modlu büyük modeldir, güçlü görüntü anlama ve akıl yürütme yeteneklerine sahip olup, kesin talimat anlama yeteneği sunmaktadır. Model, görüntü metin bilgisi çıkarımı ve görüntü tabanlı akıl yürütme görevlerinde güçlü bir performans sergilemekte, daha karmaşık ve daha geniş görsel soru-cevap görevlerine uygulanabilmektedir."
  },
  "ERNIE-3.5-128K": {
    "description": "Baidu'nun kendi geliştirdiği, büyük ölçekli bir dil modeli olan ERNIE-3.5, geniş bir Çin ve İngilizce veri kümesini kapsar. Güçlü genel yeteneklere sahip olup, çoğu diyalog, soru-cevap, yaratıcı içerik üretimi ve eklenti uygulama senaryolarını karşılayabilir; ayrıca, Baidu arama eklentisi ile otomatik entegrasyonu destekleyerek, soru-cevap bilgilerinin güncelliğini sağlar."
  },
  "ERNIE-3.5-8K": {
    "description": "Baidu'nun kendi geliştirdiği, büyük ölçekli bir dil modeli olan ERNIE-3.5, geniş bir Çin ve İngilizce veri kümesini kapsar. Güçlü genel yeteneklere sahip olup, çoğu diyalog, soru-cevap, yaratıcı içerik üretimi ve eklenti uygulama senaryolarını karşılayabilir; ayrıca, Baidu arama eklentisi ile otomatik entegrasyonu destekleyerek, soru-cevap bilgilerinin güncelliğini sağlar."
  },
  "ERNIE-3.5-8K-Preview": {
    "description": "Baidu'nun kendi geliştirdiği, büyük ölçekli bir dil modeli olan ERNIE-3.5, geniş bir Çin ve İngilizce veri kümesini kapsar. Güçlü genel yeteneklere sahip olup, çoğu diyalog, soru-cevap, yaratıcı içerik üretimi ve eklenti uygulama senaryolarını karşılayabilir; ayrıca, Baidu arama eklentisi ile otomatik entegrasyonu destekleyerek, soru-cevap bilgilerinin güncelliğini sağlar."
  },
  "ERNIE-4.0-8K-Latest": {
    "description": "Baidu'nun kendi geliştirdiği amiral gemisi ultra büyük ölçekli dil modeli, ERNIE 3.5'e kıyasla model yeteneklerinde kapsamlı bir yükseltme gerçekleştirmiştir, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgilerini güncel tutar."
  },
  "ERNIE-4.0-8K-Preview": {
    "description": "Baidu'nun kendi geliştirdiği amiral gemisi ultra büyük ölçekli dil modeli, ERNIE 3.5'e kıyasla model yeteneklerinde kapsamlı bir yükseltme gerçekleştirmiştir, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgilerini güncel tutar."
  },
  "ERNIE-4.0-Turbo-8K-Latest": {
    "description": "Baidu tarafından geliştirilen, geniş ölçekli büyük dil modeli, genel performansı mükemmeldir ve her alanda karmaşık görev sahneleri için geniş bir şekilde kullanılabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgi güncellemelerinin zamanlamasını güvence altına alır. ERNIE 4.0'a kıyasla, performans olarak daha üstündür."
  },
  "ERNIE-4.0-Turbo-8K-Preview": {
    "description": "Baidu'nun kendi geliştirdiği amiral gemisi ultra büyük ölçekli dil modeli, genel performansı mükemmel olup, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgilerini güncel tutar. ERNIE 4.0'a kıyasla performans açısından daha üstündür."
  },
  "ERNIE-Character-8K": {
    "description": "Baidu'nun kendi geliştirdiği dikey senaryo büyük dil modeli, oyun NPC'leri, müşteri hizmetleri diyalogları, diyalog karakter rolü gibi uygulama senaryoları için uygundur, karakter tarzı daha belirgin ve tutarlıdır, talimatları takip etme yeteneği daha güçlüdür ve çıkarım performansı daha iyidir."
  },
  "ERNIE-Lite-Pro-128K": {
    "description": "Baidu'nun kendi geliştirdiği hafif büyük dil modeli, mükemmel model performansı ve çıkarım yeteneklerini dengeler, ERNIE Lite'dan daha iyi sonuçlar verir, düşük hesaplama gücüne sahip AI hızlandırıcı kartları için uygundur."
  },
  "ERNIE-Speed-128K": {
    "description": "Baidu'nun 2024 yılında piyasaya sürdüğü kendi geliştirdiği yüksek performanslı büyük dil modeli, genel yetenekleri mükemmel olup, belirli senaryo sorunlarını daha iyi işlemek için temel model olarak ince ayar yapmak için uygundur ve mükemmel çıkarım performansına sahiptir."
  },
  "ERNIE-Speed-Pro-128K": {
    "description": "Baidu'nun 2024 yılında piyasaya sürdüğü kendi geliştirdiği yüksek performanslı büyük dil modeli, genel yetenekleri mükemmel olup, ERNIE Speed'den daha iyi sonuçlar verir, belirli senaryo sorunlarını daha iyi işlemek için temel model olarak ince ayar yapmak için uygundur ve mükemmel çıkarım performansına sahiptir."
  },
  "Gryphe/MythoMax-L2-13b": {
    "description": "MythoMax-L2 (13B), çok alanlı uygulamalar ve karmaşık görevler için uygun yenilikçi bir modeldir."
  },
  "InternVL2-8B": {
    "description": "InternVL2-8B, güçlü bir görsel dil modelidir. Görüntü ve metinlerin çok modlu işlenmesini destekler, görüntü içeriğini hassas bir şekilde tanıyabilir ve ilgili açıklamalar veya yanıtlar üretebilir."
  },
  "InternVL2.5-26B": {
    "description": "InternVL2.5-26B, güçlü bir görsel dil modelidir. Görüntü ve metinlerin çok modlu işlenmesini destekler, görüntü içeriğini hassas bir şekilde tanıyabilir ve ilgili açıklamalar veya yanıtlar üretebilir."
  },
  "Llama-3.2-11B-Vision-Instruct": {
    "description": "Yüksek çözünürlüklü görüntülerde mükemmel görüntü akıl yürütme yeteneği, görsel anlama uygulamaları için uygundur."
  },
  "Llama-3.2-90B-Vision-Instruct\t": {
    "description": "Görsel anlama ajan uygulamaları için gelişmiş görüntü akıl yürütme yeteneği."
  },
  "Meta-Llama-3.1-405B-Instruct": {
    "description": "Llama 3.1 talimat ayarlı metin modeli, çok dilli diyalog kullanım durumları için optimize edilmiştir ve birçok mevcut açık kaynak ve kapalı sohbet modelinde yaygın endüstri kıyaslamalarında mükemmel performans göstermektedir."
  },
  "Meta-Llama-3.1-70B-Instruct": {
    "description": "Llama 3.1 talimat ayarlı metin modeli, çok dilli diyalog kullanım durumları için optimize edilmiştir ve birçok mevcut açık kaynak ve kapalı sohbet modelinde yaygın endüstri kıyaslamalarında mükemmel performans göstermektedir."
  },
  "Meta-Llama-3.1-8B-Instruct": {
    "description": "Llama 3.1 talimat ayarlı metin modeli, çok dilli diyalog kullanım durumları için optimize edilmiştir ve birçok mevcut açık kaynak ve kapalı sohbet modelinde yaygın endüstri kıyaslamalarında mükemmel performans göstermektedir."
  },
  "Meta-Llama-3.2-1B-Instruct": {
    "description": "Gelişmiş, en son teknolojiye sahip küçük dil modeli, dil anlama, mükemmel akıl yürütme yeteneği ve metin oluşturma yeteneğine sahiptir."
  },
  "Meta-Llama-3.2-3B-Instruct": {
    "description": "Gelişmiş, en son teknolojiye sahip küçük dil modeli, dil anlama, mükemmel akıl yürütme yeteneği ve metin oluşturma yeteneğine sahiptir."
  },
  "Meta-Llama-3.3-70B-Instruct": {
    "description": "Llama 3.3, Llama serisinin en gelişmiş çok dilli açık kaynak büyük dil modelidir ve 405B modelinin performansını çok düşük maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve yararlılığını ve güvenliğini artırmak için denetimli ince ayar (SFT) ve insan geri bildirimi ile güçlendirilmiş öğrenme (RLHF) kullanılmıştır. Talimat ayarlı versiyonu çok dilli diyaloglar için optimize edilmiştir ve birçok endüstri kıyaslamasında birçok açık kaynak ve kapalı sohbet modelinden daha iyi performans göstermektedir. Bilgi kesim tarihi 2023 yılı Aralık ayıdır."
  },
  "MiniMax-M1": {
    "description": "Tamamen kendi geliştirdiğimiz yeni çıkarım modeli. Küresel lider: 80K düşünce zinciri x 1M giriş, performansı uluslararası üst düzey modellerle eşdeğer."
  },
  "MiniMax-Text-01": {
    "description": "MiniMax-01 serisi modellerinde cesur yenilikler yaptık: ilk kez büyük ölçekli lineer dikkat mekanizmasını gerçekleştirdik, geleneksel Transformer mimarisi artık tek seçenek değil. Bu modelin parametre sayısı 456 milyara kadar çıkmakta, tek bir aktivasyonda 45.9 milyar. Modelin genel performansı, yurtdışındaki en iyi modellerle karşılaştırılabilirken, dünya genelinde 4 milyon token uzunluğundaki bağlamı verimli bir şekilde işleyebilir, bu da GPT-4o'nun 32 katı, Claude-3.5-Sonnet'in 20 katıdır."
  },
  "MiniMaxAI/MiniMax-M1-80k": {
    "description": "MiniMax-M1, açık kaynak ağırlıklı büyük ölçekli karma dikkat çıkarım modeli olup, 456 milyar parametreye sahiptir ve her Token yaklaşık 45.9 milyar parametreyi aktive eder. Model, doğal olarak 1 milyon Token uzunluğunda bağlamı destekler ve şimşek dikkat mekanizması sayesinde 100 bin Token üretim görevlerinde DeepSeek R1'e kıyasla %75 daha az kayan nokta işlemi kullanır. Ayrıca, MiniMax-M1 MoE (karışık uzman) mimarisini, CISPO algoritması ve karma dikkat tasarımı ile verimli pekiştirmeli öğrenme eğitimiyle birleştirerek uzun giriş çıkarımı ve gerçek yazılım mühendisliği senaryolarında sektör lideri performans sunar."
  },
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B), karmaşık hesaplamalar için yüksek hassasiyetli bir talimat modelidir."
  },
  "Phi-3-medium-128k-instruct": {
    "description": "Aynı Phi-3-medium modeli, ancak RAG veya az sayıda örnek isteme için daha büyük bir bağlam boyutuna sahiptir."
  },
  "Phi-3-medium-4k-instruct": {
    "description": "14B parametreli bir model, Phi-3-mini'den daha iyi kalite sunar, yüksek kaliteli, akıl yürütme yoğun veriye odaklanır."
  },
  "Phi-3-mini-128k-instruct": {
    "description": "Aynı Phi-3-mini modeli, ancak RAG veya az sayıda örnek isteme için daha büyük bir bağlam boyutuna sahiptir."
  },
  "Phi-3-mini-4k-instruct": {
    "description": "Phi-3 ailesinin en küçük üyesi. Hem kalite hem de düşük gecikme için optimize edilmiştir."
  },
  "Phi-3-small-128k-instruct": {
    "description": "Aynı Phi-3-small modeli, ancak RAG veya az sayıda örnek isteme için daha büyük bir bağlam boyutuna sahiptir."
  },
  "Phi-3-small-8k-instruct": {
    "description": "7B parametreli bir model, Phi-3-mini'den daha iyi kalite sunar, yüksek kaliteli, akıl yürütme yoğun veriye odaklanır."
  },
  "Phi-3.5-mini-instruct": {
    "description": "Phi-3-mini modelinin güncellenmiş versiyonu."
  },
  "Phi-3.5-vision-instrust": {
    "description": "Phi-3-görsel modelinin güncellenmiş versiyonu."
  },
  "Pro/Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-7B-Instruct, Qwen2 serisindeki talimat ince ayar büyük dil modelidir ve parametre ölçeği 7B'dir. Bu model, Transformer mimarisi temelinde, SwiGLU aktivasyon fonksiyonu, dikkat QKV önyargısı ve grup sorgu dikkati gibi teknikler kullanmaktadır. Büyük ölçekli girişleri işleyebilme yeteneğine sahiptir. Bu model, dil anlama, üretim, çok dilli yetenek, kodlama, matematik ve akıl yürütme gibi birçok standart testte mükemmel performans sergilemekte ve çoğu açık kaynak modelini geride bırakmakta, bazı görevlerde özel modellere karşı rekabet edebilir. Qwen2-7B-Instruct, birçok değerlendirmede Qwen1.5-7B-Chat'ten daha iyi performans göstermekte ve belirgin bir performans artışı sergilemektedir."
  },
  "Pro/Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct, Alibaba Cloud tarafından yayınlanan en son büyük dil modeli serilerinden biridir. Bu 7B modeli, kodlama ve matematik gibi alanlarda önemli ölçüde geliştirilmiş yeteneklere sahiptir. Model ayrıca, Çince, İngilizce gibi 29'dan fazla dili kapsayan çok dilli destek sunmaktadır. Model, talimat takibi, yapılandırılmış verileri anlama ve yapılandırılmış çıktı (özellikle JSON) üretme konularında önemli iyileştirmeler göstermektedir."
  },
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-Instruct, Alibaba Cloud tarafından yayınlanan kod odaklı büyük dil modeli serisinin en son versiyonudur. Bu model, Qwen2.5 temelinde, 5.5 trilyon token ile eğitilerek kod üretimi, akıl yürütme ve düzeltme yeteneklerini önemli ölçüde artırmıştır. Hem kodlama yeteneklerini geliştirmiş hem de matematik ve genel yetenek avantajlarını korumuştur. Model, kod akıllı ajanları gibi pratik uygulamalar için daha kapsamlı bir temel sunmaktadır."
  },
  "Pro/Qwen/Qwen2.5-VL-7B-Instruct": {
    "description": "Qwen2.5-VL, Qwen serisinin yeni üyesidir ve güçlü görsel anlama yeteneğine sahiptir. Görsellerdeki metinleri, grafikleri ve düzenleri analiz edebilir, uzun videoları anlayabilir ve olayları yakalayabilir. Akıl yürütme yapabilir, araçları kullanabilir, çoklu format nesne konumlandırmayı destekler ve yapılandırılmış çıktılar üretebilir. Video anlama için dinamik çözünürlük ve kare hızı eğitimini optimize etmiş ve görsel kodlayıcı verimliliğini artırmıştır."
  },
  "Pro/THUDM/glm-4-9b-chat": {
    "description": "GLM-4-9B-Chat, Zhipu AI tarafından sunulan GLM-4 serisi önceden eğitilmiş modellerin açık kaynak versiyonudur. Bu model, anlam, matematik, akıl yürütme, kod ve bilgi gibi birçok alanda mükemmel performans sergilemektedir. Çoklu diyalogları desteklemenin yanı sıra, GLM-4-9B-Chat, web tarayıcı, kod yürütme, özelleştirilmiş araç çağrısı (Function Call) ve uzun metin akıl yürütme gibi gelişmiş özelliklere de sahiptir. Model, Çince, İngilizce, Japonca, Korece ve Almanca gibi 26 dili desteklemektedir. GLM-4-9B-Chat, AlignBench-v2, MT-Bench, MMLU ve C-Eval gibi birçok standart testte mükemmel performans sergilemiştir. Bu model, maksimum 128K bağlam uzunluğunu desteklemekte olup, akademik araştırmalar ve ticari uygulamalar için uygundur."
  },
  "Pro/deepseek-ai/DeepSeek-R1": {
    "description": "DeepSeek-R1, modeldeki tekrarlılık ve okunabilirlik sorunlarını çözen bir güçlendirilmiş öğrenme (RL) destekli çıkarım modelidir. RL'den önce, DeepSeek-R1 soğuk başlangıç verileri tanıtarak çıkarım performansını daha da optimize etmiştir. Matematik, kod ve çıkarım görevlerinde OpenAI-o1 ile benzer performans göstermektedir ve özenle tasarlanmış eğitim yöntemleri ile genel etkisini artırmıştır."
  },
  "Pro/deepseek-ai/DeepSeek-R1-0120": {
    "description": "DeepSeek-R1, pekiştirmeli öğrenme (RL) destekli bir akıl yürütme modelidir ve modeldeki tekrar ve okunabilirlik sorunlarını çözer. RL öncesinde soğuk başlangıç verisi kullanarak akıl yürütme performansını daha da optimize etmiştir. Matematik, kodlama ve akıl yürütme görevlerinde OpenAI-o1 ile benzer performans gösterir ve özenle tasarlanmış eğitim yöntemleriyle genel performansı artırır."
  },
  "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
    "description": "DeepSeek-R1-Distill-Qwen-7B, Qwen2.5-Math-7B modelinden bilgi damıtma yöntemiyle elde edilmiş bir modeldir. Bu model, DeepSeek-R1 tarafından oluşturulan 800 bin seçkin örnekle ince ayar yapılarak geliştirilmiş olup, üstün akıl yürütme yeteneği sergilemektedir. Çeşitli kıyaslama testlerinde başarılı performans gösteren model, MATH-500'de %92,8 doğruluk, AIME 2024'te %55,5 geçme oranı ve CodeForces'ta 1189 puan alarak, 7B ölçeğindeki bir model için güçlü matematik ve programlama yeteneklerini ortaya koymuştur."
  },
  "Pro/deepseek-ai/DeepSeek-V3": {
    "description": "DeepSeek-V3, 6710 milyar parametreye sahip bir karma uzman (MoE) dil modelidir ve çok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarisini kullanarak, yardımcı kayıplar olmadan yük dengeleme stratejileri ile çıkarım ve eğitim verimliliğini optimize etmektedir. 14.8 trilyon yüksek kaliteli token üzerinde önceden eğitilmiş ve denetimli ince ayar ve güçlendirilmiş öğrenme ile, DeepSeek-V3 performans açısından diğer açık kaynak modelleri geride bırakmakta ve lider kapalı kaynak modellere yaklaşmaktadır."
  },
  "Pro/deepseek-ai/DeepSeek-V3-1226": {
    "description": "DeepSeek-V3, 6710 milyar parametreye sahip bir karma uzman (MoE) dil modelidir. Çok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarisini kullanarak, yardımcı kayıpsız yük dengeleme stratejileri ile optimizasyon yapar ve çıkarım ile eğitim verimliliğini artırır. 14.8 trilyon yüksek kaliteli token üzerinde önceden eğitilmiş ve denetimli ince ayar ile pekiştirmeli öğrenme ile geliştirilmiştir; DeepSeek-V3, performans açısından diğer açık kaynaklı modellere göre üstünlük sağlar ve lider kapalı kaynak modellere yakın bir performans sergiler."
  },
  "QwQ-32B-Preview": {
    "description": "QwQ-32B-Preview, karmaşık diyalog oluşturma ve bağlam anlama görevlerini etkili bir şekilde işleyebilen yenilikçi bir doğal dil işleme modelidir."
  },
  "Qwen/QVQ-72B-Preview": {
    "description": "QVQ-72B-Preview, Qwen ekibi tarafından geliştirilen ve görsel çıkarım yeteneklerine odaklanan bir araştırma modelidir. Karmaşık sahne anlayışı ve görsel ile ilgili matematiksel sorunları çözme konusundaki benzersiz avantajları ile dikkat çekmektedir."
  },
  "Qwen/QwQ-32B": {
    "description": "QwQ, Qwen serisinin çıkarım modelidir. Geleneksel talimat ayarlama modellerine kıyasla, QwQ düşünme ve çıkarım yeteneğine sahiptir ve özellikle zor problemleri çözme konusunda önemli ölçüde artırılmış performans sergileyebilir. QwQ-32B, orta ölçekli bir çıkarım modelidir ve en son çıkarım modelleri (örneğin, DeepSeek-R1, o1-mini) ile karşılaştırıldığında rekabetçi bir performans elde edebilir. Bu model, RoPE, SwiGLU, RMSNorm ve Attention QKV bias gibi teknikleri kullanmakta olup, 64 katmanlı bir ağ yapısına ve 40 Q dikkat başlığına (GQA mimarisinde KV 8'dir) sahiptir."
  },
  "Qwen/QwQ-32B-Preview": {
    "description": "QwQ-32B-Preview, Qwen'in en son deneysel araştırma modelidir ve AI akıl yürütme yeteneklerini artırmaya odaklanmaktadır. Dil karışımı, özyinelemeli akıl yürütme gibi karmaşık mekanizmaları keşfederek, güçlü akıl yürütme analizi, matematik ve programlama yetenekleri gibi ana avantajlar sunmaktadır. Bununla birlikte, dil geçiş sorunları, akıl yürütme döngüleri, güvenlik endişeleri ve diğer yetenek farklılıkları gibi zorluklar da bulunmaktadır."
  },
  "Qwen/Qwen2-72B-Instruct": {
    "description": "Qwen2, çok çeşitli talimat türlerini destekleyen gelişmiş bir genel dil modelidir."
  },
  "Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-72B-Instruct, Qwen2 serisindeki talimat ince ayar büyük dil modelidir ve parametre ölçeği 72B'dir. Bu model, Transformer mimarisi temelinde, SwiGLU aktivasyon fonksiyonu, dikkat QKV önyargısı ve grup sorgu dikkati gibi teknikler kullanmaktadır. Büyük ölçekli girişleri işleyebilme yeteneğine sahiptir. Bu model, dil anlama, üretim, çok dilli yetenek, kodlama, matematik ve akıl yürütme gibi birçok standart testte mükemmel performans sergilemekte ve çoğu açık kaynak modelini geride bırakmakta, bazı görevlerde özel modellere karşı rekabet edebilir."
  },
  "Qwen/Qwen2-VL-72B-Instruct": {
    "description": "Qwen2-VL, Qwen-VL modelinin en son yineleme versiyonudur ve görsel anlama kıyaslama testlerinde en gelişmiş performansı sergilemiştir."
  },
  "Qwen/Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5, talimat tabanlı görevlerin işlenmesini optimize etmek için tasarlanmış yeni bir büyük dil modeli serisidir."
  },
  "Qwen/Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5, talimat tabanlı görevlerin işlenmesini optimize etmek için tasarlanmış yeni bir büyük dil modeli serisidir."
  },
  "Qwen/Qwen2.5-72B-Instruct": {
    "description": "Alibaba Cloud Tongyi Qianwen ekibi tarafından geliştirilen büyük bir dil modeli"
  },
  "Qwen/Qwen2.5-72B-Instruct-128K": {
    "description": "Qwen2.5, daha güçlü anlama ve üretim yeteneği ile yeni bir büyük dil modeli serisidir."
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "description": "Qwen2.5, komut tabanlı görevlerin işlenmesini optimize etmek için tasarlanmış yeni bir büyük dil modeli serisidir."
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5, talimat tabanlı görevlerin işlenmesini optimize etmek için tasarlanmış yeni bir büyük dil modeli serisidir."
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "description": "Qwen2.5, komut tabanlı görevlerin işlenmesini optimize etmek için tasarlanmış yeni bir büyük dil modeli serisidir."
  },
  "Qwen/Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder, kod yazımına odaklanmaktadır."
  },
  "Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-Instruct, Alibaba Cloud tarafından yayınlanan kod odaklı büyük dil modeli serisinin en son versiyonudur. Bu model, Qwen2.5 temelinde, 5.5 trilyon token ile eğitilerek kod üretimi, akıl yürütme ve düzeltme yeteneklerini önemli ölçüde artırmıştır. Hem kodlama yeteneklerini geliştirmiş hem de matematik ve genel yetenek avantajlarını korumuştur. Model, kod akıllı ajanları gibi pratik uygulamalar için daha kapsamlı bir temel sunmaktadır."
  },
  "Qwen/Qwen2.5-VL-32B-Instruct": {
    "description": "Qwen2.5-VL-32B-Instruct, Tongyi Qianwen ekibi tarafından geliştirilen çok modelli bir büyük modeldir ve Qwen2.5-VL serisinin bir parçasıdır. Bu model yalnızca yaygın nesneleri tanımakla kalmaz, aynı zamanda görüntülerdeki metinleri, tabloları, simgeleri, grafikleri ve düzenleri analiz edebilir. Görsel bir akıllı ajan olarak çalışabilir, araçları dinamik olarak yönetebilir ve bilgisayar ile telefon kullanma yeteneğine sahiptir. Ayrıca, bu model görüntülerdeki nesneleri hassas bir şekilde konumlandırabilir ve fatura, tablo gibi belgeler için yapılandırılmış çıktılar üretebilir. Önceki model Qwen2-VL'ye kıyasla, bu sürüm matematik ve problem çözme yeteneklerinde pekiştirmeli öğrenme ile daha da geliştirilmiştir ve yanıt tarzı insan tercihlerine daha uygun hale getirilmiştir."
  },
  "Qwen/Qwen2.5-VL-72B-Instruct": {
    "description": "Qwen2.5-VL, Qwen2.5 serisindeki görsel-dil modelidir. Bu model birçok alanda önemli gelişmeler sunmaktadır: Gelişmiş görsel anlama yeteneğiyle yaygın nesneleri tanıyabilir, metinleri, grafikleri ve düzenleri analiz edebilir; görsel bir ajan olarak akıl yürütebilir ve araç kullanımını dinamik olarak yönlendirebilir; 1 saati aşan uzun videoları anlayabilir ve önemli olayları yakalayabilir; görüntülerdeki nesneleri sınırlayıcı kutular veya noktalar oluşturarak hassas bir şekilde konumlandırabilir; yapılandırılmış çıktılar üretebilir, özellikle fatura, tablo gibi taranmış veriler için uygundur."
  },
  "Qwen/Qwen3-14B": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte önemli ölçüde geliştirilmiş yeni nesil Tongyi Qianwen büyük modelidir ve düşünme modu geçişini destekler."
  },
  "Qwen/Qwen3-235B-A22B": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte önemli ölçüde geliştirilmiş yeni nesil Tongyi Qianwen büyük modelidir ve düşünme modu geçişini destekler."
  },
  "Qwen/Qwen3-30B-A3B": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte önemli ölçüde geliştirilmiş yeni nesil Tongyi Qianwen büyük modelidir ve düşünme modu geçişini destekler."
  },
  "Qwen/Qwen3-32B": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte önemli ölçüde geliştirilmiş yeni nesil Tongyi Qianwen büyük modelidir ve düşünme modu geçişini destekler."
  },
  "Qwen/Qwen3-8B": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte önemli ölçüde geliştirilmiş yeni nesil Tongyi Qianwen büyük modelidir ve düşünme modu geçişini destekler."
  },
  "Qwen2-72B-Instruct": {
    "description": "Qwen2, Qwen modelinin en yeni serisidir ve 128k bağlamı destekler. Mevcut en iyi açık kaynak modellerle karşılaştırıldığında, Qwen2-72B doğal dil anlama, bilgi, kod, matematik ve çok dilli yetenekler açısından mevcut lider modelleri önemli ölçüde aşmaktadır."
  },
  "Qwen2-7B-Instruct": {
    "description": "Qwen2, Qwen modelinin en yeni serisidir ve eşit ölçekli en iyi açık kaynak modelleri hatta daha büyük ölçekli modelleri aşabilmektedir. Qwen2 7B, birçok değerlendirmede belirgin bir avantaj elde etmiş, özellikle kod ve Çince anlama konusunda."
  },
  "Qwen2-VL-72B": {
    "description": "Qwen2-VL-72B, görüntü ve metin için çok modlu işleme desteği sunan güçlü bir görsel dil modelidir, görüntü içeriğini hassas bir şekilde tanıyabilir ve ilgili açıklamalar veya yanıtlar üretebilir."
  },
  "Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5-14B-Instruct, 14 milyar parametreye sahip büyük bir dil modelidir. Performansı mükemmel olup, Çince ve çok dilli senaryoları optimize eder, akıllı soru-cevap, içerik üretimi gibi uygulamaları destekler."
  },
  "Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5-32B-Instruct, 32 milyar parametreye sahip büyük bir dil modelidir. Performans dengeli olup, Çince ve çok dilli senaryoları optimize eder, akıllı soru-cevap, içerik üretimi gibi uygulamaları destekler."
  },
  "Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-Instruct, 16k bağlamı destekler ve 8K'dan uzun metinler üretebilir. Fonksiyon çağrısı ile dış sistemlerle sorunsuz etkileşim sağlar, esneklik ve ölçeklenebilirliği büyük ölçüde artırır. Modelin bilgisi belirgin şekilde artmış ve kodlama ile matematik yetenekleri büyük ölçüde geliştirilmiştir, 29'dan fazla dil desteği sunmaktadır."
  },
  "Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instruct, 7 milyar parametreye sahip büyük bir dil modelidir. Fonksiyon çağrısı ile dış sistemlerle sorunsuz etkileşim destekler, esneklik ve ölçeklenebilirliği büyük ölçüde artırır. Çince ve çok dilli senaryoları optimize eder, akıllı soru-cevap, içerik üretimi gibi uygulamaları destekler."
  },
  "Qwen2.5-Coder-14B-Instruct": {
    "description": "Qwen2.5-Coder-14B-Instruct, büyük ölçekli önceden eğitilmiş bir programlama talimat modelidir, güçlü kod anlama ve üretme yeteneğine sahiptir, çeşitli programlama görevlerini verimli bir şekilde işleyebilir, özellikle akıllı kod yazma, otomatik betik oluşturma ve programlama sorunlarına yanıt verme için uygundur."
  },
  "Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder-32B-Instruct, kod üretimi, kod anlama ve verimli geliştirme senaryoları için tasarlanmış büyük bir dil modelidir. Sektördeki en ileri 32B parametre ölçeğini kullanarak çeşitli programlama ihtiyaçlarını karşılayabilir."
  },
  "SenseChat": {
    "description": "Temel sürüm model (V4), 4K bağlam uzunluğu ile genel yetenekleri güçlüdür."
  },
  "SenseChat-128K": {
    "description": "Temel sürüm model (V4), 128K bağlam uzunluğu ile uzun metin anlama ve üretme görevlerinde mükemmel performans sergilemektedir."
  },
  "SenseChat-32K": {
    "description": "Temel sürüm model (V4), 32K bağlam uzunluğu ile çeşitli senaryolarda esnek bir şekilde uygulanabilir."
  },
  "SenseChat-5": {
    "description": "En son sürüm model (V5.5), 128K bağlam uzunluğu, matematiksel akıl yürütme, İngilizce diyalog, talimat takibi ve uzun metin anlama gibi alanlarda önemli gelişmeler göstermektedir ve GPT-4o ile karşılaştırılabilir."
  },
  "SenseChat-5-1202": {
    "description": "V5.5 tabanlı en son sürüm olup, önceki sürüme kıyasla Çince ve İngilizce temel yetenekler, sohbet, fen bilimleri bilgisi, sosyal bilimler bilgisi, yazım, matematiksel mantık ve kelime sayısı kontrolü gibi birçok alanda belirgin gelişmeler sunar."
  },
  "SenseChat-5-Cantonese": {
    "description": "32K bağlam uzunluğu ile, Kantonca diyalog anlama konusunda GPT-4'ü aşmakta, bilgi, akıl yürütme, matematik ve kod yazma gibi birçok alanda GPT-4 Turbo ile rekabet edebilmektedir."
  },
  "SenseChat-5-beta": {
    "description": "Bazı performansları SenseCat-5-1202'den daha iyidir."
  },
  "SenseChat-Character": {
    "description": "Standart sürüm model, 8K bağlam uzunluğu ile yüksek yanıt hızı sunmaktadır."
  },
  "SenseChat-Character-Pro": {
    "description": "Gelişmiş sürüm model, 32K bağlam uzunluğu ile yetenekleri tamamen geliştirilmiş, Çince/İngilizce diyalogları desteklemektedir."
  },
  "SenseChat-Turbo": {
    "description": "Hızlı soru-cevap ve model ince ayar senaryoları için uygundur."
  },
  "SenseChat-Turbo-1202": {
    "description": "En son hafif versiyon modelidir, tam modelin %90'ından fazla yetenek sunar ve çıkarım maliyetini önemli ölçüde azaltır."
  },
  "SenseChat-Vision": {
    "description": "En son versiyon modeli (V5.5), çoklu görsel girişi destekler, modelin temel yetenek optimizasyonunu tamamen gerçekleştirir; nesne özellik tanıma, mekansal ilişkiler, hareket olayları tanıma, sahne anlama, duygu tanıma, mantıksal bilgi çıkarımı ve metin anlama üretimi gibi alanlarda önemli gelişmeler sağlamıştır."
  },
  "SenseNova-V6-Pro": {
    "description": "Görüntü, metin ve video yeteneklerinin yerel birliğini sağlar, geleneksel çok modlu ayrım sınırlamalarını aşar, OpenCompass ve SuperCLUE değerlendirmelerinde çift şampiyonluk kazanmıştır."
  },
  "SenseNova-V6-Reasoner": {
    "description": "Görsel ve dil derin akıl yürütmesini bir araya getirerek, yavaş düşünme ve derin akıl yürütmeyi gerçekleştirir, tam bir düşünce zinciri sürecini sunar."
  },
  "SenseNova-V6-Turbo": {
    "description": "Görüntü, metin ve video yeteneklerinin yerel birliğini sağlar, geleneksel çok modlu ayrım sınırlamalarını aşar, çoklu temel yetenekler, dil temel yetenekleri gibi ana boyutlarda kapsamlı bir şekilde önde gelir, hem edebi hem de mantıksal olarak dengelidir ve birçok değerlendirmede ulusal ve uluslararası birinci lig seviyesinde yer almıştır."
  },
  "Skylark2-lite-8k": {
    "description": "Skylark'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-lite modeli yüksek yanıt hızı ile donatılmıştır; gerçek zamanlı talep gereksinimleri yüksek, maliyet duyarlı ve model hassasiyetine daha az ihtiyaç duyulan senaryolar için uygundur; bağlam pencere uzunluğu 8k'dır."
  },
  "Skylark2-pro-32k": {
    "description": "Skylark'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro sürümüyle yüksek model hassasiyetine sahiptir; profesyonel alan metin üretimi, roman yazımı, yüksek kaliteli çeviri gibi daha karmaşık metin üretim sahneleri için uygundur ve bağlam pencere uzunluğu 32k'dır."
  },
  "Skylark2-pro-4k": {
    "description": "Skylark'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro modeli yüksek model hassasiyetine sahiptir; profesyonel alan metin üretimi, roman yazımı, yüksek kaliteli çeviri gibi daha karmaşık metin üretim sahneleri için uygundur ve bağlam pencere uzunluğu 4k'dır."
  },
  "Skylark2-pro-character-4k": {
    "description": "Skylark'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro-character modeli, mükemmel rol yapma ve sohbet yeteneklerine sahiptir; kullanıcıdan gelen istem taleplerine göre farklı roller üstlenme kabiliyeti ile sohbet edebilir. Rol stili belirgindir ve diyalog içeriği doğal ve akıcıdır. Chatbot, sanal asistan ve çevrimiçi müşteri hizmetleri gibi senaryolar için uygundur ve yüksek yanıt hızı vardır."
  },
  "Skylark2-pro-turbo-8k": {
    "description": "Skylark'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro-turbo-8k ile daha hızlı çıkarım gerçekleştirir, maliyeti düşüktür ve bağlam pencere uzunluğu 8k'dır."
  },
  "THUDM/GLM-4-32B-0414": {
    "description": "GLM-4-32B-0414, GLM serisinin yeni nesil açık kaynak modelidir ve 32 milyar parametreye sahiptir. Bu model, OpenAI'nin GPT serisi ve DeepSeek'in V3/R1 serisi ile karşılaştırılabilir performans sunar."
  },
  "THUDM/GLM-4-9B-0414": {
    "description": "GLM-4-9B-0414, GLM serisinin küçük modelidir ve 9 milyar parametreye sahiptir. Bu model, GLM-4-32B serisinin teknik özelliklerini devralır, ancak daha hafif bir dağıtım seçeneği sunar. Boyutu daha küçük olmasına rağmen, GLM-4-9B-0414, kod oluşturma, web tasarımı, SVG grafik oluşturma ve arama tabanlı yazım gibi görevlerde mükemmel yetenekler sergiler."
  },
  "THUDM/GLM-Z1-32B-0414": {
    "description": "GLM-Z1-32B-0414, derin düşünme yeteneğine sahip bir çıkarım modelidir. Bu model, GLM-4-32B-0414 temel alınarak soğuk başlatma ve genişletilmiş pekiştirme öğrenimi ile geliştirilmiştir ve matematik, kod ve mantık görevlerinde daha fazla eğitim almıştır. Temel model ile karşılaştırıldığında, GLM-Z1-32B-0414, matematik yeteneklerini ve karmaşık görevleri çözme yeteneğini önemli ölçüde artırmıştır."
  },
  "THUDM/GLM-Z1-9B-0414": {
    "description": "GLM-Z1-9B-0414, GLM serisinin küçük modelidir, yalnızca 9 milyar parametreye sahiptir, ancak açık kaynak geleneğini sürdürürken etkileyici yetenekler sergiler. Boyutu daha küçük olmasına rağmen, bu model matematik çıkarımı ve genel görevlerde mükemmel performans gösterir, genel performansı eşit boyuttaki açık kaynak modeller arasında lider konumdadır."
  },
  "THUDM/GLM-Z1-Rumination-32B-0414": {
    "description": "GLM-Z1-Rumination-32B-0414, derin düşünme yeteneğine sahip bir derin çıkarım modelidir (OpenAI'nin Derin Araştırması ile karşılaştırılabilir). Tipik derin düşünme modellerinin aksine, düşünme modeli daha uzun süreli derin düşünme ile daha açık ve karmaşık sorunları çözmektedir."
  },
  "THUDM/glm-4-9b-chat": {
    "description": "GLM-4 9B açık kaynak versiyonu, diyalog uygulamaları için optimize edilmiş bir diyalog deneyimi sunar."
  },
  "Tongyi-Zhiwen/QwenLong-L1-32B": {
    "description": "QwenLong-L1-32B, uzun bağlamlı büyük ölçekli akıl yürütme modeli (LRM) olup, pekiştirmeli öğrenme ile eğitilen ilk modeldir ve uzun metin akıl yürütme görevlerine optimize edilmiştir. Model, kademeli bağlam genişletme pekiştirmeli öğrenme çerçevesiyle kısa bağlamdan uzun bağlama stabil geçiş sağlar. Yedi uzun bağlamlı belge soru-cevap kıyaslama testinde, QwenLong-L1-32B OpenAI-o3-mini ve Qwen3-235B-A22B gibi amiral gemisi modelleri geride bırakmış ve Claude-3.7-Sonnet-Thinking ile karşılaştırılabilir performans göstermiştir. Model özellikle matematiksel akıl yürütme, mantıksal akıl yürütme ve çok adımlı akıl yürütme gibi karmaşık görevlerde uzmandır."
  },
  "Yi-34B-Chat": {
    "description": "Yi-1.5-34B, orijinal model serisinin mükemmel genel dil yeteneklerini korurken, 500 milyar yüksek kaliteli token ile artımlı eğitim sayesinde matematiksel mantık ve kodlama yeteneklerini büyük ölçüde artırmıştır."
  },
  "abab5.5-chat": {
    "description": "Üretkenlik senaryoları için tasarlanmış, karmaşık görev işleme ve verimli metin üretimini destekler, profesyonel alan uygulamaları için uygundur."
  },
  "abab5.5s-chat": {
    "description": "Çin karakter diyalog senaryoları için tasarlanmış, yüksek kaliteli Çin diyalog üretim yeteneği sunar ve çeşitli uygulama senaryoları için uygundur."
  },
  "abab6.5g-chat": {
    "description": "Çok dilli karakter diyalogları için tasarlanmış, İngilizce ve diğer birçok dilde yüksek kaliteli diyalog üretimini destekler."
  },
  "abab6.5s-chat": {
    "description": "Metin üretimi, diyalog sistemleri gibi geniş doğal dil işleme görevleri için uygundur."
  },
  "abab6.5t-chat": {
    "description": "Çin karakter diyalog senaryoları için optimize edilmiş, akıcı ve Çin ifade alışkanlıklarına uygun diyalog üretim yeteneği sunar."
  },
  "accounts/fireworks/models/deepseek-r1": {
    "description": "DeepSeek-R1, güçlendirilmiş öğrenme ve soğuk başlangıç verileri ile optimize edilmiş, mükemmel akıl yürütme, matematik ve programlama performansına sahip en son teknoloji büyük bir dil modelidir."
  },
  "accounts/fireworks/models/deepseek-v3": {
    "description": "Deepseek tarafından sunulan güçlü Mixture-of-Experts (MoE) dil modeli, toplamda 671B parametreye sahiptir ve her bir etiket için 37B parametre etkinleştirilmektedir."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct": {
    "description": "Llama 3 70B talimat modeli, çok dilli diyalog ve doğal dil anlama için optimize edilmiştir, çoğu rakip modelden daha iyi performans gösterir."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct": {
    "description": "Llama 3 8B talimat modeli, diyalog ve çok dilli görevler için optimize edilmiştir, mükemmel ve etkili performans sunar."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
    "description": "Llama 3 8B talimat modeli (HF versiyonu), resmi uygulama sonuçlarıyla uyumlu olup yüksek tutarlılık ve platformlar arası uyumluluk sunar."
  },
  "accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "description": "Llama 3.1 405B talimat modeli, devasa parametreler ile karmaşık görevler ve yüksek yük senaryolarında talimat takibi için uygundur."
  },
  "accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "description": "Llama 3.1 70B talimat modeli, mükemmel doğal dil anlama ve üretim yetenekleri sunar, diyalog ve analiz görevleri için idealdir."
  },
  "accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "description": "Llama 3.1 8B talimat modeli, çok dilli diyaloglar için optimize edilmiştir ve yaygın endüstri standartlarını aşmaktadır."
  },
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "description": "Meta'nın 11B parametreli komut ayarlı görüntü akıl yürütme modelidir. Bu model, görsel tanıma, görüntü akıl yürütme, görüntü betimleme ve görüntü hakkında genel sorulara yanıt verme üzerine optimize edilmiştir. Bu model, grafikler ve resimler gibi görsel verileri anlayabilir ve görüntü detaylarını metin olarak betimleyerek görsel ile dil arasındaki boşluğu kapatır."
  },
  "accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "description": "Llama 3.2 3B komut modeli, Meta tarafından sunulan hafif çok dilli bir modeldir. Bu model, verimliliği artırmak amacıyla daha büyük modellere göre gecikme ve maliyet açısından önemli iyileştirmeler sunar. Bu modelin örnek kullanım alanları arasında sorgulama, öneri yeniden yazma ve yazma desteği bulunmaktadır."
  },
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "description": "Meta'nın 90B parametreli komut ayarlı görüntü akıl yürütme modelidir. Bu model, görsel tanıma, görüntü akıl yürütme, görüntü betimleme ve görüntü hakkında genel sorulara yanıt verme üzerine optimize edilmiştir. Bu model, grafikler ve resimler gibi görsel verileri anlayabilir ve görüntü detaylarını metin olarak betimleyerek görsel ile dil arasındaki boşluğu kapatır."
  },
  "accounts/fireworks/models/llama-v3p3-70b-instruct": {
    "description": "Llama 3.3 70B Instruct, Llama 3.1 70B'nin Aralık güncellemesi olan bir modeldir. Bu model, Llama 3.1 70B (2024 Temmuz'da piyasaya sürüldü) temel alınarak geliştirilmiş olup, araç çağrıları, çok dilli metin desteği, matematik ve programlama yeteneklerini artırmıştır. Model, akıl yürütme, matematik ve talimat takibi alanlarında sektördeki en yüksek standartlara ulaşmış olup, 3.1 405B ile benzer performans sunarken hız ve maliyet açısından önemli avantajlar sağlamaktadır."
  },
  "accounts/fireworks/models/mistral-small-24b-instruct-2501": {
    "description": "24B parametreli model, daha büyük modellerle karşılaştırılabilir en son teknoloji yeteneklerine sahiptir."
  },
  "accounts/fireworks/models/mixtral-8x22b-instruct": {
    "description": "Mixtral MoE 8x22B talimat modeli, büyük ölçekli parametreler ve çok uzmanlı mimarisi ile karmaşık görevlerin etkili işlenmesini destekler."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct": {
    "description": "Mixtral MoE 8x7B talimat modeli, çok uzmanlı mimarisi ile etkili talimat takibi ve yürütme sunar."
  },
  "accounts/fireworks/models/mythomax-l2-13b": {
    "description": "MythoMax L2 13B modeli, yenilikçi birleşim teknolojileri ile hikaye anlatımı ve rol yapma konularında uzmandır."
  },
  "accounts/fireworks/models/phi-3-vision-128k-instruct": {
    "description": "Phi 3 Vision talimat modeli, karmaşık görsel ve metin bilgilerini işleyebilen hafif çok modlu bir modeldir ve güçlü akıl yürütme yeteneklerine sahiptir."
  },
  "accounts/fireworks/models/qwen-qwq-32b-preview": {
    "description": "QwQ modeli, Qwen ekibi tarafından geliştirilen deneysel bir araştırma modelidir ve AI akıl yürütme yeteneklerini artırmaya odaklanmaktadır."
  },
  "accounts/fireworks/models/qwen2-vl-72b-instruct": {
    "description": "Qwen-VL modelinin 72B versiyonu, Alibaba'nın en son iterasyonunun bir ürünüdür ve son bir yılın yeniliklerini temsil etmektedir."
  },
  "accounts/fireworks/models/qwen2p5-72b-instruct": {
    "description": "Qwen2.5, Alibaba Cloud Qwen ekibi tarafından geliştirilen yalnızca kodlayıcı içeren bir dizi dil modelidir. Bu modeller, 0.5B, 1.5B, 3B, 7B, 14B, 32B ve 72B gibi farklı boyutları sunar ve temel (base) ve komut (instruct) versiyonlarına sahiptir."
  },
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
    "description": "Qwen2.5 Coder 32B Instruct, Alibaba Cloud tarafından yayınlanan kod odaklı büyük dil modeli serisinin en son versiyonudur. Bu model, Qwen2.5 temelinde, 5.5 trilyon token ile eğitilerek kod üretimi, akıl yürütme ve düzeltme yeteneklerini önemli ölçüde artırmıştır. Hem kodlama yeteneklerini geliştirmiş hem de matematik ve genel yetenek avantajlarını korumuştur. Model, kod akıllı ajanları gibi pratik uygulamalar için daha kapsamlı bir temel sunmaktadır."
  },
  "accounts/yi-01-ai/models/yi-large": {
    "description": "Yi-Large modeli, mükemmel çok dilli işleme yetenekleri sunar ve her türlü dil üretimi ve anlama görevleri için uygundur."
  },
  "ai21-jamba-1.5-large": {
    "description": "398B parametreli (94B aktif) çok dilli bir model, 256K uzun bağlam penceresi, fonksiyon çağrısı, yapılandırılmış çıktı ve temellendirilmiş üretim sunar."
  },
  "ai21-jamba-1.5-mini": {
    "description": "52B parametreli (12B aktif) çok dilli bir model, 256K uzun bağlam penceresi, fonksiyon çağrısı, yapılandırılmış çıktı ve temellendirilmiş üretim sunar."
  },
  "ai21-labs/AI21-Jamba-1.5-Large": {
    "description": "398 milyar parametreli (94 milyar aktif) çok dilli model, 256K uzun bağlam penceresi, fonksiyon çağrısı, yapılandırılmış çıktı ve gerçeklere dayalı üretim sunar."
  },
  "ai21-labs/AI21-Jamba-1.5-Mini": {
    "description": "52 milyar parametreli (12 milyar aktif) çok dilli model, 256K uzun bağlam penceresi, fonksiyon çağrısı, yapılandırılmış çıktı ve gerçeklere dayalı üretim sunar."
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "description": "Claude 3.5 Sonnet, endüstri standartlarını yükselterek, rakip modelleri ve Claude 3 Opus'u geride bırakarak geniş bir değerlendirmede mükemmel performans sergilerken, orta seviye modellerimizin hızı ve maliyeti ile birlikte gelir."
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet, sektör standartlarını yükselterek, rakip modelleri ve Claude 3 Opus'u geride bırakarak, geniş bir değerlendirme yelpazesinde mükemmel performans sergilemekte, orta seviye modellerimizin hız ve maliyet avantajlarını sunmaktadır."
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "description": "Claude 3 Haiku, Anthropic'in en hızlı ve en kompakt modelidir, neredeyse anında yanıt hızı sunar. Basit sorgular ve taleplere hızlı bir şekilde yanıt verebilir. Müşteriler, insan etkileşimini taklit eden kesintisiz bir AI deneyimi oluşturabileceklerdir. Claude 3 Haiku, görüntüleri işleyebilir ve metin çıktısı döndürebilir, 200K bağlam penceresine sahiptir."
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "description": "Claude 3 Opus, Anthropic'in en güçlü AI modelidir, son derece karmaşık görevlerde en ileri düzey performansa sahiptir. Açık uçlu istemleri ve daha önce görülmemiş senaryoları işleyebilir, mükemmel akıcılık ve insan benzeri anlama yeteneğine sahiptir. Claude 3 Opus, üretken AI olasılıklarının öncüsüdür. Claude 3 Opus, görüntüleri işleyebilir ve metin çıktısı döndürebilir, 200K bağlam penceresine sahiptir."
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "description": "Anthropic'in Claude 3 Sonnet, zeka ve hız arasında ideal bir denge sağlar - özellikle kurumsal iş yükleri için uygundur. Rakiplerine göre daha düşük bir fiyatla maksimum fayda sunar ve ölçeklenebilir AI dağıtımları için güvenilir, dayanıklı bir ana makine olarak tasarlanmıştır. Claude 3 Sonnet, görüntüleri işleyebilir ve metin çıktısı döndürebilir, 200K bağlam penceresine sahiptir."
  },
  "anthropic.claude-instant-v1": {
    "description": "Günlük diyaloglar, metin analizi, özetleme ve belge soru-cevap gibi bir dizi görevi işleyebilen hızlı, ekonomik ve hala oldukça yetenekli bir modeldir."
  },
  "anthropic.claude-v2": {
    "description": "Anthropic, karmaşık diyaloglardan yaratıcı içerik üretimine ve ayrıntılı talimat takibine kadar geniş bir görev yelpazesinde yüksek yetenek sergileyen bir modeldir."
  },
  "anthropic.claude-v2:1": {
    "description": "Claude 2'nin güncellenmiş versiyonu, iki kat daha büyük bir bağlam penceresine sahiptir ve uzun belgeler ve RAG bağlamındaki güvenilirlik, yanılsama oranı ve kanıta dayalı doğrulukta iyileştirmeler sunar."
  },
  "anthropic/claude-3-haiku": {
    "description": "Claude 3 Haiku, Anthropic'in en hızlı ve en kompakt modelidir; neredeyse anlık yanıtlar sağlamak için tasarlanmıştır. Hızlı ve doğru yönlendirme performansına sahiptir."
  },
  "anthropic/claude-3-opus": {
    "description": "Claude 3 Opus, Anthropic'in son derece karmaşık görevleri işlemek için en güçlü modelidir. Performans, zeka, akıcılık ve anlama açısından olağanüstü bir performans sergiler."
  },
  "anthropic/claude-3.5-haiku": {
    "description": "Claude 3.5 Haiku, Anthropic'in en hızlı bir sonraki nesil modelidir. Claude 3 Haiku ile karşılaştırıldığında, Claude 3.5 Haiku, birçok beceride iyileşme göstermiştir ve birçok zeka kıyaslamasında bir önceki neslin en büyük modeli Claude 3 Opus'u geride bırakmıştır."
  },
  "anthropic/claude-3.5-sonnet": {
    "description": "Claude 3.5 Sonnet, Opus'tan daha fazla yetenek ve Sonnet'ten daha hızlı bir hız sunar; aynı zamanda Sonnet ile aynı fiyatı korur. Sonnet, programlama, veri bilimi, görsel işleme ve ajan görevlerinde özellikle başarılıdır."
  },
  "anthropic/claude-3.7-sonnet": {
    "description": "Claude 3.7 Sonnet, Anthropic'in şimdiye kadarki en akıllı modeli ve piyasadaki ilk karma akıl yürütme modelidir. Claude 3.7 Sonnet, neredeyse anlık yanıtlar veya uzatılmış adım adım düşünme süreçleri üretebilir; kullanıcılar bu süreçleri net bir şekilde görebilir. Sonnet, programlama, veri bilimi, görsel işleme ve temsilci görevlerde özellikle yeteneklidir."
  },
  "anthropic/claude-opus-4": {
    "description": "Claude Opus 4, Anthropic tarafından yüksek karmaşıklıktaki görevleri işlemek için geliştirilen en güçlü modeldir. Performans, zeka, akıcılık ve anlama yeteneği açısından üstün bir performans sergiler."
  },
  "anthropic/claude-sonnet-4": {
    "description": "Claude Sonnet 4, neredeyse anında yanıtlar veya uzatılmış adım adım düşünme süreçleri üretebilir; kullanıcılar bu süreçleri net bir şekilde görebilir. API kullanıcıları ayrıca modelin düşünme süresini ayrıntılı olarak kontrol edebilir."
  },
  "aya": {
    "description": "Aya 23, Cohere tarafından sunulan çok dilli bir modeldir, 23 dili destekler ve çok dilli uygulamalar için kolaylık sağlar."
  },
  "aya:35b": {
    "description": "Aya 23, Cohere tarafından sunulan çok dilli bir modeldir, 23 dili destekler ve çok dilli uygulamalar için kolaylık sağlar."
  },
  "baichuan/baichuan2-13b-chat": {
    "description": "Baichuan-13B, Baichuan Zhi Neng tarafından geliştirilen 130 milyar parametreye sahip açık kaynaklı ticari bir büyük dil modelidir ve yetkili Çince ve İngilizce benchmark'larda aynı boyuttaki en iyi sonuçları elde etmiştir."
  },
  "c4ai-aya-expanse-32b": {
    "description": "Aya Expanse, talimat ayarlama, veri arbitrajı, tercih eğitimi ve model birleştirme yenilikleri ile tek dilli modellerin performansını zorlamak için tasarlanmış yüksek performanslı bir 32B çok dilli modeldir. 23 dili desteklemektedir."
  },
  "c4ai-aya-expanse-8b": {
    "description": "Aya Expanse, talimat ayarlama, veri arbitrajı, tercih eğitimi ve model birleştirme yenilikleri ile tek dilli modellerin performansını zorlamak için tasarlanmış yüksek performanslı bir 8B çok dilli modeldir. 23 dili desteklemektedir."
  },
  "c4ai-aya-vision-32b": {
    "description": "Aya Vision, dil, metin ve görüntü yeteneklerinin birden fazla anahtar ölçütünde mükemmel performans sergileyen en son teknoloji çok modlu bir modeldir. 23 dili desteklemektedir. Bu 32 milyar parametreli versiyon, en son teknoloji çok dilli performansa odaklanmaktadır."
  },
  "c4ai-aya-vision-8b": {
    "description": "Aya Vision, dil, metin ve görüntü yeteneklerinin birden fazla anahtar ölçütünde mükemmel performans sergileyen en son teknoloji çok modlu bir modeldir. Bu 8 milyar parametreli versiyon, düşük gecikme ve en iyi performansa odaklanmaktadır."
  },
  "charglm-3": {
    "description": "CharGLM-3, rol yapma ve duygusal destek için tasarlanmış, ultra uzun çok turlu bellek ve kişiselleştirilmiş diyalog desteği sunan bir modeldir, geniş bir uygulama yelpazesine sahiptir."
  },
  "charglm-4": {
    "description": "CharGLM-4, rol yapma ve duygusal destek için tasarlanmıştır, uzun süreli çoklu hafıza ve kişiselleştirilmiş diyalogları destekler, geniş bir uygulama yelpazesine sahiptir."
  },
  "chatglm3": {
    "description": "ChatGLM3, ZhiPu AI ve Tsinghua KEG laboratuvarı tarafından yayınlanan kapalı kaynaklı bir modeldir. Büyük miktarda Çince ve İngilizce belirteçlerin önceden eğitilmesi ve insan tercihleriyle hizalama eğitimi ile, birinci nesil modellere göre MMLU, C-Eval ve GSM8K'da sırasıyla %16, %36 ve %280'lük iyileştirmeler elde edilmiştir ve Çince görevler listesinde C-Eval zirvesine ulaşmıştır. Bilgi hacmi, çıkarım yeteneği ve yaratıcılık gerektiren senaryolarda kullanılabilir, örneğin reklam metni, roman yazımı, bilgi tabanlı yazım, kod oluşturma vb."
  },
  "chatglm3-6b-base": {
    "description": "ChatGLM3-6b-base, ZhiPu tarafından geliştirilen ChatGLM serisinin en yeni nesli olan 6 milyar parametrelik açık kaynaklı temel modeldir."
  },
  "chatgpt-4o-latest": {
    "description": "ChatGPT-4o, güncel versiyonunu korumak için gerçek zamanlı olarak güncellenen dinamik bir modeldir. Güçlü dil anlama ve üretme yeteneklerini birleştirir, müşteri hizmetleri, eğitim ve teknik destek gibi geniş ölçekli uygulama senaryoları için uygundur."
  },
  "claude-2.0": {
    "description": "Claude 2, işletmelere kritik yeteneklerin ilerlemesini sunar, sektördeki en iyi 200K token bağlamı, model yanılsamalarının önemli ölçüde azaltılması, sistem ipuçları ve yeni bir test özelliği: araç çağrısı içerir."
  },
  "claude-2.1": {
    "description": "Claude 2, işletmelere kritik yeteneklerin ilerlemesini sunar, sektördeki en iyi 200K token bağlamı, model yanılsamalarının önemli ölçüde azaltılması, sistem ipuçları ve yeni bir test özelliği: araç çağrısı içerir."
  },
  "claude-3-5-haiku-20241022": {
    "description": "Claude 3.5 Haiku, Anthropic'in en hızlı bir sonraki nesil modelidir. Claude 3 Haiku ile karşılaştırıldığında, Claude 3.5 Haiku, tüm becerilerde gelişim göstermiştir ve birçok zeka standart testinde bir önceki neslin en büyük modeli olan Claude 3 Opus'u geride bırakmıştır."
  },
  "claude-3-5-sonnet-20240620": {
    "description": "Claude 3.5 Sonnet, Opus'tan daha fazla yetenek ve Sonnet'ten daha hızlı bir performans sunar, aynı zamanda Sonnet ile aynı fiyatı korur. Sonnet, programlama, veri bilimi, görsel işleme ve ajan görevlerinde özellikle başarılıdır."
  },
  "claude-3-5-sonnet-20241022": {
    "description": "Claude 3.5 Sonnet, Opus'tan daha fazla yetenek ve Sonnet'ten daha hızlı performans sunarken, aynı fiyatta kalmaktadır. Sonnet, programlama, veri bilimi, görsel işleme ve aracı görevlerde özellikle güçlüdür."
  },
  "claude-3-7-sonnet-20250219": {
    "description": "Claude 3.7 Sonnet, endüstri standartlarını yükselterek, rakip modelleri ve Claude 3 Opus'u geride bırakarak, geniş bir değerlendirme yelpazesinde mükemmel performans sergilemekte, orta seviye modellerimizin hız ve maliyet avantajlarını sunmaktadır."
  },
  "claude-3-haiku-20240307": {
    "description": "Claude 3 Haiku, Anthropic'in en hızlı ve en kompakt modelidir, neredeyse anlık yanıtlar sağlamak için tasarlanmıştır. Hızlı ve doğru yönlendirme performansına sahiptir."
  },
  "claude-3-opus-20240229": {
    "description": "Claude 3 Opus, Anthropic'in yüksek karmaşıklıkta görevleri işlemek için en güçlü modelidir. Performans, zeka, akıcılık ve anlama açısından mükemmel bir şekilde öne çıkar."
  },
  "claude-3-sonnet-20240229": {
    "description": "Claude 3 Sonnet, akıllı ve hızlı bir denge sunarak kurumsal iş yükleri için idealdir. Daha düşük bir fiyatla maksimum fayda sağlar, güvenilir ve büyük ölçekli dağıtım için uygundur."
  },
  "claude-opus-4-20250514": {
    "description": "Claude Opus 4, Anthropic'in son derece karmaşık görevleri işlemek için geliştirdiği en güçlü modeldir. Performans, zeka, akıcılık ve anlama açısından mükemmel bir şekilde öne çıkmaktadır."
  },
  "claude-sonnet-4-20250514": {
    "description": "Claude 4 Sonnet, neredeyse anlık yanıtlar veya uzatılmış aşamalı düşünme süreçleri üretebilir; kullanıcılar bu süreçleri net bir şekilde görebilir. API kullanıcıları, modelin düşünme süresini ayrıntılı bir şekilde kontrol edebilir."
  },
  "codegeex-4": {
    "description": "CodeGeeX-4, çeşitli programlama dillerinde akıllı soru-cevap ve kod tamamlama desteği sunan güçlü bir AI programlama asistanıdır, geliştirme verimliliğini artırır."
  },
  "codegeex4-all-9b": {
    "description": "CodeGeeX4-ALL-9B, çok dilli kod üretim modeli olup, kod tamamlama ve üretimi, kod yorumlayıcı, web arama, fonksiyon çağrısı, depo düzeyinde kod soru-cevap gibi kapsamlı işlevleri destekler ve yazılım geliştirme için çeşitli senaryoları kapsar. 10B'den az parametreye sahip en iyi kod üretim modelidir."
  },
  "codegemma": {
    "description": "CodeGemma, farklı programlama görevleri için özel olarak tasarlanmış hafif bir dil modelidir, hızlı iterasyon ve entegrasyonu destekler."
  },
  "codegemma:2b": {
    "description": "CodeGemma, farklı programlama görevleri için özel olarak tasarlanmış hafif bir dil modelidir, hızlı iterasyon ve entegrasyonu destekler."
  },
  "codellama": {
    "description": "Code Llama, kod üretimi ve tartışmalarına odaklanan bir LLM'dir, geniş programlama dili desteği ile geliştirici ortamları için uygundur."
  },
  "codellama/CodeLlama-34b-Instruct-hf": {
    "description": "Code Llama, kod üretimi ve tartışmalarına odaklanan bir LLM'dir ve geniş bir programlama dili desteği sunarak geliştirici ortamları için uygundur."
  },
  "codellama:13b": {
    "description": "Code Llama, kod üretimi ve tartışmalarına odaklanan bir LLM'dir, geniş programlama dili desteği ile geliştirici ortamları için uygundur."
  },
  "codellama:34b": {
    "description": "Code Llama, kod üretimi ve tartışmalarına odaklanan bir LLM'dir, geniş programlama dili desteği ile geliştirici ortamları için uygundur."
  },
  "codellama:70b": {
    "description": "Code Llama, kod üretimi ve tartışmalarına odaklanan bir LLM'dir, geniş programlama dili desteği ile geliştirici ortamları için uygundur."
  },
  "codeqwen": {
    "description": "CodeQwen1.5, büyük miktarda kod verisi ile eğitilmiş büyük bir dil modelidir, karmaşık programlama görevlerini çözmek için özel olarak tasarlanmıştır."
  },
  "codestral": {
    "description": "Codestral, Mistral AI'nın ilk kod modelidir, kod üretim görevlerine mükemmel destek sunar."
  },
  "codestral-latest": {
    "description": "Codestral, kod üretimine odaklanan son teknoloji bir üretim modelidir, ara doldurma ve kod tamamlama görevlerini optimize etmiştir."
  },
  "codex-mini-latest": {
    "description": "codex-mini-latest, Codex CLI için özel olarak tasarlanmış o4-mini'nin ince ayar versiyonudur. API üzerinden doğrudan kullanım için, gpt-4.1'den başlamanızı öneririz."
  },
  "cognitivecomputations/dolphin-mixtral-8x22b": {
    "description": "Dolphin Mixtral 8x22B, talimat takibi, diyalog ve programlama için tasarlanmış bir modeldir."
  },
  "cohere-command-r": {
    "description": "Command R, üretim ölçeğinde AI sağlamak için RAG ve Araç Kullanımına yönelik ölçeklenebilir bir üretken modeldir."
  },
  "cohere-command-r-plus": {
    "description": "Command R+, kurumsal düzeyde iş yüklerini ele almak için tasarlanmış en son RAG optimize edilmiş bir modeldir."
  },
  "cohere/Cohere-command-r": {
    "description": "Command R, RAG ve araç kullanımı için ölçeklenebilir bir üretim modeli olup, işletmelerin üretim seviyesinde yapay zeka uygulamalarını gerçekleştirmesine olanak tanır."
  },
  "cohere/Cohere-command-r-plus": {
    "description": "Command R+, işletme düzeyindeki iş yükleri için tasarlanmış, en gelişmiş RAG optimize modelidir."
  },
  "command": {
    "description": "Dil görevlerinde yüksek kalite ve güvenilirlik sunan, talimatları izleyen bir diyalog modelidir ve temel üretim modelimize göre daha uzun bir bağlam uzunluğuna sahiptir."
  },
  "command-a-03-2025": {
    "description": "Command A, şimdiye kadar geliştirdiğimiz en güçlü modeldir ve araç kullanımı, ajan, bilgi artırımlı üretim (RAG) ve çok dilli uygulama senaryolarında mükemmel performans sergilemektedir. Command A, 256K bağlam uzunluğuna sahiptir, yalnızca iki GPU ile çalıştırılabilir ve Command R+ 08-2024'e kıyasla %150 daha yüksek bir verimlilik sunar."
  },
  "command-light": {
    "description": "Neredeyse aynı güçte, ancak daha hızlı olan daha küçük ve daha hızlı bir Command versiyonudur."
  },
  "command-light-nightly": {
    "description": "Ana sürüm güncellemeleri arasındaki süreyi kısaltmak için Command modelinin her gece sürümünü sunuyoruz. command-light serisi için bu sürüm command-light-nightly olarak adlandırılmaktadır. Lütfen dikkat edin, command-light-nightly en güncel, en deneysel ve (muhtemelen) kararsız sürümdür. Her gece sürümü düzenli olarak güncellenir ve önceden bildirilmez, bu nedenle üretim ortamında kullanılması önerilmez."
  },
  "command-nightly": {
    "description": "Ana sürüm güncellemeleri arasındaki süreyi kısaltmak için Command modelinin her gece sürümünü sunuyoruz. Command serisi için bu sürüm command-cightly olarak adlandırılmaktadır. Lütfen dikkat edin, command-nightly en güncel, en deneysel ve (muhtemelen) kararsız sürümdür. Her gece sürümü düzenli olarak güncellenir ve önceden bildirilmez, bu nedenle üretim ortamında kullanılması önerilmez."
  },
  "command-r": {
    "description": "Command R, diyalog ve uzun bağlam görevleri için optimize edilmiş bir LLM'dir, dinamik etkileşim ve bilgi yönetimi için özellikle uygundur."
  },
  "command-r-03-2024": {
    "description": "Command R, dil görevlerinde daha yüksek kalite ve güvenilirlik sunan, talimatları izleyen bir diyalog modelidir ve önceki modellere göre daha uzun bir bağlam uzunluğuna sahiptir. Kod üretimi, bilgi artırımlı üretim (RAG), araç kullanımı ve ajan gibi karmaşık iş akışları için kullanılabilir."
  },
  "command-r-08-2024": {
    "description": "command-r-08-2024, Command R modelinin güncellenmiş versiyonudur ve 2024 yılının Ağustos ayında piyasaya sürülmüştür."
  },
  "command-r-plus": {
    "description": "Command R+, gerçek işletme senaryoları ve karmaşık uygulamalar için tasarlanmış yüksek performanslı bir büyük dil modelidir."
  },
  "command-r-plus-04-2024": {
    "description": "Command R+, dil görevlerinde daha yüksek kalite ve güvenilirlik sunan, talimatları izleyen bir diyalog modelidir ve önceki modellere göre daha uzun bir bağlam uzunluğuna sahiptir. Karmaşık RAG iş akışları ve çok adımlı araç kullanımı için en uygunudur."
  },
  "command-r-plus-08-2024": {
    "description": "Command R+ talimatları takip eden bir diyalog modelidir, dil görevlerinde daha yüksek kalite, daha güvenilirlik sunar ve önceki modellere göre daha uzun bağlam uzunluğuna sahiptir. Karmaşık RAG iş akışları ve çok adımlı araç kullanımı için en uygunudur."
  },
  "command-r7b-12-2024": {
    "description": "command-r7b-12-2024, 2024 yılının Aralık ayında piyasaya sürülen küçük ve verimli bir güncellenmiş versiyondur. RAG, araç kullanımı, ajan gibi karmaşık akıl yürütme ve çok adımlı işlemler gerektiren görevlerde mükemmel performans sergilemektedir."
  },
  "compound-beta": {
    "description": "Compound-beta, GroqCloud'da desteklenen birden fazla açık kullanılabilir modelden güç alan bir bileşik AI sistemidir, kullanıcı sorgularını yanıtlamak için araçları akıllıca ve seçici bir şekilde kullanabilir."
  },
  "compound-beta-mini": {
    "description": "Compound-beta-mini, GroqCloud'da desteklenen açık kullanılabilir modellerden güç alan bir bileşik AI sistemidir, kullanıcı sorgularını yanıtlamak için araçları akıllıca ve seçici bir şekilde kullanabilir."
  },
  "computer-use-preview": {
    "description": "computer-use-preview modeli, \"Bilgisayar Kullanım Araçları\" için özel olarak tasarlanmış bir modeldir ve bilgisayarla ilgili görevleri anlama ve yerine getirme konusunda eğitilmiştir."
  },
  "dall-e-2": {
    "description": "İkinci nesil DALL·E modeli, daha gerçekçi ve doğru görüntü üretimi destekler, çözünürlüğü birinci neslin 4 katıdır."
  },
  "dall-e-3": {
    "description": "En son DALL·E modeli, Kasım 2023'te piyasaya sürüldü. Daha gerçekçi ve doğru görüntü üretimi destekler, daha güçlü detay ifade yeteneğine sahiptir."
  },
  "databricks/dbrx-instruct": {
    "description": "DBRX Instruct, yüksek güvenilirlikte talimat işleme yetenekleri sunar ve çok çeşitli endüstri uygulamalarını destekler."
  },
  "deepseek-ai/DeepSeek-R1": {
    "description": "DeepSeek-R1, tekrarlayan öğrenme (RL) destekli bir çıkarım modelidir ve modeldeki tekrarlama ve okunabilirlik sorunlarını çözmektedir. RL'den önce, DeepSeek-R1 soğuk başlangıç verilerini tanıtarak çıkarım performansını daha da optimize etmiştir. Matematik, kod ve çıkarım görevlerinde OpenAI-o1 ile benzer bir performans sergilemekte ve özenle tasarlanmış eğitim yöntemleri ile genel etkisini artırmaktadır."
  },
  "deepseek-ai/DeepSeek-R1-0528": {
    "description": "DeepSeek R1, artırılmış hesaplama kaynakları ve son eğitim sürecinde algoritma optimizasyon mekanizmalarının entegrasyonu sayesinde çıkarım ve akıl yürütme derinliğini önemli ölçüde artırmıştır. Model, matematik, programlama ve genel mantık alanlarında çeşitli kıyaslama testlerinde üstün performans göstermektedir. Genel performansı, O3 ve Gemini 2.5 Pro gibi lider modellerle yakındır."
  },
  "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B": {
    "description": "DeepSeek-R1-0528-Qwen3-8B, DeepSeek-R1-0528 modelinden düşünce zinciri distilasyonu yoluyla Qwen3 8B Base modeline elde edilen bir modeldir. Açık kaynak modeller arasında en ileri (SOTA) performansa sahiptir, AIME 2024 testinde Qwen3 8B'yi %10 aşmış ve Qwen3-235B-thinking performans seviyesine ulaşmıştır. Model matematiksel akıl yürütme, programlama ve genel mantık gibi çeşitli kıyaslama testlerinde üstün performans gösterir; mimarisi Qwen3-8B ile aynıdır ancak DeepSeek-R1-0528'in tokenizer konfigürasyonunu paylaşır."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
    "description": "DeepSeek-R1 damıtma modeli, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
    "description": "DeepSeek-R1 damıtma modeli, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
    "description": "DeepSeek-R1 damıtma modeli, pekiştirme öğrenimi ve soğuk başlatma verileri ile çıkarım performansını optimize eder, açık kaynak model çoklu görev standartlarını yeniler."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
    "description": "DeepSeek-R1-Distill-Qwen-32B, Qwen2.5-32B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından üretilen 800.000 seçkin örnek ile ince ayar yapılmış, matematik, programlama ve çıkarım gibi birçok alanda olağanüstü performans sergilemektedir. AIME 2024, MATH-500, GPQA Diamond gibi birçok referans testinde mükemmel sonuçlar elde etmiş, MATH-500'de %94.3 doğruluk oranına ulaşarak güçlü matematik çıkarım yeteneğini göstermiştir."
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
    "description": "DeepSeek-R1-Distill-Qwen-7B, Qwen2.5-Math-7B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından üretilen 800.000 seçkin örnek ile ince ayar yapılmış, mükemmel çıkarım yeteneği sergilemektedir. Birçok referans testinde öne çıkmış, MATH-500'de %92.8 doğruluk oranına, AIME 2024'te %55.5 geçiş oranına ulaşmış, CodeForces'ta 1189 puan alarak 7B ölçeğindeki model olarak güçlü matematik ve programlama yeteneğini göstermiştir."
  },
  "deepseek-ai/DeepSeek-V2.5": {
    "description": "DeepSeek V2.5, önceki sürümlerin mükemmel özelliklerini bir araya getirir, genel ve kodlama yeteneklerini artırır."
  },
  "deepseek-ai/DeepSeek-V3": {
    "description": "DeepSeek-V3, 6710 milyar parametreye sahip bir karma uzman (MoE) dil modelidir. Çok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarisini kullanarak, yardımcı kayıplar olmadan yük dengeleme stratejisi ile çıkarım ve eğitim verimliliğini optimize etmektedir. 14.8 trilyon yüksek kaliteli token üzerinde önceden eğitilmiş ve denetimli ince ayar ile tekrarlayan öğrenme gerçekleştirilmiştir; DeepSeek-V3, performans açısından diğer açık kaynaklı modelleri geride bırakmakta ve lider kapalı kaynaklı modellere yaklaşmaktadır."
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "description": "DeepSeek 67B, yüksek karmaşıklıkta diyaloglar için eğitilmiş gelişmiş bir modeldir."
  },
  "deepseek-ai/deepseek-r1": {
    "description": "En son teknolojiye sahip verimli LLM, akıl yürütme, matematik ve programlama konularında uzmandır."
  },
  "deepseek-ai/deepseek-vl2": {
    "description": "DeepSeek-VL2, DeepSeekMoE-27B tabanlı bir karma uzman (MoE) görsel dil modelidir. Seyrek etkinleştirilen MoE mimarisini kullanarak yalnızca 4.5B parametreyi etkinleştirerek olağanüstü performans sergilemektedir. Bu model, görsel soru yanıtlama, optik karakter tanıma, belge/tablolar/grafikler anlama ve görsel konumlandırma gibi birçok görevde mükemmel sonuçlar elde etmektedir."
  },
  "deepseek-chat": {
    "description": "Genel ve kod yeteneklerini birleştiren yeni bir açık kaynak modeli, yalnızca mevcut Chat modelinin genel diyalog yeteneklerini ve Coder modelinin güçlü kod işleme yeteneklerini korumakla kalmaz, aynı zamanda insan tercihleri ile daha iyi hizalanmıştır. Ayrıca, DeepSeek-V2.5 yazım görevleri, talimat takibi gibi birçok alanda büyük iyileştirmeler sağlamıştır."
  },
  "deepseek-coder-33B-instruct": {
    "description": "DeepSeek Coder 33B, 20 trilyon veri ile eğitilmiş bir kod dili modelidir. Bunun %87'si kod, %13'ü ise Çince ve İngilizce dillerindendir. Model, 16K pencere boyutu ve boşluk doldurma görevini tanıtarak proje düzeyinde kod tamamlama ve parça doldurma işlevi sunmaktadır."
  },
  "deepseek-coder-v2": {
    "description": "DeepSeek Coder V2, açık kaynaklı bir karışık uzman kod modelidir, kod görevlerinde mükemmel performans sergiler ve GPT4-Turbo ile karşılaştırılabilir."
  },
  "deepseek-coder-v2:236b": {
    "description": "DeepSeek Coder V2, açık kaynaklı bir karışık uzman kod modelidir, kod görevlerinde mükemmel performans sergiler ve GPT4-Turbo ile karşılaştırılabilir."
  },
  "deepseek-r1": {
    "description": "DeepSeek-R1, tekrarlayan öğrenme (RL) destekli bir çıkarım modelidir ve modeldeki tekrarlama ve okunabilirlik sorunlarını çözmektedir. RL'den önce, DeepSeek-R1 soğuk başlangıç verilerini tanıtarak çıkarım performansını daha da optimize etmiştir. Matematik, kod ve çıkarım görevlerinde OpenAI-o1 ile benzer bir performans sergilemekte ve özenle tasarlanmış eğitim yöntemleri ile genel etkisini artırmaktadır."
  },
  "deepseek-r1-0528": {
    "description": "685 milyar parametreli tam sürüm model, 28 Mayıs 2025'te yayınlandı. DeepSeek-R1, son eğitim aşamasında pek az etiketli veriyle güçlendirilmiş öğrenme tekniklerini geniş çapta kullanarak modelin çıkarım yeteneğini büyük ölçüde artırdı. Matematik, kodlama, doğal dil çıkarımı gibi görevlerde yüksek performans ve güçlü yetenekler sergiler."
  },
  "deepseek-r1-70b-fast-online": {
    "description": "DeepSeek R1 70B hızlı versiyonu, gerçek zamanlı çevrimiçi arama desteği ile, model performansını korurken daha hızlı yanıt süreleri sunar."
  },
  "deepseek-r1-70b-online": {
    "description": "DeepSeek R1 70B standart versiyonu, gerçek zamanlı çevrimiçi arama desteği ile, en güncel bilgilere ihtiyaç duyan diyalog ve metin işleme görevleri için uygundur."
  },
  "deepseek-r1-distill-llama": {
    "description": "deepseek-r1-distill-llama, DeepSeek-R1'den Llama tabanlı damıtılarak elde edilmiş bir modeldir."
  },
  "deepseek-r1-distill-llama-70b": {
    "description": "DeepSeek R1 - DeepSeek paketindeki daha büyük ve daha akıllı model - Llama 70B mimarisine damıtılmıştır. Referans testleri ve insan değerlendirmelerine dayanarak, bu model orijinal Llama 70B'den daha akıllıdır, özellikle matematik ve gerçeklik doğruluğu gerektiren görevlerde mükemmel performans sergilemektedir."
  },
  "deepseek-r1-distill-llama-8b": {
    "description": "DeepSeek-R1-Distill serisi modeller, bilgi damıtma teknolojisi ile DeepSeek-R1 tarafından üretilen örneklerin Qwen, Llama gibi açık kaynak modeller üzerinde ince ayar yapılmasıyla elde edilmiştir."
  },
  "deepseek-r1-distill-qianfan-llama-70b": {
    "description": "14 Şubat 2025'te ilk kez piyasaya sürülen bu model, Qianfan büyük model geliştirme ekibi tarafından Llama3_70B temel modeli (Meta Llama ile oluşturulmuştur) kullanılarak damıtılmıştır ve damıtma verilerine Qianfan'ın metinleri de eklenmiştir."
  },
  "deepseek-r1-distill-qianfan-llama-8b": {
    "description": "14 Şubat 2025'te ilk kez piyasaya sürülen bu model, Qianfan büyük model geliştirme ekibi tarafından Llama3_8B temel modeli (Meta Llama ile oluşturulmuştur) kullanılarak damıtılmıştır ve damıtma verilerine Qianfan'ın metinleri de eklenmiştir."
  },
  "deepseek-r1-distill-qwen": {
    "description": "deepseek-r1-distill-qwen, Qwen temel alınarak DeepSeek-R1'den damıtılmış bir modeldir."
  },
  "deepseek-r1-distill-qwen-1.5b": {
    "description": "DeepSeek-R1-Distill serisi modeller, bilgi damıtma teknolojisi ile DeepSeek-R1 tarafından üretilen örneklerin Qwen, Llama gibi açık kaynak modeller üzerinde ince ayar yapılmasıyla elde edilmiştir."
  },
  "deepseek-r1-distill-qwen-14b": {
    "description": "DeepSeek-R1-Distill serisi modeller, bilgi damıtma teknolojisi ile DeepSeek-R1 tarafından üretilen örneklerin Qwen, Llama gibi açık kaynak modeller üzerinde ince ayar yapılmasıyla elde edilmiştir."
  },
  "deepseek-r1-distill-qwen-32b": {
    "description": "DeepSeek-R1-Distill serisi modeller, bilgi damıtma teknolojisi ile DeepSeek-R1 tarafından üretilen örneklerin Qwen, Llama gibi açık kaynak modeller üzerinde ince ayar yapılmasıyla elde edilmiştir."
  },
  "deepseek-r1-distill-qwen-7b": {
    "description": "DeepSeek-R1-Distill serisi modeller, bilgi damıtma teknolojisi ile DeepSeek-R1 tarafından üretilen örneklerin Qwen, Llama gibi açık kaynak modeller üzerinde ince ayar yapılmasıyla elde edilmiştir."
  },
  "deepseek-r1-fast-online": {
    "description": "DeepSeek R1 tam hızlı versiyonu, gerçek zamanlı çevrimiçi arama desteği ile, 671B parametrenin güçlü yetenekleri ile daha hızlı yanıt sürelerini birleştirir."
  },
  "deepseek-r1-online": {
    "description": "DeepSeek R1 tam sürümü, 671B parametreye sahip olup, gerçek zamanlı çevrimiçi arama desteği ile daha güçlü anlama ve üretim yeteneklerine sahiptir."
  },
  "deepseek-reasoner": {
    "description": "DeepSeek tarafından sunulan bir akıl yürütme modeli. Model, nihai yanıtı vermeden önce bir düşünce zinciri içeriği sunarak nihai cevabın doğruluğunu artırır."
  },
  "deepseek-v2": {
    "description": "DeepSeek V2, ekonomik ve verimli işleme ihtiyaçları için uygun, etkili bir Mixture-of-Experts dil modelidir."
  },
  "deepseek-v2:236b": {
    "description": "DeepSeek V2 236B, DeepSeek'in tasarım kodu modelidir, güçlü kod üretim yetenekleri sunar."
  },
  "deepseek-v3": {
    "description": "DeepSeek-V3, Hangzhou DeepSeek Yapay Zeka Temel Teknoloji Araştırma Şirketi tarafından geliştirilen MoE modelidir, birçok değerlendirme sonucunda öne çıkmakta ve ana akım listelerde açık kaynak modeller arasında birinci sırada yer almaktadır. V3, V2.5 modeline göre üretim hızında 3 kat artış sağlamış, kullanıcılara daha hızlı ve akıcı bir deneyim sunmuştur."
  },
  "deepseek-v3-0324": {
    "description": "DeepSeek-V3-0324, 671B parametreye sahip bir MoE modelidir ve programlama ile teknik yetenekler, bağlam anlama ve uzun metin işleme gibi alanlarda belirgin avantajlar sunar."
  },
  "deepseek/deepseek-chat-v3-0324": {
    "description": "DeepSeek V3, 685B parametreye sahip bir uzman karışık modeldir ve DeepSeek ekibinin amiral gemisi sohbet modeli serisinin en son iterasyonudur.\n\nÇeşitli görevlerde mükemmel performans sergileyen [DeepSeek V3](/deepseek/deepseek-chat-v3) modelini devralmıştır."
  },
  "deepseek/deepseek-chat-v3-0324:free": {
    "description": "DeepSeek V3, 685B parametreye sahip bir uzman karışık modeldir ve DeepSeek ekibinin amiral gemisi sohbet modeli serisinin en son iterasyonudur.\n\nÇeşitli görevlerde mükemmel performans sergileyen [DeepSeek V3](/deepseek/deepseek-chat-v3) modelini devralmıştır."
  },
  "deepseek/deepseek-r1": {
    "description": "DeepSeek-R1, yalnızca çok az etiketli veri ile modelin akıl yürütme yeteneğini büyük ölçüde artırır. Model, nihai yanıtı vermeden önce bir düşünce zinciri içeriği sunarak nihai yanıtın doğruluğunu artırır."
  },
  "deepseek/deepseek-r1-0528": {
    "description": "DeepSeek-R1, çok az etiketli veri ile modelin akıl yürütme yeteneğini büyük ölçüde artırır. Nihai yanıtı vermeden önce, model doğruluğu artırmak için bir düşünce zinciri çıktısı üretir."
  },
  "deepseek/deepseek-r1-0528:free": {
    "description": "DeepSeek-R1, çok az etiketli veri ile modelin akıl yürütme yeteneğini büyük ölçüde artırır. Nihai yanıtı vermeden önce, model doğruluğu artırmak için bir düşünce zinciri çıktısı üretir."
  },
  "deepseek/deepseek-r1-distill-llama-70b": {
    "description": "DeepSeek R1 Distill Llama 70B, Llama3.3 70B tabanlı büyük bir dil modelidir ve DeepSeek R1'in çıktısını kullanarak ince ayar yaparak büyük öncü modellerle rekabet edebilecek bir performans elde etmiştir."
  },
  "deepseek/deepseek-r1-distill-llama-8b": {
    "description": "DeepSeek R1 Distill Llama 8B, Llama-3.1-8B-Instruct tabanlı bir damıtılmış büyük dil modelidir ve DeepSeek R1'in çıktısını kullanarak eğitilmiştir."
  },
  "deepseek/deepseek-r1-distill-qwen-14b": {
    "description": "DeepSeek R1 Distill Qwen 14B, Qwen 2.5 14B tabanlı bir damıtılmış büyük dil modelidir ve DeepSeek R1'in çıktısını kullanarak eğitilmiştir. Bu model, birçok benchmark testinde OpenAI'nin o1-mini'sini geçerek yoğun modellerin (dense models) en son teknik liderlik başarılarını elde etmiştir. İşte bazı benchmark test sonuçları:\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nBu model, DeepSeek R1'in çıktısından ince ayar yaparak daha büyük ölçekli öncü modellerle karşılaştırılabilir bir performans sergilemiştir."
  },
  "deepseek/deepseek-r1-distill-qwen-32b": {
    "description": "DeepSeek R1 Distill Qwen 32B, Qwen 2.5 32B tabanlı bir damıtılmış büyük dil modelidir ve DeepSeek R1'in çıktısını kullanarak eğitilmiştir. Bu model, birçok benchmark testinde OpenAI'nin o1-mini'sini geçerek yoğun modellerin (dense models) en son teknik liderlik başarılarını elde etmiştir. İşte bazı benchmark test sonuçları:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nBu model, DeepSeek R1'in çıktısından ince ayar yaparak daha büyük ölçekli öncü modellerle karşılaştırılabilir bir performans sergilemiştir."
  },
  "deepseek/deepseek-r1/community": {
    "description": "DeepSeek R1, DeepSeek ekibinin yayınladığı en son açık kaynak modelidir ve özellikle matematik, programlama ve akıl yürütme görevlerinde OpenAI'nin o1 modeli ile karşılaştırılabilir bir çıkarım performansına sahiptir."
  },
  "deepseek/deepseek-r1:free": {
    "description": "DeepSeek-R1, yalnızca çok az etiketli veri ile modelin akıl yürütme yeteneğini büyük ölçüde artırır. Model, nihai yanıtı vermeden önce bir düşünce zinciri içeriği sunarak nihai yanıtın doğruluğunu artırır."
  },
  "deepseek/deepseek-v3": {
    "description": "DeepSeek-V3, çıkarım hızında önceki modellere göre önemli bir atılım gerçekleştirmiştir. Açık kaynak modeller arasında birinci sırada yer almakta ve dünya çapındaki en gelişmiş kapalı kaynak modellerle rekabet edebilmektedir. DeepSeek-V3, DeepSeek-V2'de kapsamlı bir şekilde doğrulanan çok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarilerini kullanmaktadır. Ayrıca, DeepSeek-V3, yük dengeleme için yardımcı kayıpsız bir strateji geliştirmiştir ve daha güçlü bir performans elde etmek için çok etiketli tahmin eğitim hedefleri belirlemiştir."
  },
  "deepseek/deepseek-v3/community": {
    "description": "DeepSeek-V3, çıkarım hızında önceki modellere göre önemli bir atılım gerçekleştirmiştir. Açık kaynak modeller arasında birinci sırada yer almakta ve dünya çapındaki en gelişmiş kapalı kaynak modellerle rekabet edebilmektedir. DeepSeek-V3, DeepSeek-V2'de kapsamlı bir şekilde doğrulanan çok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarilerini kullanmaktadır. Ayrıca, DeepSeek-V3, yük dengeleme için yardımcı kayıpsız bir strateji geliştirmiştir ve daha güçlü bir performans elde etmek için çok etiketli tahmin eğitim hedefleri belirlemiştir."
  },
  "deepseek_r1": {
    "description": "DeepSeek-R1, pekiştirme öğrenimi (RL) ile yönlendirilen bir çıkarım modelidir, modeldeki tekrarlama ve okunabilirlik sorunlarını çözmektedir. RL'den önce, DeepSeek-R1, soğuk başlatma verilerini tanıtarak çıkarım performansını daha da optimize etmiştir. Matematik, kod ve çıkarım görevlerinde OpenAI-o1 ile benzer performans sergilemekte ve özenle tasarlanmış eğitim yöntemleri ile genel etkisini artırmaktadır."
  },
  "deepseek_r1_distill_llama_70b": {
    "description": "DeepSeek-R1-Distill-Llama-70B, Llama-3.3-70B-Instruct temel alınarak damıtma eğitimi ile elde edilen bir modeldir. Bu model, DeepSeek-R1 serisinin bir parçasıdır ve DeepSeek-R1 tarafından üretilen örnekler kullanılarak ince ayar yapılmış, matematik, programlama ve çıkarım gibi birçok alanda mükemmel performans sergilemektedir."
  },
  "deepseek_r1_distill_qwen_14b": {
    "description": "DeepSeek-R1-Distill-Qwen-14B, Qwen2.5-14B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından üretilen 800.000 seçkin örnek ile ince ayar yapılmış ve mükemmel çıkarım yetenekleri sergilemektedir."
  },
  "deepseek_r1_distill_qwen_32b": {
    "description": "DeepSeek-R1-Distill-Qwen-32B, Qwen2.5-32B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından üretilen 800.000 seçkin örnek ile ince ayar yapılmış ve matematik, programlama ve çıkarım gibi birçok alanda olağanüstü performans sergilemektedir."
  },
  "doubao-1.5-lite-32k": {
    "description": "Doubao-1.5-lite, tamamen yeni nesil hafif modeldir, olağanüstü yanıt hızı ile etkisi ve gecikmesi dünya standartlarında bir seviyeye ulaşmıştır."
  },
  "doubao-1.5-pro-256k": {
    "description": "Doubao-1.5-pro-256k, Doubao-1.5-Pro'nun kapsamlı bir yükseltmesi olup, genel performans %10 oranında büyük bir artış göstermektedir. 256k bağlam penceresi ile akıl yürütmeyi destekler, çıktı uzunluğu maksimum 12k token'a kadar desteklenmektedir. Daha yüksek performans, daha büyük pencere, yüksek maliyet etkinliği ile daha geniş uygulama alanlarına uygundur."
  },
  "doubao-1.5-pro-32k": {
    "description": "Doubao-1.5-pro, tamamen yeni nesil ana model, performansı tamamen yükseltilmiş olup, bilgi, kod, akıl yürütme gibi alanlarda mükemmel bir performans sergilemektedir."
  },
  "doubao-1.5-thinking-pro": {
    "description": "Doubao-1.5, tamamen yeni bir derin düşünme modeli, matematik, programlama, bilimsel akıl yürütme gibi uzmanlık alanlarında ve yaratıcı yazım gibi genel görevlerde olağanüstü performans sergilemektedir. AIME 2024, Codeforces, GPQA gibi birçok saygın ölçekte sektörün en üst seviyelerine ulaşmakta veya bunlara yakın bir performans göstermektedir. 128k bağlam penceresi ve 16k çıktı desteği sunmaktadır."
  },
  "doubao-1.5-vision-lite": {
    "description": "Doubao-1.5-vision-lite, yeni güncellenmiş çok modlu büyük modeldir, herhangi bir çözünürlük ve aşırı en-boy oranı görüntü tanıma desteği sunar, görsel çıkarım, belge tanıma, detay bilgisi anlama ve talimat takibi yeteneklerini artırır. 128k bağlam penceresi destekler, çıktı uzunluğu maksimum 16k token destekler."
  },
  "doubao-seed-1.6": {
    "description": "Doubao-Seed-1.6, auto/thinking/non-thinking olmak üzere üç düşünme modunu destekleyen tamamen yeni çok modlu derin düşünme modelidir. Non-thinking modunda, model performansı Doubao-1.5-pro/250115'e kıyasla büyük ölçüde artmıştır. 256k bağlam penceresini destekler ve çıktı uzunluğu maksimum 16k token olabilir."
  },
  "doubao-seed-1.6-flash": {
    "description": "Doubao-Seed-1.6-flash, TPOT sadece 10ms olan son derece hızlı çok modlu derin düşünme modelidir; hem metin hem de görsel anlayışı destekler, metin anlama yeteneği önceki lite neslini aşar, görsel anlama ise rakiplerin pro serisi modelleriyle eşdeğerdir. 256k bağlam penceresini destekler ve çıktı uzunluğu maksimum 16k token olabilir."
  },
  "doubao-seed-1.6-thinking": {
    "description": "Doubao-Seed-1.6-thinking modeli düşünme yeteneğinde büyük gelişme göstermiştir; Doubao-1.5-thinking-pro ile karşılaştırıldığında Kodlama, Matematik ve mantıksal akıl yürütme gibi temel yeteneklerde daha da iyileşmiştir ve görsel anlayışı destekler. 256k bağlam penceresini destekler ve çıktı uzunluğu maksimum 16k token olabilir."
  },
  "emohaa": {
    "description": "Emohaa, duygusal sorunları anlamalarına yardımcı olmak için profesyonel danışmanlık yeteneklerine sahip bir psikolojik modeldir."
  },
  "ernie-3.5-128k": {
    "description": "Baidu tarafından geliştirilen amiral gemisi büyük ölçekli dil modeli, geniş bir Çince ve İngilizce veri kümesini kapsar, güçlü genel yeteneklere sahiptir ve çoğu diyalog soru-cevap, yaratım, eklenti uygulama senaryolarını karşılayabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar."
  },
  "ernie-3.5-8k": {
    "description": "Baidu tarafından geliştirilen amiral gemisi büyük ölçekli dil modeli, geniş bir Çince ve İngilizce veri kümesini kapsar, güçlü genel yeteneklere sahiptir ve çoğu diyalog soru-cevap, yaratım, eklenti uygulama senaryolarını karşılayabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar."
  },
  "ernie-3.5-8k-preview": {
    "description": "Baidu tarafından geliştirilen amiral gemisi büyük ölçekli dil modeli, geniş bir Çince ve İngilizce veri kümesini kapsar, güçlü genel yeteneklere sahiptir ve çoğu diyalog soru-cevap, yaratım, eklenti uygulama senaryolarını karşılayabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar."
  },
  "ernie-4.0-8k-latest": {
    "description": "Baidu tarafından geliştirilen amiral gemisi ultra büyük ölçekli dil modeli, ERNIE 3.5'e göre model yeteneklerinde kapsamlı bir yükseltme gerçekleştirmiştir, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar."
  },
  "ernie-4.0-8k-preview": {
    "description": "Baidu tarafından geliştirilen amiral gemisi ultra büyük ölçekli dil modeli, ERNIE 3.5'e göre model yeteneklerinde kapsamlı bir yükseltme gerçekleştirmiştir, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar."
  },
  "ernie-4.0-turbo-128k": {
    "description": "Baidu tarafından geliştirilen amiral gemisi ultra büyük ölçekli dil modeli, genel performansı mükemmel, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar. ERNIE 4.0'a göre performans açısından daha üstündür."
  },
  "ernie-4.0-turbo-8k-latest": {
    "description": "Baidu tarafından geliştirilen amiral gemisi ultra büyük ölçekli dil modeli, genel performansı mükemmel, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar. ERNIE 4.0'a göre performans açısından daha üstündür."
  },
  "ernie-4.0-turbo-8k-preview": {
    "description": "Baidu tarafından geliştirilen amiral gemisi ultra büyük ölçekli dil modeli, genel performansı mükemmel, çeşitli alanlardaki karmaşık görev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyon desteği sunarak soru-cevap bilgilerini güncel tutar. ERNIE 4.0'a göre performans açısından daha üstündür."
  },
  "ernie-4.5-8k-preview": {
    "description": "Wenxin büyük modeli 4.5, Baidu tarafından geliştirilen yeni nesil yerel çok modlu temel büyük modeldir. Birden fazla modun birleşik modellemesi ile işbirlikçi optimizasyon sağlar, çok modlu anlama yeteneği mükemmeldir; dil yetenekleri, anlama, üretim, mantık ve hafıza yetenekleri önemli ölçüde geliştirilmiştir, yanılsamaları ortadan kaldırma, mantıksal akıl yürütme ve kod yetenekleri belirgin şekilde artmıştır."
  },
  "ernie-4.5-turbo-128k": {
    "description": "Wenxin 4.5 Turbo, yanılsamaları giderme, mantıksal akıl yürütme ve kodlama yetenekleri gibi alanlarda belirgin bir artış göstermektedir. Wenxin 4.5 ile karşılaştırıldığında, daha hızlı ve daha düşük maliyetlidir. Modelin yetenekleri genel olarak artırılmıştır, çoklu uzun geçmiş diyalog işleme ve uzun belgeleri anlama görevlerini daha iyi karşılamaktadır."
  },
  "ernie-4.5-turbo-32k": {
    "description": "Wenxin 4.5 Turbo, yanılsamaları giderme, mantıksal akıl yürütme ve kodlama yetenekleri gibi alanlarda belirgin bir artış göstermektedir. Wenxin 4.5 ile karşılaştırıldığında, daha hızlı ve daha düşük maliyetlidir. Metin yaratma, bilgi sorgulama gibi yeteneklerde belirgin bir artış sağlanmıştır. Çıktı uzunluğu ve tam cümle gecikmesi, ERNIE 4.5'e kıyasla artmıştır."
  },
  "ernie-4.5-turbo-vl-32k": {
    "description": "Wenxin Yiyan büyük modelinin yeni versiyonu, görüntü anlama, yaratma, çeviri, kodlama gibi yeteneklerde belirgin bir artış göstermektedir, ilk kez 32K bağlam uzunluğunu desteklemekte ve ilk token gecikmesi belirgin şekilde azaltılmıştır."
  },
  "ernie-char-8k": {
    "description": "Baidu tarafından geliştirilen dikey senaryo büyük dil modeli, oyun NPC'leri, müşteri hizmetleri diyalogları, diyalog karakter rolü gibi uygulama senaryolarına uygundur, karakter tarzı daha belirgin ve tutarlıdır, talimat takibi yeteneği daha güçlü, çıkarım performansı daha iyidir."
  },
  "ernie-char-fiction-8k": {
    "description": "Baidu tarafından geliştirilen dikey senaryo büyük dil modeli, oyun NPC'leri, müşteri hizmetleri diyalogları, diyalog karakter rolü gibi uygulama senaryolarına uygundur, karakter tarzı daha belirgin ve tutarlıdır, talimat takibi yeteneği daha güçlü, çıkarım performansı daha iyidir."
  },
  "ernie-lite-8k": {
    "description": "ERNIE Lite, Baidu tarafından geliştirilen hafif büyük dil modelidir, mükemmel model performansı ve çıkarım yeteneği ile düşük hesaplama gücüne sahip AI hızlandırıcı kartları için uygundur."
  },
  "ernie-lite-pro-128k": {
    "description": "Baidu tarafından geliştirilen hafif büyük dil modeli, mükemmel model performansı ve çıkarım yeteneği ile ERNIE Lite'dan daha iyi sonuçlar verir, düşük hesaplama gücüne sahip AI hızlandırıcı kartları için uygundur."
  },
  "ernie-novel-8k": {
    "description": "Baidu tarafından geliştirilen genel büyük dil modeli, roman devam ettirme yeteneğinde belirgin bir avantaja sahiptir, aynı zamanda kısa oyun, film gibi senaryolarda da kullanılabilir."
  },
  "ernie-speed-128k": {
    "description": "Baidu'nun 2024 yılında yayımladığı en son yüksek performanslı büyük dil modeli, genel yetenekleri mükemmel, belirli senaryo sorunlarını daha iyi ele almak için temel model olarak ince ayar yapılabilir, aynı zamanda mükemmel çıkarım performansına sahiptir."
  },
  "ernie-speed-pro-128k": {
    "description": "Baidu'nun 2024 yılında yayımladığı en son yüksek performanslı büyük dil modeli, genel yetenekleri mükemmel, ERNIE Speed'den daha iyi sonuçlar verir, belirli senaryo sorunlarını daha iyi ele almak için temel model olarak ince ayar yapılabilir, aynı zamanda mükemmel çıkarım performansına sahiptir."
  },
  "ernie-tiny-8k": {
    "description": "ERNIE Tiny, Baidu tarafından geliştirilen ultra yüksek performanslı büyük dil modelidir, dağıtım ve ince ayar maliyetleri Wenxin serisi modelleri arasında en düşüktür."
  },
  "ernie-x1-32k": {
    "description": "Daha güçlü anlama, planlama, düşünme ve evrim yeteneklerine sahiptir. Daha kapsamlı bir derin düşünme modeli olarak, Wenxin X1, doğru, yaratıcı ve edebi bir şekilde, Çince bilgi sorgulama, edebi yaratım, metin yazımı, günlük diyalog, mantıksal akıl yürütme, karmaşık hesaplamalar ve araç çağırma gibi alanlarda özellikle başarılıdır."
  },
  "ernie-x1-32k-preview": {
    "description": "Wenxin Büyük Model X1, daha güçlü anlama, planlama, düşünme ve evrim yeteneklerine sahiptir. Daha kapsamlı bir derin düşünme modeli olarak, Wenxin X1, doğru, yaratıcı ve edebi bir üslup sunarak, Çince bilgi sorgulama, edebi yaratım, metin yazımı, günlük diyalog, mantıksal akıl yürütme, karmaşık hesaplamalar ve araç çağırma gibi alanlarda özellikle başarılıdır."
  },
  "ernie-x1-turbo-32k": {
    "description": "ERNIE-X1-32K ile karşılaştırıldığında, modelin etkisi ve performansı daha iyidir."
  },
  "gemini-1.0-pro-001": {
    "description": "Gemini 1.0 Pro 001 (Tuning), kararlı ve ayarlanabilir bir performans sunar, karmaşık görev çözümleri için ideal bir seçimdir."
  },
  "gemini-1.0-pro-002": {
    "description": "Gemini 1.0 Pro 002 (Tuning), mükemmel çok modlu destek sunar ve karmaşık görevlerin etkili bir şekilde çözülmesine odaklanır."
  },
  "gemini-1.0-pro-latest": {
    "description": "Gemini 1.0 Pro, Google'ın yüksek performanslı AI modelidir ve geniş görev genişletmeleri için tasarlanmıştır."
  },
  "gemini-1.5-flash-001": {
    "description": "Gemini 1.5 Flash 001, geniş uygulama alanları için destekleyen verimli bir çok modlu modeldir."
  },
  "gemini-1.5-flash-002": {
    "description": "Gemini 1.5 Flash 002, geniş uygulama yelpazesini destekleyen verimli bir çok modlu modeldir."
  },
  "gemini-1.5-flash-8b": {
    "description": "Gemini 1.5 Flash 8B, geniş uygulama yelpazesini destekleyen verimli bir çok modlu modeldir."
  },
  "gemini-1.5-flash-8b-exp-0924": {
    "description": "Gemini 1.5 Flash 8B 0924, metin ve çok modlu kullanım durumlarında önemli performans artışları sunan en son deneysel modeldir."
  },
  "gemini-1.5-flash-8b-latest": {
    "description": "Gemini 1.5 Flash 8B, geniş uygulama desteğiyle çoklu modaliteyi destekleyen yüksek verimli bir modeldir."
  },
  "gemini-1.5-flash-exp-0827": {
    "description": "Gemini 1.5 Flash 0827, optimize edilmiş çok modlu işleme yetenekleri sunarak çeşitli karmaşık görev sahnelerine uygundur."
  },
  "gemini-1.5-flash-latest": {
    "description": "Gemini 1.5 Flash, Google'ın en son çok modlu AI modelidir, hızlı işleme yeteneğine sahiptir ve metin, görüntü ve video girişi destekler, çeşitli görevlerin verimli bir şekilde genişletilmesine olanak tanır."
  },
  "gemini-1.5-pro-001": {
    "description": "Gemini 1.5 Pro 001, geniş karmaşık görevleri destekleyen ölçeklenebilir bir çok modlu AI çözümüdür."
  },
  "gemini-1.5-pro-002": {
    "description": "Gemini 1.5 Pro 002, daha yüksek kaliteli çıktılar sunan en son üretim hazır modeldir; özellikle matematik, uzun bağlam ve görsel görevlerde önemli iyileştirmeler sağlamaktadır."
  },
  "gemini-1.5-pro-exp-0801": {
    "description": "Gemini 1.5 Pro 0801, olağanüstü çok modlu işleme yetenekleri sunarak uygulama geliştirmeye daha fazla esneklik getirir."
  },
  "gemini-1.5-pro-exp-0827": {
    "description": "Gemini 1.5 Pro 0827, en son optimize edilmiş teknolojilerle birleştirilmiş daha verimli çok modlu veri işleme yeteneği sunar."
  },
  "gemini-1.5-pro-latest": {
    "description": "Gemini 1.5 Pro, 2 milyon token'a kadar destekler, orta ölçekli çok modlu modeller için ideal bir seçimdir ve karmaşık görevler için çok yönlü destek sunar."
  },
  "gemini-2.0-flash": {
    "description": "Gemini 2.0 Flash, mükemmel hız, yerel araç kullanımı, çok modlu üretim ve 1M token bağlam penceresi dahil olmak üzere bir sonraki nesil özellikler ve iyileştirmeler sunar."
  },
  "gemini-2.0-flash-001": {
    "description": "Gemini 2.0 Flash, mükemmel hız, yerel araç kullanımı, çok modlu üretim ve 1M token bağlam penceresi dahil olmak üzere bir sonraki nesil özellikler ve iyileştirmeler sunar."
  },
  "gemini-2.0-flash-exp": {
    "description": "Gemini 2.0 Flash modeli varyantı, maliyet etkinliği ve düşük gecikme gibi hedefler için optimize edilmiştir."
  },
  "gemini-2.0-flash-exp-image-generation": {
    "description": "Gemini 2.0 Flash deneysel modeli, görüntü oluşturmayı destekler"
  },
  "gemini-2.0-flash-lite": {
    "description": "Gemini 2.0 Flash model varyantı, maliyet etkinliği ve düşük gecikme gibi hedefler için optimize edilmiştir."
  },
  "gemini-2.0-flash-lite-001": {
    "description": "Gemini 2.0 Flash model varyantı, maliyet etkinliği ve düşük gecikme gibi hedefler için optimize edilmiştir."
  },
  "gemini-2.0-flash-preview-image-generation": {
    "description": "Gemini 2.0 Flash önizleme modeli, görüntü üretimini destekler."
  },
  "gemini-2.5-flash": {
    "description": "Gemini 2.5 Flash, Google'ın en yüksek maliyet-performans modelidir ve kapsamlı özellikler sunar."
  },
  "gemini-2.5-flash-lite-preview-06-17": {
    "description": "Gemini 2.5 Flash-Lite Önizlemesi, Google'ın en küçük ve en yüksek maliyet-performans modelidir ve büyük ölçekli kullanım için tasarlanmıştır."
  },
  "gemini-2.5-flash-preview-04-17": {
    "description": "Gemini 2.5 Flash Önizleme, Google'ın en iyi fiyat-performans oranına sahip modelidir ve kapsamlı özellikler sunar."
  },
  "gemini-2.5-flash-preview-04-17-thinking": {
    "description": "Gemini 2.5 Flash Önizleme, Google'ın en yüksek maliyet-performans modelidir ve kapsamlı özellikler sunar."
  },
  "gemini-2.5-flash-preview-05-20": {
    "description": "Gemini 2.5 Flash Önizleme, Google'ın en yüksek maliyet-performans modelidir ve kapsamlı özellikler sunar."
  },
  "gemini-2.5-pro": {
    "description": "Gemini 2.5 Pro, Google'ın en gelişmiş düşünce modelidir; kodlama, matematik ve STEM alanlarındaki karmaşık problemleri çıkarım yapabilir ve uzun bağlam kullanarak büyük veri setleri, kod tabanları ve belgeleri analiz edebilir."
  },
  "gemini-2.5-pro-exp-03-25": {
    "description": "Gemini 2.5 Pro Deneysel, Google'ın en gelişmiş düşünce modeli olup, kod, matematik ve STEM alanlarındaki karmaşık sorunları akıl yürütebilmektedir. Ayrıca, uzun bağlamları kullanarak büyük veri setlerini, kod havuzlarını ve belgeleri analiz edebilir."
  },
  "gemini-2.5-pro-preview-03-25": {
    "description": "Gemini 2.5 Pro Önizleme, Google'ın en gelişmiş düşünce modeli olup, kod, matematik ve STEM alanlarındaki karmaşık sorunları akıl yürütme yeteneğine sahiptir. Uzun bağlamları analiz ederek büyük veri setleri, kod havuzları ve belgeler üzerinde çalışabilir."
  },
  "gemini-2.5-pro-preview-05-06": {
    "description": "Gemini 2.5 Pro Önizleme, Google'ın en gelişmiş düşünce modelidir ve kod, matematik ve STEM alanlarındaki karmaşık sorunları akıl yürütme yeteneğine sahiptir. Uzun bağlamları analiz ederek büyük veri setleri, kod havuzları ve belgeler üzerinde çalışabilir."
  },
  "gemini-2.5-pro-preview-06-05": {
    "description": "Gemini 2.5 Pro Önizlemesi, Google'ın en gelişmiş düşünce modelidir; kodlama, matematik ve STEM alanlarındaki karmaşık problemleri çözebilir ve uzun bağlam kullanarak büyük veri setleri, kod kütüphaneleri ve belgeleri analiz edebilir."
  },
  "gemma-7b-it": {
    "description": "Gemma 7B, orta ölçekli görev işleme için uygundur ve maliyet etkinliği sunar."
  },
  "gemma2": {
    "description": "Gemma 2, Google tarafından sunulan verimli bir modeldir, küçük uygulamalardan karmaşık veri işleme senaryolarına kadar çeşitli uygulama alanlarını kapsar."
  },
  "gemma2-9b-it": {
    "description": "Gemma 2 9B, belirli görevler ve araç entegrasyonu için optimize edilmiş bir modeldir."
  },
  "gemma2:27b": {
    "description": "Gemma 2, Google tarafından sunulan verimli bir modeldir, küçük uygulamalardan karmaşık veri işleme senaryolarına kadar çeşitli uygulama alanlarını kapsar."
  },
  "gemma2:2b": {
    "description": "Gemma 2, Google tarafından sunulan verimli bir modeldir, küçük uygulamalardan karmaşık veri işleme senaryolarına kadar çeşitli uygulama alanlarını kapsar."
  },
  "generalv3": {
    "description": "Spark Pro, profesyonel alanlar için optimize edilmiş yüksek performanslı büyük dil modelidir, matematik, programlama, sağlık, eğitim gibi birçok alana odaklanır ve çevrimiçi arama ile yerleşik hava durumu, tarih gibi eklentileri destekler. Optimize edilmiş modeli, karmaşık bilgi sorgulama, dil anlama ve yüksek düzeyde metin oluşturma konularında mükemmel performans ve yüksek verimlilik sergiler, profesyonel uygulama senaryoları için ideal bir seçimdir."
  },
  "generalv3.5": {
    "description": "Spark3.5 Max, en kapsamlı özelliklere sahip versiyondur, çevrimiçi arama ve birçok yerleşik eklentiyi destekler. Kapsamlı optimize edilmiş temel yetenekleri ve sistem rol ayarları ile fonksiyon çağırma özellikleri, çeşitli karmaşık uygulama senaryolarında son derece mükemmel ve olağanüstü performans sergiler."
  },
  "glm-4": {
    "description": "GLM-4, Ocak 2024'te piyasaya sürülen eski amiral gemisi versiyonudur, şu anda daha güçlü GLM-4-0520 ile değiştirilmiştir."
  },
  "glm-4-0520": {
    "description": "GLM-4-0520, son derece karmaşık ve çeşitli görevler için tasarlanmış en yeni model versiyonudur, olağanüstü performans sergiler."
  },
  "glm-4-9b-chat": {
    "description": "GLM-4-9B-Chat, anlam, matematik, akıl yürütme, kod ve bilgi gibi birçok alanda yüksek performans göstermektedir. Ayrıca web tarayıcı, kod yürütme, özel araç çağrıları ve uzun metin akıl yürütme yeteneklerine sahiptir. Japonca, Korece, Almanca dahil olmak üzere 26 dil desteği sunmaktadır."
  },
  "glm-4-air": {
    "description": "GLM-4-Air, maliyet etkin bir versiyondur, GLM-4'e yakın performans sunar ve hızlı hız ve uygun fiyat sağlar."
  },
  "glm-4-air-250414": {
    "description": "GLM-4-Air, maliyet açısından yüksek verimlilik sunan bir versiyondur, GLM-4'e yakın performans sunar, hızlı hız ve uygun fiyat sağlar."
  },
  "glm-4-airx": {
    "description": "GLM-4-AirX, GLM-4-Air'ın verimli bir versiyonunu sunar, çıkarım hızı 2.6 katına kadar çıkabilir."
  },
  "glm-4-alltools": {
    "description": "GLM-4-AllTools, karmaşık talimat planlaması ve araç çağrıları gibi çok işlevli görevleri desteklemek için optimize edilmiş bir akıllı modeldir. İnternet tarayıcıları, kod açıklamaları ve metin üretimi gibi çoklu görevleri yerine getirmek için uygundur."
  },
  "glm-4-flash": {
    "description": "GLM-4-Flash, basit görevleri işlemek için ideal bir seçimdir, en hızlı ve en uygun fiyatlıdır."
  },
  "glm-4-flash-250414": {
    "description": "GLM-4-Flash, basit görevler için ideal bir seçimdir, en hızlı ve ücretsizdir."
  },
  "glm-4-flashx": {
    "description": "GLM-4-FlashX, Flash'ın geliştirilmiş bir versiyonudur ve ultra hızlı çıkarım hızı sunar."
  },
  "glm-4-long": {
    "description": "GLM-4-Long, ultra uzun metin girişlerini destekler, bellek tabanlı görevler ve büyük ölçekli belge işleme için uygundur."
  },
  "glm-4-plus": {
    "description": "GLM-4-Plus, güçlü uzun metin işleme ve karmaşık görevler için yeteneklere sahip yüksek akıllı bir amiral gemisidir, performansı tamamen artırılmıştır."
  },
  "glm-4v": {
    "description": "GLM-4V, güçlü görüntü anlama ve akıl yürütme yetenekleri sunar, çeşitli görsel görevleri destekler."
  },
  "glm-4v-flash": {
    "description": "GLM-4V-Flash, hızlı görsel analiz veya toplu görsel işleme gibi sahnelerde, tek bir görüntü anlayışına odaklanarak etkili bir performans sunar."
  },
  "glm-4v-plus": {
    "description": "GLM-4V-Plus, video içeriği ve çoklu görüntüleri anlama yeteneğine sahiptir, çok modlu görevler için uygundur."
  },
  "glm-4v-plus-0111": {
    "description": "GLM-4V-Plus, video içeriği ve çoklu görüntüleri anlama yeteneğine sahiptir, çok modlu görevler için uygundur."
  },
  "glm-z1-air": {
    "description": "Çıkarım modeli: Güçlü çıkarım yeteneklerine sahiptir, derin çıkarım gerektiren görevler için uygundur."
  },
  "glm-z1-airx": {
    "description": "Hızlı çıkarım: Süper hızlı çıkarım hızı ve güçlü çıkarım etkisi sunar."
  },
  "glm-z1-flash": {
    "description": "GLM-Z1 serisi, karmaşık çıkarım yeteneklerine sahiptir, mantıksal çıkarım, matematik, programlama gibi alanlarda mükemmel performans gösterir. Maksimum bağlam uzunluğu 32K'dır."
  },
  "glm-zero-preview": {
    "description": "GLM-Zero-Preview, karmaşık akıl yürütme yeteneklerine sahip olup, mantıksal akıl yürütme, matematik, programlama gibi alanlarda mükemmel performans sergilemektedir."
  },
  "google/gemini-2.0-flash-001": {
    "description": "Gemini 2.0 Flash, mükemmel hız, yerel araç kullanımı, çok modlu üretim ve 1M token bağlam penceresi dahil olmak üzere bir sonraki nesil özellikler ve iyileştirmeler sunar."
  },
  "google/gemini-2.0-flash-exp:free": {
    "description": "Gemini 2.0 Flash Deneysel, Google'ın en yeni deneysel çok modlu AI modelidir ve önceki sürümlere göre belirli bir kalite artışı sağlamaktadır, özellikle dünya bilgisi, kod ve uzun bağlam için."
  },
  "google/gemini-2.5-flash": {
    "description": "Gemini 2.5 Flash, Google'ın en gelişmiş ana modeli olup, ileri düzey akıl yürütme, kodlama, matematik ve bilimsel görevler için tasarlanmıştır. Yerleşik \"düşünme\" yeteneği sayesinde, daha yüksek doğruluk ve ayrıntılı bağlam işleme ile yanıtlar sunabilir.\n\nNot: Bu modelin iki varyantı vardır: düşünme ve düşünmeme. Çıktı fiyatlandırması, düşünme yeteneğinin etkin olup olmamasına göre önemli ölçüde farklılık gösterir. Standart varyantı (\" :thinking\" eki olmayan) seçerseniz, model düşünme tokenları üretmekten açıkça kaçınır.\n\nDüşünme yeteneğinden yararlanmak ve düşünme tokenları almak için \" :thinking\" varyantını seçmeniz gerekir; bu, daha yüksek bir düşünme çıktı fiyatlandırmasıyla sonuçlanır.\n\nAyrıca, Gemini 2.5 Flash, belgelerde belirtildiği gibi (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning) \"maksimum akıl yürütme token sayısı\" parametresi ile yapılandırılabilir."
  },
  "google/gemini-2.5-flash-preview": {
    "description": "Gemini 2.5 Flash, Google'ın en gelişmiş ana modelidir ve ileri düzey akıl yürütme, kodlama, matematik ve bilimsel görevler için tasarlanmıştır. Daha yüksek doğruluk ve ayrıntılı bağlam işleme ile yanıtlar sunabilen yerleşik 'düşünme' yeteneğine sahiptir.\n\nNot: Bu modelin iki varyantı vardır: düşünme ve düşünmeme. Çıktı fiyatlandırması, düşünme yeteneğinin etkin olup olmamasına göre önemli ölçüde farklılık gösterir. Standart varyantı (':thinking' eki olmadan) seçerseniz, model açıkça düşünme tokenleri üretmekten kaçınacaktır.\n\nDüşünme yeteneğinden yararlanmak ve düşünme tokenleri almak için, ':thinking' varyantını seçmelisiniz; bu, daha yüksek düşünme çıktı fiyatlandırması ile sonuçlanacaktır.\n\nAyrıca, Gemini 2.5 Flash, belgede belirtildiği gibi 'akıl yürütme maksimum token sayısı' parametresi ile yapılandırılabilir (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."
  },
  "google/gemini-2.5-flash-preview:thinking": {
    "description": "Gemini 2.5 Flash, Google'ın en gelişmiş ana modelidir ve ileri düzey akıl yürütme, kodlama, matematik ve bilimsel görevler için tasarlanmıştır. Daha yüksek doğruluk ve ayrıntılı bağlam işleme ile yanıtlar sunabilen yerleşik 'düşünme' yeteneğine sahiptir.\n\nNot: Bu modelin iki varyantı vardır: düşünme ve düşünmeme. Çıktı fiyatlandırması, düşünme yeteneğinin etkin olup olmamasına göre önemli ölçüde farklılık gösterir. Standart varyantı (':thinking' eki olmadan) seçerseniz, model açıkça düşünme tokenleri üretmekten kaçınacaktır.\n\nDüşünme yeteneğinden yararlanmak ve düşünme tokenleri almak için, ':thinking' varyantını seçmelisiniz; bu, daha yüksek düşünme çıktı fiyatlandırması ile sonuçlanacaktır.\n\nAyrıca, Gemini 2.5 Flash, belgede belirtildiği gibi 'akıl yürütme maksimum token sayısı' parametresi ile yapılandırılabilir (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."
  },
  "google/gemini-2.5-pro": {
    "description": "Gemini 2.5 Pro, Google'ın en gelişmiş düşünme modeli olup, kodlama, matematik ve STEM alanlarındaki karmaşık sorunları akıl yürütebilir ve uzun bağlam kullanarak büyük veri setleri, kod tabanları ve belgeleri analiz edebilir."
  },
  "google/gemini-2.5-pro-preview": {
    "description": "Gemini 2.5 Pro Önizlemesi, Google'ın en gelişmiş düşünce modeli olup, kodlama, matematik ve STEM alanlarındaki karmaşık sorunları çözme yeteneğine sahiptir ve uzun bağlam kullanarak büyük veri setleri, kod tabanları ve belgeleri analiz edebilir."
  },
  "google/gemini-flash-1.5": {
    "description": "Gemini 1.5 Flash, optimize edilmiş çok modlu işleme yetenekleri sunar ve çeşitli karmaşık görev senaryolarına uygundur."
  },
  "google/gemini-pro-1.5": {
    "description": "Gemini 1.5 Pro, en son optimize edilmiş teknolojileri birleştirerek daha verimli çok modlu veri işleme yetenekleri sunar."
  },
  "google/gemma-2-27b": {
    "description": "Gemma 2, Google tarafından sunulan verimli bir modeldir, küçük uygulamalardan karmaşık veri işleme senaryolarına kadar çeşitli uygulama alanlarını kapsar."
  },
  "google/gemma-2-27b-it": {
    "description": "Gemma 2, hafiflik ve verimlilik tasarım felsefesini sürdürmektedir."
  },
  "google/gemma-2-2b-it": {
    "description": "Google'ın hafif talimat ayarlama modeli"
  },
  "google/gemma-2-9b": {
    "description": "Gemma 2, Google tarafından sunulan verimli bir modeldir, küçük uygulamalardan karmaşık veri işleme senaryolarına kadar çeşitli uygulama alanlarını kapsar."
  },
  "google/gemma-2-9b-it": {
    "description": "Gemma 2, Google'ın hafif açık kaynak metin modeli serisidir."
  },
  "google/gemma-2-9b-it:free": {
    "description": "Gemma 2, Google'ın hafif açık kaynak metin modeli serisidir."
  },
  "google/gemma-2b-it": {
    "description": "Gemma Instruct (2B), temel talimat işleme yetenekleri sunar ve hafif uygulamalar için uygundur."
  },
  "google/gemma-3-27b-it": {
    "description": "Gemma 3 27B, Google'ın verimlilik ve performans açısından yeni standartlar belirleyen açık kaynaklı bir dil modelidir."
  },
  "gpt-3.5-turbo": {
    "description": "GPT 3.5 Turbo, çeşitli metin üretimi ve anlama görevleri için uygundur, şu anda gpt-3.5-turbo-0125'e işaret ediyor."
  },
  "gpt-3.5-turbo-0125": {
    "description": "GPT 3.5 Turbo, çeşitli metin üretimi ve anlama görevleri için uygundur, şu anda gpt-3.5-turbo-0125'e işaret ediyor."
  },
  "gpt-3.5-turbo-1106": {
    "description": "GPT 3.5 Turbo, çeşitli metin üretimi ve anlama görevleri için uygundur, şu anda gpt-3.5-turbo-0125'e işaret ediyor."
  },
  "gpt-3.5-turbo-instruct": {
    "description": "GPT 3.5 Turbo, çeşitli metin üretimi ve anlama görevleri için uygundur, şu anda gpt-3.5-turbo-0125'e işaret ediyor."
  },
  "gpt-35-turbo": {
    "description": "GPT 3.5 Turbo, OpenAI tarafından sağlanan verimli bir modeldir ve sohbet ve metin üretim görevleri için uygundur, paralel fonksiyon çağrılarını destekler."
  },
  "gpt-35-turbo-16k": {
    "description": "GPT 3.5 Turbo 16k, karmaşık görevler için uygun yüksek kapasiteli bir metin üretim modelidir."
  },
  "gpt-4": {
    "description": "GPT-4, daha büyük bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar için uygundur."
  },
  "gpt-4-0125-preview": {
    "description": "En son GPT-4 Turbo modeli görsel işlevselliğe sahiptir. Artık görsel talepler JSON formatı ve fonksiyon çağrıları ile işlenebilir. GPT-4 Turbo, çok modlu görevler için maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, gerçek zamanlı etkileşim gerektiren uygulama senaryoları için uygundur."
  },
  "gpt-4-0613": {
    "description": "GPT-4, daha büyük bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar için uygundur."
  },
  "gpt-4-1106-preview": {
    "description": "En son GPT-4 Turbo modeli görsel işlevselliğe sahiptir. Artık görsel talepler JSON formatı ve fonksiyon çağrıları ile işlenebilir. GPT-4 Turbo, çok modlu görevler için maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, gerçek zamanlı etkileşim gerektiren uygulama senaryoları için uygundur."
  },
  "gpt-4-32k": {
    "description": "GPT-4, daha büyük bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar için uygundur."
  },
  "gpt-4-32k-0613": {
    "description": "GPT-4, daha büyük bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar için uygundur."
  },
  "gpt-4-turbo": {
    "description": "En son GPT-4 Turbo modeli görsel işlevselliğe sahiptir. Artık görsel talepler JSON formatı ve fonksiyon çağrıları ile işlenebilir. GPT-4 Turbo, çok modlu görevler için maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, gerçek zamanlı etkileşim gerektiren uygulama senaryoları için uygundur."
  },
  "gpt-4-turbo-2024-04-09": {
    "description": "En son GPT-4 Turbo modeli görsel işlevselliğe sahiptir. Artık görsel talepler JSON formatı ve fonksiyon çağrıları ile işlenebilir. GPT-4 Turbo, çok modlu görevler için maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, gerçek zamanlı etkileşim gerektiren uygulama senaryoları için uygundur."
  },
  "gpt-4-turbo-preview": {
    "description": "En son GPT-4 Turbo modeli görsel işlevselliğe sahiptir. Artık görsel talepler JSON formatı ve fonksiyon çağrıları ile işlenebilir. GPT-4 Turbo, çok modlu görevler için maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, gerçek zamanlı etkileşim gerektiren uygulama senaryoları için uygundur."
  },
  "gpt-4-vision-preview": {
    "description": "En son GPT-4 Turbo modeli görsel işlevselliğe sahiptir. Artık görsel talepler JSON formatı ve fonksiyon çağrıları ile işlenebilir. GPT-4 Turbo, çok modlu görevler için maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, gerçek zamanlı etkileşim gerektiren uygulama senaryoları için uygundur."
  },
  "gpt-4.1": {
    "description": "GPT-4.1, karmaşık görevler için kullandığımız amiral gemisi modelidir. Farklı alanlarda sorunları çözmek için son derece uygundur."
  },
  "gpt-4.1-mini": {
    "description": "GPT-4.1 mini, zeka, hız ve maliyet arasında bir denge sunarak birçok kullanım durumu için çekici bir model haline getirir."
  },
  "gpt-4.1-nano": {
    "description": "GPT-4.1 mini, zeka, hız ve maliyet arasında bir denge sunarak birçok kullanım durumu için çekici bir model haline getirir."
  },
  "gpt-4.5-preview": {
    "description": "GPT-4.5'in araştırma önizleme sürümü, şimdiye kadar geliştirdiğimiz en büyük ve en güçlü GPT modelidir. Geniş bir dünya bilgisine sahip olup, kullanıcı niyetlerini daha iyi anlayarak yaratıcı görevler ve bağımsız planlama konularında mükemmel bir performans sergilemektedir. GPT-4.5, metin ve görsel girdi alabilir ve metin çıktısı (yapılandırılmış çıktı dahil) üretebilir. Fonksiyon çağrıları, toplu API ve akış çıktısı gibi önemli geliştirici özelliklerini destekler. Yaratıcılık, açık düşünme ve diyalog gerektiren görevlerde (örneğin yazma, öğrenme veya yeni fikirler keşfetme) GPT-4.5 özellikle başarılıdır. Bilgi kesim tarihi Ekim 2023'tür."
  },
  "gpt-4o": {
    "description": "ChatGPT-4o, güncel versiyonunu korumak için gerçek zamanlı olarak güncellenen dinamik bir modeldir. Güçlü dil anlama ve üretme yeteneklerini birleştirir, müşteri hizmetleri, eğitim ve teknik destek gibi geniş ölçekli uygulama senaryoları için uygundur."
  },
  "gpt-4o-2024-05-13": {
    "description": "ChatGPT-4o, güncel versiyonunu korumak için gerçek zamanlı olarak güncellenen dinamik bir modeldir. Güçlü dil anlama ve üretme yeteneklerini birleştirir, müşteri hizmetleri, eğitim ve teknik destek gibi geniş ölçekli uygulama senaryoları için uygundur."
  },
  "gpt-4o-2024-08-06": {
    "description": "ChatGPT-4o, güncel versiyonunu korumak için gerçek zamanlı olarak güncellenen dinamik bir modeldir. Güçlü dil anlama ve üretme yeteneklerini birleştirir, müşteri hizmetleri, eğitim ve teknik destek gibi geniş ölçekli uygulama senaryoları için uygundur."
  },
  "gpt-4o-2024-11-20": {
    "description": "ChatGPT-4o, güncel en son sürümü korumak için gerçek zamanlı olarak güncellenen dinamik bir modeldir. Müşteri hizmetleri, eğitim ve teknik destek gibi büyük ölçekli uygulama senaryoları için güçlü dil anlama ve üretme yeteneklerini bir araya getirir."
  },
  "gpt-4o-audio-preview": {
    "description": "GPT-4o Ses modeli, sesli giriş ve çıkış desteği sunar."
  },
  "gpt-4o-mini": {
    "description": "GPT-4o mini, OpenAI'nin GPT-4 Omni'den sonra tanıttığı en yeni modeldir. Görsel ve metin girişi destekler ve metin çıktısı verir. En gelişmiş küçük model olarak, diğer son zamanlardaki öncü modellere göre çok daha ucuzdur ve GPT-3.5 Turbo'dan %60'tan fazla daha ucuzdur. En son teknolojiyi korurken, önemli bir maliyet etkinliği sunar. GPT-4o mini, MMLU testinde %82 puan almış olup, şu anda sohbet tercihleri açısından GPT-4'ün üzerinde yer almaktadır."
  },
  "gpt-4o-mini-audio-preview": {
    "description": "GPT-4o mini Ses modeli, ses giriş ve çıkışını destekler."
  },
  "gpt-4o-mini-realtime-preview": {
    "description": "GPT-4o-mini gerçek zamanlı versiyonu, ses ve metin için gerçek zamanlı giriş ve çıkış desteği sunar."
  },
  "gpt-4o-mini-search-preview": {
    "description": "GPT-4o mini arama önizleme sürümü, web arama sorgularını anlama ve yürütme için özel olarak eğitilmiş bir modeldir ve Chat Completions API kullanır. Jeton ücretlerinin yanı sıra, web arama sorguları her araç çağrısı başına ücretlendirilir."
  },
  "gpt-4o-mini-tts": {
    "description": "GPT-4o mini TTS, GPT-4o mini'ye dayalı bir metin-ses modeldir ve yüksek kaliteli ses üretimi, düşük maliyetli oluşturma sunar."
  },
  "gpt-4o-realtime-preview": {
    "description": "GPT-4o gerçek zamanlı versiyonu, ses ve metin için gerçek zamanlı giriş ve çıkış desteği sunar."
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "description": "GPT-4o gerçek zamanlı versiyonu, ses ve metin için gerçek zamanlı giriş ve çıkış desteği sunar."
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    "description": "GPT-4o gerçek zamanlı versiyonu, ses ve metin için gerçek zamanlı giriş ve çıkış desteği sunar."
  },
  "gpt-4o-search-preview": {
    "description": "GPT-4o arama önizleme sürümü, web arama sorgularını anlama ve yürütme için özel olarak eğitilmiş bir modeldir ve Chat Completions API kullanır. Jeton ücretlerinin yanı sıra, web arama sorguları her araç çağrısı başına ücretlendirilir."
  },
  "grok-2-1212": {
    "description": "Bu model, doğruluk, talimat takibi ve çok dilli yetenekler açısından geliştirilmiştir."
  },
  "grok-2-vision-1212": {
    "description": "Bu model, doğruluk, talimat takibi ve çok dilli yetenekler açısından geliştirilmiştir."
  },
  "grok-3": {
    "description": "Amiral gemisi model olup, veri çıkarımı, programlama ve metin özetleme gibi kurumsal uygulamalarda uzmandır; finans, sağlık, hukuk ve bilim alanlarında derin bilgiye sahiptir."
  },
  "grok-3-fast": {
    "description": "Amiral gemisi model olup, veri çıkarımı, programlama ve metin özetleme gibi kurumsal uygulamalarda uzmandır; finans, sağlık, hukuk ve bilim alanlarında derin bilgiye sahiptir."
  },
  "grok-3-mini": {
    "description": "Hafif model olup, konuşma öncesi düşünür. Hızlı ve akıllı çalışır, derin alan bilgisi gerektirmeyen mantıksal görevler için uygundur ve orijinal düşünce izlerini elde edebilir."
  },
  "grok-3-mini-fast": {
    "description": "Hafif model olup, konuşma öncesi düşünür. Hızlı ve akıllı çalışır, derin alan bilgisi gerektirmeyen mantıksal görevler için uygundur ve orijinal düşünce izlerini elde edebilir."
  },
  "gryphe/mythomax-l2-13b": {
    "description": "MythoMax l2 13B, birden fazla üst düzey modelin birleşimiyle yaratıcı ve zeka odaklı bir dil modelidir."
  },
  "hunyuan-code": {
    "description": "Hunyuan'ın en son kod oluşturma modeli, 200B yüksek kaliteli kod verisi ile artırılmış temel model ile altı ay boyunca yüksek kaliteli SFT verisi eğitimi almıştır. Bağlam penceresi uzunluğu 8K'ya çıkarılmıştır ve beş büyük dil için kod oluşturma otomatik değerlendirme göstergelerinde ön sıralardadır; beş büyük dilde 10 kriterin her yönüyle yüksek kaliteli değerlendirmelerde performansı birinci sıradadır."
  },
  "hunyuan-functioncall": {
    "description": "Hunyuan'ın en son MOE mimarisi FunctionCall modeli, yüksek kaliteli FunctionCall verisi ile eğitilmiş olup, bağlam penceresi 32K'ya ulaşmıştır ve birçok boyutta değerlendirme göstergelerinde lider konumdadır."
  },
  "hunyuan-large": {
    "description": "Hunyuan-large modelinin toplam parametre sayısı yaklaşık 389B, etkin parametre sayısı yaklaşık 52B'dir; bu, mevcut endüstrideki en büyük parametre ölçeğine sahip ve en iyi performansı gösteren Transformer mimarisinin açık kaynaklı MoE modelidir."
  },
  "hunyuan-large-longcontext": {
    "description": "Uzun metin görevlerini, örneğin belge özeti ve belge sorgulama gibi, işleme konusunda uzmandır; aynı zamanda genel metin oluşturma görevlerini de yerine getirme yeteneğine sahiptir. Uzun metinlerin analizi ve oluşturulmasında mükemmel bir performans sergiler, karmaşık ve ayrıntılı uzun metin içerik işleme ihtiyaçlarına etkili bir şekilde yanıt verebilir."
  },
  "hunyuan-large-vision": {
    "description": "Bu model, görsel ve metin anlama senaryoları için uygundur. Hunyuan Large tabanlı görsel-dil büyük modelidir, herhangi bir çözünürlükte çoklu resim ve metin girişini destekler, metin üretir, görsel-metinsel anlama görevlerine odaklanır ve çok dilli görsel-metinsel anlama yeteneğinde belirgin gelişme sağlar."
  },
  "hunyuan-lite": {
    "description": "MOE yapısına yükseltilmiş, bağlam penceresi 256k, NLP, kod, matematik, endüstri gibi birçok değerlendirme setinde birçok açık kaynak modelden önde."
  },
  "hunyuan-lite-vision": {
    "description": "Hunyuan'ın en son 7B çok modlu modeli, bağlam penceresi 32K, Çince ve İngilizce senaryolarında çok modlu diyalog, görüntü nesne tanıma, belge tablo anlama, çok modlu matematik vb. destekler; birçok boyutta değerlendirme kriterleri 7B rakip modellerden üstündür."
  },
  "hunyuan-pro": {
    "description": "Trilyon seviyesinde parametre ölçeğine sahip MOE-32K uzun metin modeli. Çeşitli benchmarklarda kesin bir liderlik seviyesine ulaşarak, karmaşık talimatlar ve akıl yürütme yetenekleri ile karmaşık matematik yetenekleri sunar, functioncall desteği ile çok dilli çeviri, finans, hukuk ve sağlık gibi alanlarda önemli optimizasyonlar sağlar."
  },
  "hunyuan-role": {
    "description": "Hunyuan'ın en son rol yapma modeli, Hunyuan resmi ince ayar eğitimi ile geliştirilmiş rol yapma modelidir. Hunyuan modeli ile rol yapma senaryosu veri seti birleştirilerek artırılmıştır ve rol yapma senaryolarında daha iyi temel performans sunmaktadır."
  },
  "hunyuan-standard": {
    "description": "Daha iyi bir yönlendirme stratejisi kullanarak, yük dengeleme ve uzman yakınsaması sorunlarını hafifletir. Uzun metinlerde, iğne arama göstergesi %99.9'a ulaşmaktadır. MOE-32K, uzun metin girişlerini işleme yeteneği ile etki ve fiyat dengesini sağlarken, maliyet açısından daha yüksek bir değer sunar."
  },
  "hunyuan-standard-256K": {
    "description": "Daha iyi bir yönlendirme stratejisi kullanarak, yük dengeleme ve uzman yakınsaması sorunlarını hafifletir. Uzun metinlerde, iğne arama göstergesi %99.9'a ulaşmaktadır. MOE-256K, uzunluk ve etki açısından daha fazla bir sıçrama yaparak, girdi uzunluğunu büyük ölçüde genişletir."
  },
  "hunyuan-standard-vision": {
    "description": "Hunyuan'ın en son çok modlu modeli, çok dilli yanıtları destekler, Çince ve İngilizce yetenekleri dengelidir."
  },
  "hunyuan-t1-20250321": {
    "description": "Modelin hem fen hem de sosyal bilimler alanındaki yeteneklerini kapsamlı bir şekilde inşa eder, uzun metin bilgilerini yakalama yeteneği yüksektir. Her türlü zorluktaki matematik/ mantık çıkarımı/ bilim/ kod gibi bilimsel sorunları çözme yeteneğini destekler."
  },
  "hunyuan-t1-20250403": {
    "description": "Proje düzeyinde kod üretme yeteneğini artırır; metin oluşturma ve yazma kalitesini yükseltir; metin anlama, çok turlu konu takibi, toB komut uyumu ve kelime-anlama yeteneklerini geliştirir; karmaşık geleneksel ve basitleştirilmiş Çince ile İngilizce karışık çıktı sorunlarını optimize eder."
  },
  "hunyuan-t1-20250529": {
    "description": "Metin oluşturma ve kompozisyon yazımını optimize eder; kod ön yüzü, matematik, mantıksal çıkarım gibi fen bilimleri yeteneklerini geliştirir ve talimatlara uyum yeteneğini artırır."
  },
  "hunyuan-t1-latest": {
    "description": "Sektördeki ilk ultra büyük ölçekli Hybrid-Transformer-Mamba çıkarım modeli, çıkarım yeteneklerini genişletir, yüksek çözümleme hızı sunar ve insan tercihleri ile daha iyi hizalanır."
  },
  "hunyuan-t1-vision": {
    "description": "Hunyuan çok modlu anlayış derin düşünme modeli, çok modlu doğal uzun düşünce zincirini destekler, çeşitli görsel çıkarım senaryolarında uzmandır ve fen bilimleri problemlerinde hızlı düşünme modellerine kıyasla kapsamlı iyileşme sağlar."
  },
  "hunyuan-turbo": {
    "description": "Hunyuan'ın yeni nesil büyük dil modelinin önizleme sürümü, tamamen yeni bir karma uzman modeli (MoE) yapısı kullanır ve hunyuan-pro'ya kıyasla daha hızlı çıkarım verimliliği ve daha güçlü performans sunar."
  },
  "hunyuan-turbo-20241223": {
    "description": "Bu sürümde yapılan optimizasyonlar: veri talimatı ölçeklendirme, modelin genel genelleme yeteneğini büyük ölçüde artırma; matematik, kodlama, mantıksal akıl yürütme yeteneklerini büyük ölçüde artırma; metin anlama ve kelime anlama ile ilgili yetenekleri optimize etme; metin oluşturma içerik üretim kalitesini optimize etme."
  },
  "hunyuan-turbo-latest": {
    "description": "Genel deneyim optimizasyonu, NLP anlama, metin oluşturma, sohbet, bilgi sorgulama, çeviri, alan vb. dahil; insan benzeri özellikleri artırma, modelin duygusal zekasını optimize etme; niyet belirsiz olduğunda modelin aktif olarak netleştirme yeteneğini artırma; kelime ve terim analizi ile ilgili sorunların işlenme yeteneğini artırma; yaratım kalitesini ve etkileşimliğini artırma; çoklu tur deneyimini geliştirme."
  },
  "hunyuan-turbo-vision": {
    "description": "Hunyuan'ın yeni nesil görsel dil amiral modeli, tamamen yeni bir karışık uzman modeli (MoE) yapısını benimser; metin ve görüntü anlama ile ilgili temel tanıma, içerik oluşturma, bilgi sorgulama, analiz ve akıl yürütme gibi yeteneklerde bir önceki nesil modele göre kapsamlı bir iyileştirme sağlar."
  },
  "hunyuan-turbos-20250313": {
    "description": "Matematik problem çözme adımlarının stilini birleştirir, matematikte çok turlu soru-cevapları güçlendirir. Metin oluşturma, yanıt stilini optimize eder, yapay zeka izlerini kaldırır, edebi ifadeyi artırır."
  },
  "hunyuan-turbos-20250416": {
    "description": "Ön eğitim tabanı yükseltmesi, tabanın komut anlama ve uyum yeteneklerini güçlendirir; hizalama aşamasında matematik, kodlama, mantık ve bilimsel alanlardaki yetenekleri artırır; yaratıcı yazım kalitesi, metin anlama, çeviri doğruluğu ve bilgi tabanlı soru-cevap gibi beşeri bilimler yeteneklerini geliştirir; çeşitli alanlardaki ajan yeteneklerini güçlendirir, özellikle çok turlu diyalog anlama yeteneğine odaklanır."
  },
  "hunyuan-turbos-20250604": {
    "description": "Ön eğitim tabanı yükseltildi; yazma ve okuduğunu anlama yetenekleri geliştirildi; kodlama ve fen bilimleri yeteneklerinde önemli iyileştirmeler sağlandı; karmaşık talimatlara uyum gibi alanlarda sürekli gelişme devam ediyor."
  },
  "hunyuan-turbos-latest": {
    "description": "hunyuan-TurboS, daha güçlü düşünme yeteneği ve daha iyi deneyim sunan en son sürümüdür."
  },
  "hunyuan-turbos-longtext-128k-20250325": {
    "description": "Uzun metin görevlerini, örneğin belge özetleme ve belge yanıtları gibi, işleme konusunda uzmandır ve genel metin oluşturma görevlerini de yerine getirebilir. Uzun metinlerin analizi ve oluşturulmasında mükemmel performans gösterir, karmaşık ve ayrıntılı uzun metin içerik işleme ihtiyaçlarını etkili bir şekilde karşılar."
  },
  "hunyuan-turbos-role-plus": {
    "description": "Hunyuan'ın en son rol yapma modeli, Hunyuan tarafından resmi olarak ince ayar ve eğitimle geliştirilmiş, rol yapma senaryoları veri setiyle artırılmıştır ve rol yapma senaryolarında daha iyi temel performans sunar."
  },
  "hunyuan-vision": {
    "description": "Hunyuan'ın en son çok modlu modeli, resim + metin girişi ile metin içeriği oluşturmayı destekler."
  },
  "internlm/internlm2_5-7b-chat": {
    "description": "InternLM2.5, çoklu senaryolarda akıllı diyalog çözümleri sunar."
  },
  "internlm2.5-latest": {
    "description": "En son model serimiz, olağanüstü çıkarım performansına sahiptir, 1M bağlam uzunluğunu destekler ve daha güçlü talimat takibi ve araç çağırma yetenekleri sunar."
  },
  "internlm3-latest": {
    "description": "En son model serimiz, olağanüstü çıkarım performansına sahiptir ve aynı ölçekli açık kaynak modeller arasında liderdir. Varsayılan olarak en son yayımlanan InternLM3 serisi modellerine işaret eder."
  },
  "internvl2.5-latest": {
    "description": "Hala bakımını yaptığımız InternVL2.5 sürümü, mükemmel ve istikrarlı bir performansa sahiptir. Varsayılan olarak en son yayımladığımız InternVL2.5 serisi modele işaret eder, şu anda internvl2.5-78b'ye işaret ediyor."
  },
  "internvl3-latest": {
    "description": "En son yayımladığımız çok modlu büyük model, daha güçlü metin-görüntü anlama yeteneği ve uzun süreli görüntü anlama yeteneğine sahiptir; performansı en iyi kapalı kaynak modellerle karşılaştırılabilir. Varsayılan olarak en son yayımladığımız InternVL serisi modele işaret eder, şu anda internvl3-78b'ye işaret ediyor."
  },
  "jamba-large": {
    "description": "En güçlü ve en gelişmiş modelimiz, kurumsal düzeyde karmaşık görevleri işlemek için tasarlanmıştır ve olağanüstü performans sunar."
  },
  "jamba-mini": {
    "description": "Sınıfındaki en verimli model, hız ve kaliteyi dengeler, daha küçük bir boyuta sahiptir."
  },
  "jina-deepsearch-v1": {
    "description": "Derin arama, web araması, okuma ve akıl yürütmeyi birleştirerek kapsamlı bir araştırma yapar. Bunu, araştırma görevlerinizi kabul eden bir ajan olarak düşünebilirsiniz - geniş bir arama yapar ve birden fazla yineleme ile cevap verir. Bu süreç, sürekli araştırma, akıl yürütme ve sorunları çeşitli açılardan çözmeyi içerir. Bu, doğrudan önceden eğitilmiş verilerden cevaplar üreten standart büyük modellerle ve tek seferlik yüzey aramasına dayanan geleneksel RAG sistemleriyle temelde farklıdır."
  },
  "kimi-latest": {
    "description": "Kimi akıllı asistan ürünü, en son Kimi büyük modelini kullanır ve henüz kararlı olmayan özellikler içerebilir. Görüntü anlayışını desteklerken, isteğin bağlam uzunluğuna göre 8k/32k/128k modelini faturalama modeli olarak otomatik olarak seçecektir."
  },
  "kimi-thinking-preview": {
    "description": "kimi-thinking-preview modeli, Ay'ın karanlık yüzü tarafından sunulan çok modlu akıl yürütme ve genel akıl yürütme yeteneklerine sahip çok modlu düşünme modelidir; derin akıl yürütmede uzmandır ve daha zor sorunların çözümüne yardımcı olur."
  },
  "learnlm-1.5-pro-experimental": {
    "description": "LearnLM, öğrenme bilimleri ilkelerine uygun olarak eğitilmiş, görev odaklı deneysel bir dil modelidir. Eğitim ve öğrenim senaryolarında sistem talimatlarını takip edebilir ve uzman bir mentor olarak görev alabilir."
  },
  "learnlm-2.0-flash-experimental": {
    "description": "LearnLM, öğrenme bilimleri ilkelerine uygun olarak eğitilmiş, görev odaklı deneysel bir dil modelidir; öğretim ve öğrenim senaryolarında sistem talimatlarını takip edebilir, uzman bir mentor gibi davranabilir."
  },
  "lite": {
    "description": "Spark Lite, son derece düşük gecikme süresi ve yüksek verimlilikle çalışan hafif bir büyük dil modelidir. Tamamen ücretsiz ve açık olup, gerçek zamanlı çevrimiçi arama işlevini desteklemektedir. Hızlı yanıt verme özelliği, düşük hesaplama gücüne sahip cihazlarda çıkarım uygulamaları ve model ince ayarlarında mükemmel performans sergileyerek, kullanıcılara maliyet etkinliği ve akıllı deneyim sunmakta, özellikle bilgi sorgulama, içerik oluşturma ve arama senaryolarında başarılı olmaktadır."
  },
  "llama-2-7b-chat": {
    "description": "Llama2, Meta tarafından geliştirilmiş ve açık kaynaklı büyük dil modeli (LLM) serisidir. Bu, 7 milyar ile 70 milyar parametre arasında değişen, önceden eğitilmiş ve ince ayarlanmış üretici metin modellerinden oluşan bir gruptır. Mimari açısından, Llama2, optimize edilmiş dönüştürücü mimarisi kullanan bir otoregresif dil modelidir. Ayarlanmış versiyonlar, faydalılık ve güvenliğin insan tercihleriyle hizalanması için gözetimli ince ayarlama (SFT) ve insan geri bildirimleriyle güçlendirilmiş öğrenme (RLHF) kullanır. Llama2, Llama serisine göre çeşitli akademik veri kümelerinde daha iyi performans gösterir ve birçok diğer modelin tasarım ve geliştirilmesine ilham verir."
  },
  "llama-3.1-70b-versatile": {
    "description": "Llama 3.1 70B, daha güçlü AI akıl yürütme yeteneği sunar, karmaşık uygulamalar için uygundur ve yüksek verimlilik ve doğruluk sağlamak için çok sayıda hesaplama işlemini destekler."
  },
  "llama-3.1-8b-instant": {
    "description": "Llama 3.1 8B, hızlı metin üretim yeteneği sunan yüksek performanslı bir modeldir ve büyük ölçekli verimlilik ve maliyet etkinliği gerektiren uygulama senaryoları için son derece uygundur."
  },
  "llama-3.1-instruct": {
    "description": "Llama 3.1 talimat ince ayarlı modeli, diyalog senaryoları için optimize edilmiştir ve yaygın endüstri kıyaslamalarında birçok mevcut açık kaynaklı sohbet modelini geride bırakmaktadır."
  },
  "llama-3.2-11b-vision-instruct": {
    "description": "Yüksek çözünürlüklü görüntülerde mükemmel görüntü akıl yürütme yeteneği, görsel anlama uygulamaları için uygundur."
  },
  "llama-3.2-11b-vision-preview": {
    "description": "Llama 3.2, görsel ve metin verilerini birleştiren görevleri işlemek için tasarlanmıştır. Görüntü tanımlama ve görsel soru-cevap gibi görevlerde mükemmel performans sergiler, dil üretimi ile görsel akıl yürütme arasındaki uçurumu aşar."
  },
  "llama-3.2-90b-vision-instruct": {
    "description": "Görsel anlayış ajan uygulamaları için ileri düzey görüntü akıl yürütme yeteneği."
  },
  "llama-3.2-90b-vision-preview": {
    "description": "Llama 3.2, görsel ve metin verilerini birleştiren görevleri işlemek için tasarlanmıştır. Görüntü tanımlama ve görsel soru-cevap gibi görevlerde mükemmel performans sergiler, dil üretimi ile görsel akıl yürütme arasındaki uçurumu aşar."
  },
  "llama-3.2-vision-instruct": {
    "description": "Llama 3.2-Vision komut ince ayarlı modeli, görsel tanıma, görüntü çıkarımı, görüntü açıklama ve görüntülerle ilgili genel soruları yanıtlamak için optimize edilmiştir."
  },
  "llama-3.3-70b-instruct": {
    "description": "Llama 3.3, Llama serisinin en gelişmiş çok dilli açık kaynak büyük dil modelidir ve 405B modelinin performansını çok düşük maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve denetimli ince ayar (SFT) ve insan geri bildirimi ile güçlendirilmiş öğrenme (RLHF) ile faydalılığını ve güvenliğini artırmıştır. Talimat ayarlı versiyonu, çok dilli diyaloglar için optimize edilmiştir ve birçok endüstri kıyaslamasında birçok açık kaynak ve kapalı sohbet modelinden daha iyi performans göstermektedir. Bilgi kesim tarihi 2023 Aralık'tır."
  },
  "llama-3.3-70b-versatile": {
    "description": "Meta Llama 3.3 çok dilli büyük dil modeli (LLM), 70B (metin girişi/metin çıkışı) içindeki önceden eğitilmiş ve talimat ayarlanmış bir üretim modelidir. Llama 3.3 talimat ayarlı saf metin modeli, çok dilli konuşma kullanım durumları için optimize edilmiştir ve yaygın endüstri kıyaslamalarında mevcut birçok açık kaynak ve kapalı sohbet modelinden daha üstündür."
  },
  "llama-3.3-instruct": {
    "description": "Llama 3.3 komut ince ayarlı modeli, diyalog senaryoları için optimize edilmiştir ve yaygın endüstri kıyaslamalarında birçok mevcut açık kaynaklı sohbet modelini geride bırakmaktadır."
  },
  "llama3-70b-8192": {
    "description": "Meta Llama 3 70B, eşsiz karmaşıklık işleme yeteneği sunar ve yüksek talepli projeler için özel olarak tasarlanmıştır."
  },
  "llama3-8b-8192": {
    "description": "Meta Llama 3 8B, yüksek kaliteli akıl yürütme performansı sunar ve çok çeşitli uygulama ihtiyaçları için uygundur."
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 70B Tool Use, güçlü araç çağırma yetenekleri sunar ve karmaşık görevlerin verimli bir şekilde işlenmesini destekler."
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 8B Tool Use, verimli araç kullanımı için optimize edilmiş bir modeldir ve hızlı paralel hesaplamayı destekler."
  },
  "llama3.1": {
    "description": "Llama 3.1, Meta tarafından sunulan öncü bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, çok dilli çeviri ve veri analizi alanlarında kullanılabilir."
  },
  "llama3.1:405b": {
    "description": "Llama 3.1, Meta tarafından sunulan öncü bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, çok dilli çeviri ve veri analizi alanlarında kullanılabilir."
  },
  "llama3.1:70b": {
    "description": "Llama 3.1, Meta tarafından sunulan öncü bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, çok dilli çeviri ve veri analizi alanlarında kullanılabilir."
  },
  "llava": {
    "description": "LLaVA, görsel kodlayıcı ve Vicuna'yı birleştiren çok modlu bir modeldir, güçlü görsel ve dil anlama yetenekleri sunar."
  },
  "llava-v1.5-7b-4096-preview": {
    "description": "LLaVA 1.5 7B, görsel işleme yeteneklerini birleştirir ve görsel bilgi girişi ile karmaşık çıktılar üretir."
  },
  "llava:13b": {
    "description": "LLaVA, görsel kodlayıcı ve Vicuna'yı birleştiren çok modlu bir modeldir, güçlü görsel ve dil anlama yetenekleri sunar."
  },
  "llava:34b": {
    "description": "LLaVA, görsel kodlayıcı ve Vicuna'yı birleştiren çok modlu bir modeldir, güçlü görsel ve dil anlama yetenekleri sunar."
  },
  "mathstral": {
    "description": "MathΣtral, bilimsel araştırma ve matematik akıl yürütme için tasarlanmış, etkili hesaplama yetenekleri ve sonuç açıklamaları sunar."
  },
  "max-32k": {
    "description": "Spark Max 32K, büyük bağlam işleme yeteneği ile donatılmıştır ve daha güçlü bağlam anlama ve mantıksal çıkarım yetenekleri sunmaktadır. 32K token'lık metin girişi desteklemekte olup, uzun belgelerin okunması, özel bilgi sorgulama gibi senaryolar için uygundur."
  },
  "megrez-3b-instruct": {
    "description": "Megrez-3B-Instruct, Wuwen Xin Qiong tarafından tamamen bağımsız olarak eğitilen büyük dil modelidir. Megrez-3B-Instruct, yazılım ve donanım işbirliği felsefesiyle, hızlı çıkarım, küçük ve güçlü, kullanımı kolay bir uç tarafı zeka çözümü oluşturmayı amaçlamaktadır."
  },
  "meta-llama-3-70b-instruct": {
    "description": "Akıl yürütme, kodlama ve geniş dil uygulamalarında mükemmel bir 70 milyar parametreli model."
  },
  "meta-llama-3-8b-instruct": {
    "description": "Diyalog ve metin üretim görevleri için optimize edilmiş çok yönlü bir 8 milyar parametreli model."
  },
  "meta-llama-3.1-405b-instruct": {
    "description": "Llama 3.1 talimat ayarlı yalnızca metin modelleri, çok dilli diyalog kullanım durumları için optimize edilmiştir ve mevcut açık kaynak ve kapalı sohbet modellerinin çoğunu yaygın endüstri standartlarında geride bırakmaktadır."
  },
  "meta-llama-3.1-70b-instruct": {
    "description": "Llama 3.1 talimat ayarlı yalnızca metin modelleri, çok dilli diyalog kullanım durumları için optimize edilmiştir ve mevcut açık kaynak ve kapalı sohbet modellerinin çoğunu yaygın endüstri standartlarında geride bırakmaktadır."
  },
  "meta-llama-3.1-8b-instruct": {
    "description": "Llama 3.1 talimat ayarlı yalnızca metin modelleri, çok dilli diyalog kullanım durumları için optimize edilmiştir ve mevcut açık kaynak ve kapalı sohbet modellerinin çoğunu yaygın endüstri standartlarında geride bırakmaktadır."
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "description": "LLaMA-2 Chat (13B), mükemmel dil işleme yetenekleri ve olağanüstü etkileşim deneyimi sunar."
  },
  "meta-llama/Llama-2-70b-hf": {
    "description": "LLaMA-2, mükemmel dil işleme yeteneği ve üstün etkileşim deneyimi sunar."
  },
  "meta-llama/Llama-3-70b-chat-hf": {
    "description": "LLaMA-3 Chat (70B), karmaşık diyalog ihtiyaçlarını destekleyen güçlü bir sohbet modelidir."
  },
  "meta-llama/Llama-3-8b-chat-hf": {
    "description": "LLaMA-3 Chat (8B), çok dilli desteği ile zengin alan bilgilerini kapsar."
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2, görsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. Görüntü betimleme ve görsel soru yanıtlama gibi görevlerde mükemmel performans sergiler, dil üretimi ve görsel akıl yürütme arasındaki boşluğu kapar."
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "description": "LLaMA 3.2, görsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. Görüntü betimleme ve görsel soru yanıtlama gibi görevlerde mükemmel performans sergiler, dil üretimi ve görsel akıl yürütme arasındaki boşluğu kapar."
  },
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2, görsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. Görüntü betimleme ve görsel soru yanıtlama gibi görevlerde mükemmel performans sergiler, dil üretimi ve görsel akıl yürütme arasındaki boşluğu kapar."
  },
  "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
    "description": "Meta Llama 3.3 çok dilli büyük dil modeli (LLM), 70B (metin girişi/metin çıkışı) içinde önceden eğitilmiş ve talimat ayarlı bir üretim modelidir. Llama 3.3 talimat ayarlı saf metin modeli, çok dilli diyalog kullanım durumları için optimize edilmiştir ve yaygın endüstri standartlarında birçok mevcut açık kaynak ve kapalı sohbet modelinden daha iyi performans göstermektedir."
  },
  "meta-llama/Llama-Vision-Free": {
    "description": "LLaMA 3.2, görsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. Görüntü betimleme ve görsel soru yanıtlama gibi görevlerde mükemmel performans sergiler, dil üretimi ve görsel akıl yürütme arasındaki boşluğu kapar."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
    "description": "Llama 3 70B Instruct Lite, yüksek performans ve düşük gecikme gerektiren ortamlara uygundur."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
    "description": "Llama 3 70B Instruct Turbo, en zorlu hesaplama görevleri için mükemmel dil anlama ve üretim yetenekleri sunar."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
    "description": "Llama 3 8B Instruct Lite, kaynak kısıtlı ortamlara uygun, mükemmel denge performansı sunar."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
    "description": "Llama 3 8B Instruct Turbo, geniş uygulama alanlarını destekleyen yüksek performanslı bir büyük dil modelidir."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "description": "LLaMA 3.1 405B, ön eğitim ve talimat ayarlaması için güçlü bir modeldir."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "description": "405B Llama 3.1 Turbo modeli, büyük veri işleme için devasa bağlam desteği sunar ve büyük ölçekli AI uygulamalarında öne çıkar."
  },
  "meta-llama/Meta-Llama-3.1-70B": {
    "description": "Llama 3.1, Meta tarafından sunulan öncü bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, çok dilli çeviri ve veri analizi alanlarında uygulanabilir."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "description": "Llama 3.1 70B modeli, yüksek yük uygulamaları için ince ayar yapılmış, FP8'e kuantize edilerek daha verimli hesaplama gücü ve doğruluk sağlar, karmaşık senaryolarda mükemmel performans sunar."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "description": "Llama 3.1 8B modeli, FP8 kuantizasyonu ile 131,072'ye kadar bağlam belirteci destekler, karmaşık görevler için mükemmel bir açık kaynak modelidir ve birçok endüstri standardını aşar."
  },
  "meta-llama/llama-3-70b-instruct": {
    "description": "Llama 3 70B Instruct, yüksek kaliteli diyalog senaryoları için optimize edilmiştir ve çeşitli insan değerlendirmelerinde mükemmel performans göstermektedir."
  },
  "meta-llama/llama-3-8b-instruct": {
    "description": "Llama 3 8B Instruct, yüksek kaliteli diyalog senaryoları için optimize edilmiştir ve birçok kapalı kaynak modelden daha iyi performans göstermektedir."
  },
  "meta-llama/llama-3.1-70b-instruct": {
    "description": "Llama 3.1 70B Instruct, yüksek kaliteli diyalog için tasarlanmış olup, insan değerlendirmelerinde öne çıkmakta ve özellikle yüksek etkileşimli senaryolar için uygundur."
  },
  "meta-llama/llama-3.1-8b-instruct": {
    "description": "Llama 3.1 8B Instruct, Meta tarafından sunulan en son versiyon olup, yüksek kaliteli diyalog senaryoları için optimize edilmiştir ve birçok önde gelen kapalı kaynak modelden daha iyi performans göstermektedir."
  },
  "meta-llama/llama-3.1-8b-instruct:free": {
    "description": "LLaMA 3.1, çok dilli destek sunar ve sektördeki en önde gelen üretim modellerinden biridir."
  },
  "meta-llama/llama-3.2-11b-vision-instruct": {
    "description": "LLaMA 3.2, görsel ve metin verilerini birleştiren görevleri işlemek için tasarlanmıştır. Görüntü tanımlama ve görsel soru yanıtlama gibi görevlerde mükemmel performans sergileyerek dil üretimi ve görsel akıl yürütme arasındaki boşluğu kapatmaktadır."
  },
  "meta-llama/llama-3.2-3b-instruct": {
    "description": "meta-llama/llama-3.2-3b-instruct"
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    "description": "LLaMA 3.2, görsel ve metin verilerini birleştiren görevleri işlemek için tasarlanmıştır. Görüntü tanımlama ve görsel soru yanıtlama gibi görevlerde mükemmel performans sergileyerek dil üretimi ve görsel akıl yürütme arasındaki boşluğu kapatmaktadır."
  },
  "meta-llama/llama-3.3-70b-instruct": {
    "description": "Llama 3.3, Llama serisinin en gelişmiş çok dilli açık kaynak büyük dil modelidir ve 405B modelinin performansını çok düşük maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve denetimli ince ayar (SFT) ve insan geri bildirimi ile güçlendirilmiş öğrenme (RLHF) ile faydalılığını ve güvenliğini artırmıştır. Talimat ayarlı versiyonu, çok dilli diyaloglar için optimize edilmiştir ve birçok endüstri kıyaslamasında birçok açık kaynak ve kapalı sohbet modelinden daha iyi performans göstermektedir. Bilgi kesim tarihi 2023 Aralık'tır."
  },
  "meta-llama/llama-3.3-70b-instruct:free": {
    "description": "Llama 3.3, Llama serisinin en gelişmiş çok dilli açık kaynak büyük dil modelidir ve 405B modelinin performansını çok düşük maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve denetimli ince ayar (SFT) ve insan geri bildirimi ile güçlendirilmiş öğrenme (RLHF) ile faydalılığını ve güvenliğini artırmıştır. Talimat ayarlı versiyonu, çok dilli diyaloglar için optimize edilmiştir ve birçok endüstri kıyaslamasında birçok açık kaynak ve kapalı sohbet modelinden daha iyi performans göstermektedir. Bilgi kesim tarihi 2023 Aralık'tır."
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "description": "Meta Llama 3.1 405B Instruct, Llama 3.1 Instruct modelinin en büyük ve en güçlü versiyonudur. Bu, son derece gelişmiş bir diyalog akıl yürütme ve veri sentezleme modelidir ve belirli alanlarda uzmanlaşmış sürekli ön eğitim veya ince ayar için bir temel olarak da kullanılabilir. Llama 3.1, çok dilli büyük dil modelleri (LLM'ler) sunar ve 8B, 70B ve 405B boyutlarında önceden eğitilmiş, talimat ayarlı üretim modellerinden oluşur (metin girişi/çıkışı). Llama 3.1'in talimat ayarlı metin modelleri (8B, 70B, 405B), çok dilli diyalog kullanım durumları için optimize edilmiştir ve yaygın endüstri benchmark testlerinde birçok mevcut açık kaynaklı sohbet modelini geride bırakmıştır. Llama 3.1, çok dilli ticari ve araştırma amaçları için tasarlanmıştır. Talimat ayarlı metin modelleri, asistan benzeri sohbetler için uygundur, önceden eğitilmiş modeller ise çeşitli doğal dil üretim görevlerine uyum sağlayabilir. Llama 3.1 modeli, diğer modellerin çıktısını iyileştirmek için de kullanılabilir, bu da veri sentezleme ve rafine etme işlemlerini içerir. Llama 3.1, optimize edilmiş bir transformer mimarisi kullanarak oluşturulmuş bir otoregresif dil modelidir. Ayarlanmış versiyon, insan yardımseverliği ve güvenlik tercihleri ile uyumlu hale getirmek için denetimli ince ayar (SFT) ve insan geri bildirimi ile güçlendirilmiş öğrenme (RLHF) kullanır."
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "description": "Meta Llama 3.1 70B Instruct'un güncellenmiş versiyonu, genişletilmiş 128K bağlam uzunluğu, çok dilli yetenek ve geliştirilmiş akıl yürütme yetenekleri içerir. Llama 3.1 tarafından sağlanan çok dilli büyük dil modelleri (LLM'ler), 8B, 70B ve 405B boyutlarında önceden eğitilmiş, talimat ayarlı üretim modelleridir (metin girişi/çıkışı). Llama 3.1 talimat ayarlı metin modelleri (8B, 70B, 405B), çok dilli diyalog kullanım durumları için optimize edilmiştir ve birçok mevcut açık kaynaklı sohbet modelini yaygın endüstri benchmark testlerinde geçmiştir. Llama 3.1, çok dilli ticari ve araştırma amaçları için kullanılmak üzere tasarlanmıştır. Talimat ayarlı metin modelleri, asistan benzeri sohbetler için uygundur, önceden eğitilmiş modeller ise çeşitli doğal dil üretim görevlerine uyum sağlayabilir. Llama 3.1 modeli, diğer modellerin çıktısını iyileştirmek için de kullanılabilir, bu da sentetik veri üretimi ve rafine etme işlemlerini içerir. Llama 3.1, optimize edilmiş bir dönüştürücü mimarisi kullanarak oluşturulmuş bir otoregresif dil modelidir. Ayarlanmış versiyonlar, insan yardımseverliği ve güvenlik tercihlerini karşılamak için denetimli ince ayar (SFT) ve insan geri bildirimli pekiştirmeli öğrenme (RLHF) kullanır."
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "description": "Meta Llama 3.1 8B Instruct'un güncellenmiş versiyonu, genişletilmiş 128K bağlam uzunluğu, çok dilli yetenek ve geliştirilmiş akıl yürütme yetenekleri içerir. Llama 3.1 tarafından sağlanan çok dilli büyük dil modelleri (LLM'ler), 8B, 70B ve 405B boyutlarında önceden eğitilmiş, talimat ayarlı üretim modelleridir (metin girişi/çıkışı). Llama 3.1 talimat ayarlı metin modelleri (8B, 70B, 405B), çok dilli diyalog kullanım durumları için optimize edilmiştir ve birçok mevcut açık kaynaklı sohbet modelini yaygın endüstri benchmark testlerinde geçmiştir. Llama 3.1, çok dilli ticari ve araştırma amaçları için kullanılmak üzere tasarlanmıştır. Talimat ayarlı metin modelleri, asistan benzeri sohbetler için uygundur, önceden eğitilmiş modeller ise çeşitli doğal dil üretim görevlerine uyum sağlayabilir. Llama 3.1 modeli, diğer modellerin çıktısını iyileştirmek için de kullanılabilir, bu da sentetik veri üretimi ve rafine etme işlemlerini içerir. Llama 3.1, optimize edilmiş bir dönüştürücü mimarisi kullanarak oluşturulmuş bir otoregresif dil modelidir. Ayarlanmış versiyonlar, insan yardımseverliği ve güvenlik tercihlerini karşılamak için denetimli ince ayar (SFT) ve insan geri bildirimli pekiştirmeli öğrenme (RLHF) kullanır."
  },
  "meta.llama3-70b-instruct-v1:0": {
    "description": "Meta Llama 3, geliştiriciler, araştırmacılar ve işletmeler için açık bir büyük dil modelidir (LLM) ve onların üretken AI fikirlerini inşa etmelerine, denemelerine ve sorumlu bir şekilde genişletmelerine yardımcı olmak için tasarlanmıştır. Küresel topluluk yeniliğinin temel sistemlerinden biri olarak, içerik oluşturma, diyalog AI, dil anlama, araştırma ve işletme uygulamaları için son derece uygundur."
  },
  "meta.llama3-8b-instruct-v1:0": {
    "description": "Meta Llama 3, geliştiriciler, araştırmacılar ve işletmeler için açık bir büyük dil modelidir (LLM) ve onların üretken AI fikirlerini inşa etmelerine, denemelerine ve sorumlu bir şekilde genişletmelerine yardımcı olmak için tasarlanmıştır. Küresel topluluk yeniliğinin temel sistemlerinden biri olarak, sınırlı hesaplama gücü ve kaynaklara sahip, kenar cihazları ve daha hızlı eğitim süreleri için son derece uygundur."
  },
  "meta/Llama-3.2-11B-Vision-Instruct": {
    "description": "Yüksek çözünürlüklü görüntülerde üstün görsel çıkarım yeteneği sunar, görsel anlama uygulamaları için idealdir."
  },
  "meta/Llama-3.2-90B-Vision-Instruct": {
    "description": "Görsel anlama ajan uygulamaları için gelişmiş görüntü çıkarım yetenekleri sağlar."
  },
  "meta/Llama-3.3-70B-Instruct": {
    "description": "Llama 3.3, Llama serisinin en gelişmiş çok dilli açık kaynak büyük dil modeli olup, 405 milyar parametreli modellere kıyasla çok düşük maliyetle yüksek performans sunar. Transformer mimarisi temel alınmış, denetimli ince ayar (SFT) ve insan geri bildirimi ile güçlendirilmiş pekiştirmeli öğrenme (RLHF) ile faydalılık ve güvenlik artırılmıştır. Çok dilli diyaloglar için optimize edilmiş talimat ayarlı versiyonu, birçok endüstri kıyaslamasında açık ve kapalı sohbet modellerinden üstün performans gösterir. Bilgi kesim tarihi 2023 Aralık'tır."
  },
  "meta/Meta-Llama-3-70B-Instruct": {
    "description": "Çıkarım, kodlama ve geniş dil uygulamalarında üstün performans gösteren güçlü 70 milyar parametreli model."
  },
  "meta/Meta-Llama-3-8B-Instruct": {
    "description": "Diyalog ve metin üretimi görevleri için optimize edilmiş çok yönlü 8 milyar parametreli model."
  },
  "meta/Meta-Llama-3.1-405B-Instruct": {
    "description": "Llama 3.1 talimat ayarlı metin modeli, çok dilli diyalog senaryoları için optimize edilmiştir ve birçok açık ve kapalı sohbet modeli arasında yaygın endüstri kıyaslamalarında üstün performans sergiler."
  },
  "meta/Meta-Llama-3.1-70B-Instruct": {
    "description": "Llama 3.1 talimat ayarlı metin modeli, çok dilli diyalog senaryoları için optimize edilmiştir ve birçok açık ve kapalı sohbet modeli arasında yaygın endüstri kıyaslamalarında üstün performans sergiler."
  },
  "meta/Meta-Llama-3.1-8B-Instruct": {
    "description": "Llama 3.1 talimat ayarlı metin modeli, çok dilli diyalog senaryoları için optimize edilmiştir ve birçok açık ve kapalı sohbet modeli arasında yaygın endüstri kıyaslamalarında üstün performans sergiler."
  },
  "meta/llama-3.1-405b-instruct": {
    "description": "Gelişmiş LLM, sentetik veri üretimi, bilgi damıtma ve akıl yürütmeyi destekler, sohbet botları, programlama ve belirli alan görevleri için uygundur."
  },
  "meta/llama-3.1-70b-instruct": {
    "description": "Karmaşık diyalogları güçlendiren, mükemmel bağlam anlama, akıl yürütme yeteneği ve metin üretimi yeteneğine sahip."
  },
  "meta/llama-3.1-8b-instruct": {
    "description": "En son teknolojiye sahip model, dil anlama, mükemmel akıl yürütme yeteneği ve metin üretimi yeteneğine sahiptir."
  },
  "meta/llama-3.2-11b-vision-instruct": {
    "description": "Gelişmiş görsel-dil modeli, görüntülerden yüksek kaliteli akıl yürütme yapma konusunda uzmandır."
  },
  "meta/llama-3.2-1b-instruct": {
    "description": "En son teknolojiye sahip küçük dil modeli, dil anlama, mükemmel akıl yürütme yeteneği ve metin üretimi yeteneğine sahiptir."
  },
  "meta/llama-3.2-3b-instruct": {
    "description": "En son teknolojiye sahip küçük dil modeli, dil anlama, mükemmel akıl yürütme yeteneği ve metin üretimi yeteneğine sahiptir."
  },
  "meta/llama-3.2-90b-vision-instruct": {
    "description": "Gelişmiş görsel-dil modeli, görüntülerden yüksek kaliteli akıl yürütme yapma konusunda uzmandır."
  },
  "meta/llama-3.3-70b-instruct": {
    "description": "Akıllı LLM, akıl yürütme, matematik, genel bilgi ve fonksiyon çağrılarında uzmandır."
  },
  "microsoft/Phi-3-medium-128k-instruct": {
    "description": "Aynı Phi-3-medium modeli, ancak daha büyük bağlam boyutuna sahip olup RAG veya az sayıda istem için uygundur."
  },
  "microsoft/Phi-3-medium-4k-instruct": {
    "description": "140 milyar parametreli model, Phi-3-mini'den daha yüksek kaliteye sahip olup, yüksek kaliteli ve çıkarım yoğun veriye odaklanır."
  },
  "microsoft/Phi-3-mini-128k-instruct": {
    "description": "Aynı Phi-3-mini modeli, ancak daha büyük bağlam boyutuna sahip olup RAG veya az sayıda istem için uygundur."
  },
  "microsoft/Phi-3-mini-4k-instruct": {
    "description": "Phi-3 ailesinin en küçük üyesi olup, kalite ve düşük gecikme için optimize edilmiştir."
  },
  "microsoft/Phi-3-small-128k-instruct": {
    "description": "Aynı Phi-3-small modeli, ancak daha büyük bağlam boyutuna sahip olup RAG veya az sayıda istem için uygundur."
  },
  "microsoft/Phi-3-small-8k-instruct": {
    "description": "70 milyar parametreli model, Phi-3-mini'den daha yüksek kaliteye sahip olup, yüksek kaliteli ve çıkarım yoğun veriye odaklanır."
  },
  "microsoft/Phi-3.5-mini-instruct": {
    "description": "Phi-3-mini modelinin güncellenmiş versiyonu."
  },
  "microsoft/Phi-3.5-vision-instruct": {
    "description": "Phi-3-vision modelinin güncellenmiş versiyonu."
  },
  "microsoft/WizardLM-2-8x22B": {
    "description": "WizardLM 2, Microsoft AI tarafından sağlanan bir dil modelidir ve karmaşık diyaloglar, çok dilli destek, akıl yürütme ve akıllı asistan alanlarında özellikle başarılıdır."
  },
  "microsoft/wizardlm-2-8x22b": {
    "description": "WizardLM-2 8x22B, Microsoft'un en gelişmiş AI Wizard modelidir ve son derece rekabetçi bir performans sergiler."
  },
  "minicpm-v": {
    "description": "MiniCPM-V, OpenBMB tarafından sunulan yeni nesil çok modlu büyük bir modeldir; olağanüstü OCR tanıma ve çok modlu anlama yeteneklerine sahiptir ve geniş bir uygulama yelpazesini destekler."
  },
  "ministral-3b-latest": {
    "description": "Ministral 3B, Mistral'ın dünya çapında en üst düzey kenar modelidir."
  },
  "ministral-8b-latest": {
    "description": "Ministral 8B, Mistral'ın fiyat-performans oranı oldukça yüksek kenar modelidir."
  },
  "mistral": {
    "description": "Mistral, Mistral AI tarafından sunulan 7B modelidir, değişken dil işleme ihtiyaçları için uygundur."
  },
  "mistral-ai/Mistral-Large-2411": {
    "description": "Mistral'in amiral gemisi modeli olup, büyük ölçekli çıkarım yetenekleri veya yüksek derecede uzmanlaşmış karmaşık görevler (metin sentezi, kod üretimi, RAG veya ajanlar) için uygundur."
  },
  "mistral-ai/Mistral-Nemo": {
    "description": "Mistral Nemo, boyut kategorisinde en gelişmiş çıkarım, dünya bilgisi ve kodlama yeteneklerine sahip ileri düzey bir dil modelidir (LLM)."
  },
  "mistral-ai/mistral-small-2503": {
    "description": "Mistral Small, yüksek verimlilik ve düşük gecikme gerektiren dil tabanlı görevler için uygundur."
  },
  "mistral-large": {
    "description": "Mixtral Large, Mistral'ın amiral gemisi modelidir, kod üretimi, matematik ve akıl yürütme yeteneklerini birleştirir, 128k bağlam penceresini destekler."
  },
  "mistral-large-instruct": {
    "description": "Mistral-Large-Instruct-2407, 123 milyar parametreye sahip, gelişmiş bir yoğun büyük dil modelidir (LLM) ve en son akıl yürütme, bilgi ve kodlama yeteneklerine sahiptir."
  },
  "mistral-large-latest": {
    "description": "Mistral Large, çok dilli görevler, karmaşık akıl yürütme ve kod üretimi için ideal bir seçimdir ve yüksek uç uygulamalar için tasarlanmıştır."
  },
  "mistral-medium-latest": {
    "description": "Mistral Medium 3, 8 kat daha düşük maliyetle en ileri düzey performansı sunar ve kurumsal dağıtımları temelden basitleştirir."
  },
  "mistral-nemo": {
    "description": "Mistral Nemo, Mistral AI ve NVIDIA işbirliği ile sunulan, yüksek verimli 12B modelidir."
  },
  "mistral-nemo-instruct": {
    "description": "Mistral-Nemo-Instruct-2407 büyük dil modeli (LLM), Mistral-Nemo-Base-2407'nin komut ince ayarlı versiyonudur."
  },
  "mistral-small": {
    "description": "Mistral Small, yüksek verimlilik ve düşük gecikme gerektiren her dil tabanlı görevde kullanılabilir."
  },
  "mistral-small-latest": {
    "description": "Mistral Small, çeviri, özetleme ve duygu analizi gibi kullanım durumları için maliyet etkin, hızlı ve güvenilir bir seçenektir."
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "description": "Mistral (7B) Instruct, yüksek performansıyla tanınır ve çeşitli dil görevleri için uygundur."
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "description": "Mistral 7B, talebe göre ince ayar yapılmış bir modeldir ve görevler için optimize edilmiş yanıtlar sunar."
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "description": "Mistral (7B) Instruct v0.3, geniş uygulamalar için etkili hesaplama gücü ve doğal dil anlama sunar."
  },
  "mistralai/Mistral-7B-v0.1": {
    "description": "Mistral 7B, kompakt ancak yüksek performanslı bir modeldir, sınıflandırma ve metin üretimi gibi basit görevlerde iyi bir akıl yürütme yeteneği ile yoğun işlem yapma konusunda uzmandır."
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "description": "Mixtral-8x22B Instruct (141B), son derece büyük bir dil modelidir ve çok yüksek işleme taleplerini destekler."
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "description": "Mixtral 8x7B, genel metin görevleri için kullanılan önceden eğitilmiş seyrek karışık uzman modelidir."
  },
  "mistralai/Mixtral-8x7B-v0.1": {
    "description": "Mixtral 8x7B, birden fazla parametre kullanarak akıl yürütme hızını artıran seyrek uzman modelidir, çok dilli ve kod üretim görevleri için uygundur."
  },
  "mistralai/mistral-7b-instruct": {
    "description": "Mistral 7B Instruct, hız optimizasyonu ve uzun bağlam desteği sunan yüksek performanslı bir endüstri standart modelidir."
  },
  "mistralai/mistral-nemo": {
    "description": "Mistral Nemo, çok dilli destek ve yüksek performanslı programlama sunan 7.3B parametreli bir modeldir."
  },
  "mixtral": {
    "description": "Mixtral, Mistral AI'nın uzman modelidir, açık kaynak ağırlıkları ile birlikte gelir ve kod üretimi ve dil anlama konularında destek sunar."
  },
  "mixtral-8x7b-32768": {
    "description": "Mixtral 8x7B, yüksek hata toleransına sahip paralel hesaplama yeteneği sunar ve karmaşık görevler için uygundur."
  },
  "mixtral:8x22b": {
    "description": "Mixtral, Mistral AI'nın uzman modelidir, açık kaynak ağırlıkları ile birlikte gelir ve kod üretimi ve dil anlama konularında destek sunar."
  },
  "moonshot-v1-128k": {
    "description": "Moonshot V1 128K, ultra uzun bağlam işleme yeteneğine sahip bir modeldir, karmaşık üretim görevlerini karşılamak için ultra uzun metinler üretmekte kullanılabilir, 128,000 token'a kadar içeriği işleyebilir, araştırma, akademik ve büyük belgelerin üretilmesi gibi uygulama senaryoları için son derece uygundur."
  },
  "moonshot-v1-128k-vision-preview": {
    "description": "Kimi görsel modeli (moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview gibi) resim içeriğini anlayabilir, resim metni, resim rengi ve nesne şekilleri gibi içerikleri kapsar."
  },
  "moonshot-v1-32k": {
    "description": "Moonshot V1 32K, orta uzunlukta bağlam işleme yeteneği sunar, 32,768 token'ı işleyebilir, çeşitli uzun belgeler ve karmaşık diyaloglar üretmek için özellikle uygundur, içerik oluşturma, rapor üretimi ve diyalog sistemleri gibi alanlarda kullanılabilir."
  },
  "moonshot-v1-32k-vision-preview": {
    "description": "Kimi görsel modeli (moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview gibi) resim içeriğini anlayabilir, resim metni, resim rengi ve nesne şekilleri gibi içerikleri kapsar."
  },
  "moonshot-v1-8k": {
    "description": "Moonshot V1 8K, kısa metin görevleri için tasarlanmış, yüksek verimlilikte işleme performansı sunar, 8,192 token'ı işleyebilir, kısa diyaloglar, not alma ve hızlı içerik üretimi için son derece uygundur."
  },
  "moonshot-v1-8k-vision-preview": {
    "description": "Kimi görsel modeli (moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview gibi) resim içeriğini anlayabilir, resim metni, resim rengi ve nesne şekilleri gibi içerikleri kapsar."
  },
  "moonshot-v1-auto": {
    "description": "Moonshot V1 Auto, mevcut bağlamın kullandığı Token sayısına göre uygun modeli seçebilir."
  },
  "nousresearch/hermes-2-pro-llama-3-8b": {
    "description": "Hermes 2 Pro Llama 3 8B, Nous Hermes 2'nin güncellenmiş versiyonudur ve en son iç geliştirme veri setlerini içermektedir."
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
    "description": "Llama 3.1 Nemotron 70B, NVIDIA tarafından özelleştirilmiş büyük bir dil modelidir ve LLM tarafından üretilen yanıtların kullanıcı sorgularına yardımcı olma düzeyini artırmayı amaçlamaktadır. Bu model, Arena Hard, AlpacaEval 2 LC ve GPT-4-Turbo MT-Bench gibi standart testlerde mükemmel performans sergilemiştir ve 1 Ekim 2024 itibarıyla tüm üç otomatik hizalama testinde birinci sıradadır. Model, Llama-3.1-70B-Instruct modelinin temelinde RLHF (özellikle REINFORCE), Llama-3.1-Nemotron-70B-Reward ve HelpSteer2-Preference ipuçları kullanılarak eğitilmiştir."
  },
  "nvidia/llama-3.1-nemotron-51b-instruct": {
    "description": "Eşsiz bir dil modeli, benzersiz doğruluk ve verimlilik sunar."
  },
  "nvidia/llama-3.1-nemotron-70b-instruct": {
    "description": "Llama-3.1-Nemotron-70B-Instruct, NVIDIA'nın özel olarak geliştirdiği büyük dil modelidir ve LLM tarafından üretilen yanıtların yardımcı olmasını artırmayı amaçlar."
  },
  "o1": {
    "description": "Gelişmiş çıkarım ve karmaşık sorunları çözmeye odaklanır, matematik ve bilim görevlerini içerir. Derin bağlam anlayışı ve aracılık iş akışları gerektiren uygulamalar için son derece uygundur."
  },
  "o1-mini": {
    "description": "o1-mini, programlama, matematik ve bilim uygulama senaryoları için tasarlanmış hızlı ve ekonomik bir akıl yürütme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."
  },
  "o1-preview": {
    "description": "o1, OpenAI'nin geniş genel bilgiye ihtiyaç duyan karmaşık görevler için uygun yeni bir akıl yürütme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."
  },
  "o1-pro": {
    "description": "o1 serisi modeller, güçlendirilmiş öğrenme ile eğitilmiş olup, yanıtlamadan önce düşünme yapabilir ve karmaşık akıl yürütme görevlerini yerine getirebilir. o1-pro modeli, daha derin düşünme için daha fazla hesaplama kaynağı kullanır ve böylece sürekli olarak daha kaliteli yanıtlar sunar."
  },
  "o3": {
    "description": "o3, çok çeşitli alanlarda mükemmel performans gösteren çok yönlü güçlü bir modeldir. Matematik, bilim, programlama ve görsel çıkarım görevlerinde yeni standartlar belirler. Ayrıca teknik yazım ve talimat takibi konusunda da uzmandır. Kullanıcılar, metin, kod ve görüntüleri analiz ederek çok adımlı karmaşık sorunları çözebilir."
  },
  "o3-mini": {
    "description": "o3-mini, aynı maliyet ve gecikme hedefleriyle yüksek zeka sunan en yeni küçük ölçekli çıkarım modelimizdir."
  },
  "o3-pro": {
    "description": "o3-pro modeli, daha derin düşünmek ve her zaman daha iyi yanıtlar sunmak için daha fazla hesaplama kullanır; yalnızca Responses API altında kullanılabilir."
  },
  "o4-mini": {
    "description": "o4-mini, en yeni küçük o serisi modelimizdir. Hızlı ve etkili çıkarım için optimize edilmiştir ve kodlama ile görsel görevlerde son derece yüksek verimlilik ve performans sergiler."
  },
  "open-codestral-mamba": {
    "description": "Codestral Mamba, kod üretimine odaklanan Mamba 2 dil modelidir ve ileri düzey kod ve akıl yürütme görevlerine güçlü destek sunar."
  },
  "open-mistral-7b": {
    "description": "Mistral 7B, kompakt ama yüksek performanslı bir modeldir, sınıflandırma ve metin üretimi gibi basit görevlerde iyi bir akıl yürütme yeteneğine sahiptir."
  },
  "open-mistral-nemo": {
    "description": "Mistral Nemo, Nvidia ile işbirliği içinde geliştirilmiş 12B modelidir, mükemmel akıl yürütme ve kodlama performansı sunar, entegrasyonu ve değiştirilmesi kolaydır."
  },
  "open-mixtral-8x22b": {
    "description": "Mixtral 8x22B, karmaşık görevler için odaklanmış daha büyük bir uzman modelidir, mükemmel akıl yürütme yeteneği ve daha yüksek bir verim sunar."
  },
  "open-mixtral-8x7b": {
    "description": "Mixtral 8x7B, birden fazla parametre kullanarak akıl yürütme hızını artıran seyrek uzman modelidir, çok dilli ve kod üretim görevlerini işlemek için uygundur."
  },
  "openai/gpt-4.1": {
    "description": "GPT-4.1, karmaşık görevler için kullandığımız amiral gemisi modelidir. Farklı alanlarda sorun çözmek için son derece uygundur."
  },
  "openai/gpt-4.1-mini": {
    "description": "GPT-4.1 mini, zeka, hız ve maliyet arasında bir denge sunarak birçok kullanım durumu için çekici bir model haline getirir."
  },
  "openai/gpt-4.1-nano": {
    "description": "GPT-4.1 nano, en hızlı ve en maliyet etkin GPT-4.1 modelidir."
  },
  "openai/gpt-4o": {
    "description": "ChatGPT-4o, güncel en son sürümü korumak için gerçek zamanlı olarak güncellenen dinamik bir modeldir. Güçlü dil anlama ve üretme yeteneklerini birleştirir, müşteri hizmetleri, eğitim ve teknik destek gibi büyük ölçekli uygulama senaryoları için uygundur."
  },
  "openai/gpt-4o-mini": {
    "description": "GPT-4o mini, OpenAI'nin GPT-4 Omni'den sonra sunduğu en son modeldir; görsel ve metin girişi destekler ve metin çıktısı verir. En gelişmiş küçük model olarak, diğer son zamanlardaki öncü modellere göre çok daha ucuzdur ve GPT-3.5 Turbo'dan %60'tan fazla daha ucuzdur. En son teknolojiyi korurken, önemli bir maliyet etkinliği sunar. GPT-4o mini, MMLU testinde %82 puan almış olup, şu anda sohbet tercihleri açısından GPT-4'ün üzerinde bir sıralamaya sahiptir."
  },
  "openai/o1": {
    "description": "o1, OpenAI'nin yeni çıkarım modeli olup, metin ve görsel girişleri destekler ve metin çıktısı üretir; geniş kapsamlı genel bilgi gerektiren karmaşık görevler için uygundur. Model, 200K bağlam uzunluğuna ve 2023 Ekim bilgi kesim tarihine sahiptir."
  },
  "openai/o1-mini": {
    "description": "o1-mini, programlama, matematik ve bilim uygulama senaryoları için tasarlanmış hızlı ve ekonomik bir akıl yürütme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."
  },
  "openai/o1-preview": {
    "description": "o1, OpenAI'nin geniş genel bilgiye ihtiyaç duyan karmaşık görevler için uygun yeni bir akıl yürütme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."
  },
  "openai/o3": {
    "description": "o3, birçok alanda mükemmel performans sergileyen güçlü bir modeldir. Matematik, bilim, programlama ve görsel akıl yürütme görevleri için yeni bir standart belirler. Ayrıca teknik yazım ve talimat takibi konusunda da uzmandır. Kullanıcılar, metin, kod ve görüntüleri analiz ederek çok adımlı karmaşık problemleri çözebilir."
  },
  "openai/o3-mini": {
    "description": "o3-mini, o1-mini ile aynı maliyet ve gecikme hedefleri altında yüksek zeka sunar."
  },
  "openai/o3-mini-high": {
    "description": "o3-mini yüksek akıl yürütme seviyesi, o1-mini ile aynı maliyet ve gecikme hedefleri altında yüksek zeka sunar."
  },
  "openai/o4-mini": {
    "description": "o4-mini, hızlı ve etkili çıkarım için optimize edilmiştir ve kodlama ile görsel görevlerde son derece yüksek verimlilik ve performans sergiler."
  },
  "openai/o4-mini-high": {
    "description": "o4-mini yüksek çıkarım seviyesinde, hızlı ve etkili çıkarım için optimize edilmiştir ve kodlama ile görsel görevlerde son derece yüksek verimlilik ve performans sergiler."
  },
  "openrouter/auto": {
    "description": "Bağlam uzunluğu, konu ve karmaşıklığa göre isteğiniz, Llama 3 70B Instruct, Claude 3.5 Sonnet (kendini ayarlama) veya GPT-4o'ya gönderilecektir."
  },
  "phi3": {
    "description": "Phi-3, Microsoft tarafından sunulan hafif bir açık modeldir, verimli entegrasyon ve büyük ölçekli bilgi akıl yürütme için uygundur."
  },
  "phi3:14b": {
    "description": "Phi-3, Microsoft tarafından sunulan hafif bir açık modeldir, verimli entegrasyon ve büyük ölçekli bilgi akıl yürütme için uygundur."
  },
  "pixtral-12b-2409": {
    "description": "Pixtral modeli, grafik ve görüntü anlama, belge yanıtı, çok modlu akıl yürütme ve talimat takibi gibi görevlerde güçlü yetenekler sergiler, doğal çözünürlük ve en boy oranında görüntüleri alabilir ve 128K token uzunluğunda bir bağlam penceresinde herhangi bir sayıda görüntüyü işleyebilir."
  },
  "pixtral-large-latest": {
    "description": "Pixtral Large, 1240 milyar parametreye sahip açık kaynaklı çok modlu bir modeldir ve Mistral Large 2 üzerine inşa edilmiştir. Bu, çok modlu ailemizdeki ikinci modeldir ve öncü düzeyde görüntü anlama yetenekleri sergilemektedir."
  },
  "pro-128k": {
    "description": "Spark Pro 128K, olağanüstü bağlam işleme yeteneği ile donatılmıştır ve 128K'ya kadar bağlam bilgilerini işleyebilir. Özellikle uzun metinlerin bütünsel analizi ve uzun vadeli mantıksal ilişkilerin işlenmesi gereken durumlar için uygundur ve karmaşık metin iletişiminde akıcı ve tutarlı bir mantık ile çeşitli alıntı desteği sunmaktadır."
  },
  "qvq-72b-preview": {
    "description": "QVQ modeli, Qwen ekibi tarafından geliştirilen deneysel bir araştırma modelidir; görsel akıl yürütme yeteneğini artırmaya odaklanır, özellikle matematik akıl yürütme alanında."
  },
  "qvq-max": {
    "description": "Tongyi Qianwen QVQ görsel akıl yürütme modeli, görsel giriş ve düşünce zinciri çıktısını destekler; matematik, programlama, görsel analiz, yaratım ve genel görevlerde daha güçlü performans sergiler."
  },
  "qvq-plus": {
    "description": "Görsel çıkarım modeli. Görsel girişleri ve düşünce zinciri çıktısını destekler; qvq-max modelinin ardından gelen plus versiyonudur. qvq-max modeline kıyasla, qvq-plus serisi modeller daha hızlı çıkarım yapar ve performans ile maliyet arasında daha dengeli bir sonuç sunar."
  },
  "qwen-coder-plus": {
    "description": "Tongyi Qianwen kodlama modeli."
  },
  "qwen-coder-turbo": {
    "description": "Tongyi Qianwen kodlama modeli."
  },
  "qwen-coder-turbo-latest": {
    "description": "Tongyi Qianwen kodlama modeli."
  },
  "qwen-long": {
    "description": "Tongyi Qianwen, uzun metin bağlamını destekleyen ve uzun belgeler, çoklu belgeler gibi çeşitli senaryolar için diyalog işlevselliği sunan büyük ölçekli bir dil modelidir."
  },
  "qwen-math-plus": {
    "description": "Tongyi Qianwen matematik modeli, matematik problemlerini çözmek için özel olarak tasarlanmış dil modelidir."
  },
  "qwen-math-plus-latest": {
    "description": "Tongyi Qianwen matematik modeli, matematik problemlerini çözmek için özel olarak tasarlanmış bir dil modelidir."
  },
  "qwen-math-turbo": {
    "description": "Tongyi Qianwen matematik modeli, matematik problemlerini çözmek için özel olarak tasarlanmış dil modelidir."
  },
  "qwen-math-turbo-latest": {
    "description": "Tongyi Qianwen matematik modeli, matematik problemlerini çözmek için özel olarak tasarlanmış bir dil modelidir."
  },
  "qwen-max": {
    "description": "Tongyi Qianwen, 100 milyar seviyesinde büyük ölçekli bir dil modelidir ve Çince, İngilizce gibi farklı dil girişlerini destekler; şu anda Tongyi Qianwen 2.5 ürün sürümünün arkasındaki API modelidir."
  },
  "qwen-omni-turbo": {
    "description": "Qwen-Omni serisi modeller, video, ses, resim ve metin dahil çoklu modalite girişlerini destekler ve ses ile metin çıktısı sağlar."
  },
  "qwen-plus": {
    "description": "Tongyi Qianwen, Çince, İngilizce gibi farklı dil girişlerini destekleyen geliştirilmiş büyük ölçekli bir dil modelidir."
  },
  "qwen-turbo": {
    "description": "Tongyi Qianwen, Çince, İngilizce gibi farklı dil girişlerini destekleyen büyük ölçekli bir dil modelidir."
  },
  "qwen-vl-chat-v1": {
    "description": "Tongyi Qianwen VL, çoklu görüntü, çok turlu soru-cevap, yaratım gibi esnek etkileşim yöntemlerini destekleyen bir modeldir."
  },
  "qwen-vl-max": {
    "description": "Tongyi Qianwen ultra büyük ölçekli görsel-dil modeli. Geliştirilmiş versiyona kıyasla görsel akıl yürütme ve komut uyum yeteneklerini daha da artırır, daha yüksek görsel algı ve bilişsel seviyeler sunar."
  },
  "qwen-vl-max-latest": {
    "description": "Tongyi Qianwen ultra büyük ölçekli görsel dil modeli. Geliştirilmiş versiyona kıyasla, görsel akıl yürütme yeteneğini ve talimatlara uyum yeteneğini bir kez daha artırır, daha yüksek görsel algı ve bilişsel seviyeler sunar."
  },
  "qwen-vl-ocr": {
    "description": "Tongyi Qianwen OCR, belge, tablo, sınav soruları ve el yazısı gibi görüntülerden metin çıkarma konusunda uzmanlaşmış özel modeldir. Çoklu dil tanıma yeteneğine sahiptir; desteklenen diller arasında Çince, İngilizce, Fransızca, Japonca, Korece, Almanca, Rusça, İtalyanca, Vietnamca ve Arapça bulunmaktadır."
  },
  "qwen-vl-plus": {
    "description": "Tongyi Qianwen büyük ölçekli görsel-dil modeli geliştirilmiş versiyonu. Detay tanıma ve metin tanıma yeteneklerini büyük ölçüde artırır, milyonlarca piksel çözünürlük ve herhangi bir en-boy oranındaki görüntüleri destekler."
  },
  "qwen-vl-plus-latest": {
    "description": "Tongyi Qianwen büyük ölçekli görsel dil modelinin geliştirilmiş versiyonu. Detay tanıma ve metin tanıma yeteneklerini büyük ölçüde artırır, bir milyondan fazla piksel çözünürlüğü ve herhangi bir en-boy oranındaki görüntüleri destekler."
  },
  "qwen-vl-v1": {
    "description": "Qwen-7B dil modeli ile başlatılan, 448 çözünürlükte görüntü girişi olan önceden eğitilmiş bir modeldir."
  },
  "qwen/qwen-2-7b-instruct": {
    "description": "Qwen2, tamamen yeni bir Qwen büyük dil modeli serisidir. Qwen2 7B, dil anlama, çok dilli yetenek, programlama, matematik ve akıl yürütme konularında mükemmel performans sergileyen bir transformer tabanlı modeldir."
  },
  "qwen/qwen-2-7b-instruct:free": {
    "description": "Qwen2, daha güçlü anlama ve üretme yeteneklerine sahip yeni bir büyük dil modeli serisidir."
  },
  "qwen/qwen-2-vl-72b-instruct": {
    "description": "Qwen2-VL, Qwen-VL modelinin en son yineleme versiyonudur ve MathVista, DocVQA, RealWorldQA ve MTVQA gibi görsel anlama benchmark testlerinde en gelişmiş performansa ulaşmıştır. Qwen2-VL, yüksek kaliteli video tabanlı soru-cevap, diyalog ve içerik oluşturma için 20 dakikadan fazla videoyu anlayabilmektedir. Ayrıca, karmaşık akıl yürütme ve karar verme yeteneklerine sahiptir ve mobil cihazlar, robotlar gibi sistemlerle entegre olarak görsel ortam ve metin talimatlarına dayalı otomatik işlemler gerçekleştirebilmektedir. İngilizce ve Çince'nin yanı sıra, Qwen2-VL artık çoğu Avrupa dili, Japonca, Korece, Arapça ve Vietnamca gibi farklı dillerdeki metinleri de anlayabilmektedir."
  },
  "qwen/qwen-2.5-72b-instruct": {
    "description": "Qwen2.5-72B-Instruct, Alibaba Cloud tarafından yayınlanan en son büyük dil modeli serilerinden biridir. Bu 72B modeli, kodlama ve matematik gibi alanlarda önemli iyileştirmelere sahiptir. Model ayrıca, Çince, İngilizce gibi 29'dan fazla dili kapsayan çok dilli destek sunmaktadır. Model, talimat takibi, yapılandırılmış verileri anlama ve yapılandırılmış çıktı (özellikle JSON) üretme konularında önemli gelişmeler göstermektedir."
  },
  "qwen/qwen2.5-32b-instruct": {
    "description": "Qwen2.5-32B-Instruct, Alibaba Cloud tarafından yayınlanan en son büyük dil modeli serilerinden biridir. Bu 32B modeli, kodlama ve matematik gibi alanlarda önemli iyileştirmelere sahiptir. Model, Çince, İngilizce gibi 29'dan fazla dili kapsayan çok dilli destek sunmaktadır. Model, talimat takibi, yapılandırılmış verileri anlama ve yapılandırılmış çıktı (özellikle JSON) üretme konularında önemli gelişmeler göstermektedir."
  },
  "qwen/qwen2.5-7b-instruct": {
    "description": "Çince ve İngilizce'ye yönelik LLM, dil, programlama, matematik, akıl yürütme gibi alanlara odaklanır."
  },
  "qwen/qwen2.5-coder-32b-instruct": {
    "description": "Gelişmiş LLM, kod üretimi, akıl yürütme ve düzeltme desteği sunar, ana akım programlama dillerini kapsar."
  },
  "qwen/qwen2.5-coder-7b-instruct": {
    "description": "Güçlü orta ölçekli kod modeli, 32K bağlam uzunluğunu destekler, çok dilli programlama konusunda uzmandır."
  },
  "qwen/qwen3-14b": {
    "description": "Qwen3-14B, Qwen3 serisindeki yoğun 14.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl yürütme ve etkili diyalog için tasarlanmıştır. Matematik, programlama ve mantık akıl yürütme gibi görevler için 'düşünme' modu ile genel diyalog için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, talimat takibi, ajan araç kullanımı, yaratıcı yazım ve 100'den fazla dil ve lehçede çok dilli görevler için ince ayar yapılmıştır. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token'a kadar genişletilebilir."
  },
  "qwen/qwen3-14b:free": {
    "description": "Qwen3-14B, Qwen3 serisindeki yoğun 14.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl yürütme ve etkili diyalog için tasarlanmıştır. Matematik, programlama ve mantık akıl yürütme gibi görevler için 'düşünme' modu ile genel diyalog için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, talimat takibi, ajan araç kullanımı, yaratıcı yazım ve 100'den fazla dil ve lehçede çok dilli görevler için ince ayar yapılmıştır. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token'a kadar genişletilebilir."
  },
  "qwen/qwen3-235b-a22b": {
    "description": "Qwen3-235B-A22B, Qwen tarafından geliştirilen 235B parametreli uzman karışımı (MoE) modelidir ve her ileri geçişte 22B parametreyi etkinleştirir. Karmaşık akıl yürütme, matematik ve kod görevleri için 'düşünme' modu ile genel diyalog verimliliği için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, güçlü akıl yürütme yetenekleri, çok dilli destek (100'den fazla dil ve lehçe), ileri düzey talimat takibi ve ajan araç çağırma yetenekleri sergiler. 32K token bağlam penceresini yerel olarak işler ve YaRN tabanlı genişletme ile 131K token'a kadar genişletilebilir."
  },
  "qwen/qwen3-235b-a22b:free": {
    "description": "Qwen3-235B-A22B, Qwen tarafından geliştirilen 235B parametreli uzman karışımı (MoE) modelidir ve her ileri geçişte 22B parametreyi etkinleştirir. Karmaşık akıl yürütme, matematik ve kod görevleri için 'düşünme' modu ile genel diyalog verimliliği için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, güçlü akıl yürütme yetenekleri, çok dilli destek (100'den fazla dil ve lehçe), ileri düzey talimat takibi ve ajan araç çağırma yetenekleri sergiler. 32K token bağlam penceresini yerel olarak işler ve YaRN tabanlı genişletme ile 131K token'a kadar genişletilebilir."
  },
  "qwen/qwen3-30b-a3b": {
    "description": "Qwen3, Qwen büyük dil modeli serisinin en son neslidir ve yoğun ve uzman karışımı (MoE) mimarisi ile akıl yürütme, çok dilli destek ve ileri düzey görevlerde mükemmel performans sergilemektedir. Karmaşık akıl yürütme düşünce modu ile etkili diyalog için düşünmeden geçiş yapma yeteneği, çok yönlü ve yüksek kaliteli performansı garanti eder.\n\nQwen3, QwQ ve Qwen2.5 gibi önceki modellere kıyasla önemli ölçüde daha üstündür ve matematik, kodlama, genel bilgi akıl yürütme, yaratıcı yazım ve etkileşimli diyalog yetenekleri sunar. Qwen3-30B-A3B varyantı, 30.5 milyar parametre (3.3 milyar etkin parametre), 48 katman, 128 uzman (her görevde 8 etkin) içerir ve 131K token bağlamını destekler (YaRN kullanarak), açık kaynaklı modeller için yeni bir standart belirler."
  },
  "qwen/qwen3-30b-a3b:free": {
    "description": "Qwen3, Qwen büyük dil modeli serisinin en son neslidir ve yoğun ve uzman karışımı (MoE) mimarisi ile akıl yürütme, çok dilli destek ve ileri düzey görevlerde mükemmel performans sergilemektedir. Karmaşık akıl yürütme düşünce modu ile etkili diyalog için düşünmeden geçiş yapma yeteneği, çok yönlü ve yüksek kaliteli performansı garanti eder.\n\nQwen3, QwQ ve Qwen2.5 gibi önceki modellere kıyasla önemli ölçüde daha üstündür ve matematik, kodlama, genel bilgi akıl yürütme, yaratıcı yazım ve etkileşimli diyalog yetenekleri sunar. Qwen3-30B-A3B varyantı, 30.5 milyar parametre (3.3 milyar etkin parametre), 48 katman, 128 uzman (her görevde 8 etkin) içerir ve 131K token bağlamını destekler (YaRN kullanarak), açık kaynaklı modeller için yeni bir standart belirler."
  },
  "qwen/qwen3-32b": {
    "description": "Qwen3-32B, Qwen3 serisindeki yoğun 32.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl yürütme ve etkili diyalog için optimize edilmiştir. Matematik, kodlama ve mantık akıl yürütme gibi görevler için 'düşünme' modu ile daha hızlı, genel diyalog için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, talimat takibi, ajan araç kullanımı, yaratıcı yazım ve 100'den fazla dil ve lehçede çok dilli görevlerde güçlü performans sergiler. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token'a kadar genişletilebilir."
  },
  "qwen/qwen3-32b:free": {
    "description": "Qwen3-32B, Qwen3 serisindeki yoğun 32.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl yürütme ve etkili diyalog için optimize edilmiştir. Matematik, kodlama ve mantık akıl yürütme gibi görevler için 'düşünme' modu ile daha hızlı, genel diyalog için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, talimat takibi, ajan araç kullanımı, yaratıcı yazım ve 100'den fazla dil ve lehçede çok dilli görevlerde güçlü performans sergiler. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token'a kadar genişletilebilir."
  },
  "qwen/qwen3-8b:free": {
    "description": "Qwen3-8B, Qwen3 serisindeki yoğun 8.2 milyar parametreli nedensel dil modelidir ve akıl yürütme yoğun görevler ve etkili diyalog için tasarlanmıştır. Matematik, kodlama ve mantık akıl yürütme için 'düşünme' modu ile genel diyalog için 'düşünmeme' modu arasında sorunsuz geçiş yapmayı destekler. Bu model, talimat takibi, ajan entegrasyonu, yaratıcı yazım ve 100'den fazla dil ve lehçede çok dilli kullanım için ince ayar yapılmıştır. 32K token bağlam penceresini yerel olarak destekler ve YaRN aracılığıyla 131K token'a genişletilebilir."
  },
  "qwen2": {
    "description": "Qwen2, Alibaba'nın yeni nesil büyük ölçekli dil modelidir, mükemmel performans ile çeşitli uygulama ihtiyaçlarını destekler."
  },
  "qwen2-72b-instruct": {
    "description": "Qwen2, Qwen ekibinin yeni nesil büyük dil modeli serisidir. Bu model, Transformer mimarisine dayanır ve SwiGLU aktivasyon fonksiyonu, dikkat QKV yanlısı (attention QKV bias), grup sorgu dikkati (group query attention), kayan pencere dikkatı (mixture of sliding window attention) ve tam dikkatin karışımı gibi teknikleri kullanır. Ayrıca, Qwen ekibi, çeşitli doğal diller ve kodları destekleyen belirteçleyiciyi (tokenizer) de geliştirdi."
  },
  "qwen2-7b-instruct": {
    "description": "Qwen2, Qwen ekibinin yeni nesil büyük dil modeli serisidir. Bu model, Transformer mimarisine dayanır ve SwiGLU aktivasyon fonksiyonu, dikkat QKV bias, grup sorgu dikkati, kayan pencere dikkatini ve tam dikkat karışımını içeren teknolojiler kullanır. Ayrıca, Qwen ekibi, çeşitli doğal diller ve kodları için belirteçleyiciyi de geliştirdi."
  },
  "qwen2.5": {
    "description": "Qwen2.5, Alibaba'nın yeni nesil büyük ölçekli dil modelidir ve mükemmel performansıyla çeşitli uygulama ihtiyaçlarını desteklemektedir."
  },
  "qwen2.5-14b-instruct": {
    "description": "Tongyi Qianwen 2.5, halka açık 14B ölçeğinde bir modeldir."
  },
  "qwen2.5-14b-instruct-1m": {
    "description": "Tongyi Qianwen 2.5, 72B ölçeğinde açık kaynak olarak sunulmuştur."
  },
  "qwen2.5-32b-instruct": {
    "description": "Tongyi Qianwen 2.5, halka açık 32B ölçeğinde bir modeldir."
  },
  "qwen2.5-72b-instruct": {
    "description": "Tongyi Qianwen 2.5, halka açık 72B ölçeğinde bir modeldir."
  },
  "qwen2.5-7b-instruct": {
    "description": "Tongyi Qianwen 2.5, halka açık 7B ölçeğinde bir modeldir."
  },
  "qwen2.5-coder-1.5b-instruct": {
    "description": "Tongyi Qianwen kodlama modelinin açık kaynak sürümüdür."
  },
  "qwen2.5-coder-14b-instruct": {
    "description": "Tongyi Qianwen kodlama modeli açık kaynak sürümü."
  },
  "qwen2.5-coder-32b-instruct": {
    "description": "Tongyi Qianwen kod modeli açık kaynak versiyonu."
  },
  "qwen2.5-coder-7b-instruct": {
    "description": "Tongyi Qianwen kodlama modelinin açık kaynak versiyonu."
  },
  "qwen2.5-coder-instruct": {
    "description": "Qwen2.5-Coder, Qwen serisinin en yeni kod odaklı büyük dil modelidir (eski adıyla CodeQwen)."
  },
  "qwen2.5-instruct": {
    "description": "Qwen2.5, Qwen büyük dil modeli serisinin en son sürümüdür. Qwen2.5 için, 500 milyondan 7.2 milyara kadar değişen parametre aralığında birden fazla temel dil modeli ve komut ayarlı dil modeli yayınladık."
  },
  "qwen2.5-math-1.5b-instruct": {
    "description": "Qwen-Math modeli, güçlü matematiksel problem çözme yeteneklerine sahiptir."
  },
  "qwen2.5-math-72b-instruct": {
    "description": "Qwen-Math modeli, güçlü matematik problem çözme yeteneklerine sahiptir."
  },
  "qwen2.5-math-7b-instruct": {
    "description": "Qwen-Math modeli, güçlü matematik problem çözme yeteneklerine sahiptir."
  },
  "qwen2.5-omni-7b": {
    "description": "Qwen-Omni serisi modeller, video, ses, resim ve metin gibi çeşitli modlarda veri girişi destekler ve ses ile metin çıktısı verir."
  },
  "qwen2.5-vl-32b-instruct": {
    "description": "Qwen2.5-VL serisi modeller, doğal konuşma, içerik oluşturma, uzmanlık hizmetleri ve kod geliştirme gibi senaryolarda daha iyi performans göstermek için modelin zekâ seviyesini, pratikliğini ve uygunluğunu artırmaktadır. 32B sürümü, pekiştirmeli öğrenme teknolojisi kullanılarak optimize edilmiş olup, Qwen2.5 VL serisinin diğer modellerine kıyasla insan tercihlerine daha uygun çıktı tarzı, karmaşık matematik problemlerini çözme yeteneği ve görüntülerin ince detaylarını anlama ve akıl yürütme becerisi sunmaktadır."
  },
  "qwen2.5-vl-72b-instruct": {
    "description": "Talimat takibi, matematik, problem çözme, kodlama genelinde iyileştirme, her türlü nesneyi tanıma yeteneği artışı, çeşitli formatları doğrudan hassas bir şekilde görsel unsurları konumlandırma desteği, uzun video dosyalarını (en fazla 10 dakika) anlama ve saniye düzeyinde olay anlarını konumlandırma yeteneği, zaman sıralamasını ve hızını anlama, analiz ve konumlandırma yeteneğine dayanarak OS veya Mobil ajanları kontrol etme desteği, anahtar bilgileri çıkarma yeteneği ve Json formatında çıktı verme yeteneği güçlüdür, bu sürüm 72B versiyonudur, bu serinin en güçlü versiyonudur."
  },
  "qwen2.5-vl-7b-instruct": {
    "description": "Talimat takibi, matematik, problem çözme, kodlama genelinde iyileştirme, her türlü nesneyi tanıma yeteneği artışı, çeşitli formatları doğrudan hassas bir şekilde görsel unsurları konumlandırma desteği, uzun video dosyalarını (en fazla 10 dakika) anlama ve saniye düzeyinde olay anlarını konumlandırma yeteneği, zaman sıralamasını ve hızını anlama, analiz ve konumlandırma yeteneğine dayanarak OS veya Mobil ajanları kontrol etme desteği, anahtar bilgileri çıkarma yeteneği ve Json formatında çıktı verme yeteneği güçlüdür, bu sürüm 72B versiyonudur, bu serinin en güçlü versiyonudur."
  },
  "qwen2.5-vl-instruct": {
    "description": "Qwen2.5-VL, Qwen model ailesinin en yeni görsel-dil modeli sürümüdür."
  },
  "qwen2.5:0.5b": {
    "description": "Qwen2.5, Alibaba'nın yeni nesil büyük ölçekli dil modelidir ve mükemmel performansıyla çeşitli uygulama ihtiyaçlarını desteklemektedir."
  },
  "qwen2.5:1.5b": {
    "description": "Qwen2.5, Alibaba'nın yeni nesil büyük ölçekli dil modelidir ve mükemmel performansıyla çeşitli uygulama ihtiyaçlarını desteklemektedir."
  },
  "qwen2.5:72b": {
    "description": "Qwen2.5, Alibaba'nın yeni nesil büyük ölçekli dil modelidir ve mükemmel performansıyla çeşitli uygulama ihtiyaçlarını desteklemektedir."
  },
  "qwen2:0.5b": {
    "description": "Qwen2, Alibaba'nın yeni nesil büyük ölçekli dil modelidir, mükemmel performans ile çeşitli uygulama ihtiyaçlarını destekler."
  },
  "qwen2:1.5b": {
    "description": "Qwen2, Alibaba'nın yeni nesil büyük ölçekli dil modelidir, mükemmel performans ile çeşitli uygulama ihtiyaçlarını destekler."
  },
  "qwen2:72b": {
    "description": "Qwen2, Alibaba'nın yeni nesil büyük ölçekli dil modelidir, mükemmel performans ile çeşitli uygulama ihtiyaçlarını destekler."
  },
  "qwen3": {
    "description": "Qwen3, Alibaba'nın yeni nesil büyük ölçekli dil modelidir ve çeşitli uygulama ihtiyaçlarını mükemmel bir performansla destekler."
  },
  "qwen3-0.6b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-1.7b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-14b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-235b-a22b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-30b-a3b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-32b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-4b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwen3-8b": {
    "description": "Qwen3, akıl yürütme, genel, Ajan ve çok dilli gibi birçok temel yetenekte endüstri lideri seviyesine ulaşan yeni nesil bir modeldir ve düşünme modu geçişini destekler."
  },
  "qwq": {
    "description": "QwQ, AI akıl yürütme yeteneklerini artırmaya odaklanan deneysel bir araştırma modelidir."
  },
  "qwq-32b": {
    "description": "Qwen2.5-32B modeli üzerine eğitilmiş QwQ çıkarım modeli, pekiştirmeli öğrenme ile modelin çıkarım yeteneğini önemli ölçüde artırmıştır. Modelin matematiksel kodları ve diğer temel göstergeleri (AIME 24/25, LiveCodeBench) ile bazı genel göstergeleri (IFEval, LiveBench vb.) DeepSeek-R1 tam sürüm seviyesine ulaşmıştır ve tüm göstergeler, yine Qwen2.5-32B tabanlı olan DeepSeek-R1-Distill-Qwen-32B'yi önemli ölçüde aşmaktadır."
  },
  "qwq-32b-preview": {
    "description": "QwQ modeli, Qwen ekibi tarafından geliştirilen deneysel bir araştırma modelidir ve AI akıl yürütme yeteneklerini artırmaya odaklanmaktadır."
  },
  "qwq-plus": {
    "description": "Qwen2.5 modeli temel alınarak eğitilmiş QwQ akıl yürütme modeli, pekiştirmeli öğrenme ile modelin akıl yürütme yeteneğini büyük ölçüde artırmıştır. Model, matematik ve kodlama gibi temel göstergelerde (AIME 24/25, LiveCodeBench) ve bazı genel göstergelerde (IFEval, LiveBench vb.) DeepSeek-R1 tam sürüm seviyesine ulaşmıştır."
  },
  "qwq_32b": {
    "description": "Qwen serisinin orta ölçekli çıkarım modelidir. Geleneksel talimat ayarlama modellerine kıyasla, düşünme ve çıkarım yeteneğine sahip QwQ, özellikle zorlu görevleri çözme konusunda, alt görevlerde performansı önemli ölçüde artırabilir."
  },
  "r1-1776": {
    "description": "R1-1776, DeepSeek R1 modelinin bir versiyonudur ve son eğitimle, sansürsüz, tarafsız gerçek bilgileri sunar."
  },
  "solar-mini": {
    "description": "Solar Mini, GPT-3.5'ten daha iyi performansa sahip kompakt bir LLM'dir, güçlü çok dilli yeteneklere sahiptir, İngilizce ve Korece'yi destekler ve etkili, kompakt çözümler sunar."
  },
  "solar-mini-ja": {
    "description": "Solar Mini (Ja), Solar Mini'nin yeteneklerini genişletir, Japonca'ya odaklanır ve İngilizce ile Korece kullanımında yüksek verimlilik ve mükemmel performans sağlar."
  },
  "solar-pro": {
    "description": "Solar Pro, Upstage tarafından sunulan yüksek akıllı LLM'dir, tek GPU talimat takibi yeteneğine odaklanır, IFEval puanı 80'in üzerindedir. Şu anda İngilizceyi desteklemekte olup, resmi versiyonu 2024 Kasım'da piyasaya sürülmesi planlanmaktadır ve dil desteği ile bağlam uzunluğunu genişletecektir."
  },
  "sonar": {
    "description": "Arama bağlamına dayalı hafif bir arama ürünüdür, Sonar Pro'dan daha hızlı ve daha ucuzdur."
  },
  "sonar-deep-research": {
    "description": "Deep Research, kapsamlı uzman düzeyinde araştırmalar yapar ve bunları erişilebilir, uygulanabilir raporlar haline getirir."
  },
  "sonar-pro": {
    "description": "Gelişmiş sorgular ve takip desteği sunan, arama bağlamını destekleyen bir üst düzey arama ürünüdür."
  },
  "sonar-reasoning": {
    "description": "DeepSeek akıl yürütme modeli tarafından desteklenen yeni API ürünü."
  },
  "sonar-reasoning-pro": {
    "description": "DeepSeek'in akıl yürütme modeli tarafından desteklenen yeni API ürünü."
  },
  "step-1-128k": {
    "description": "Performans ve maliyet arasında denge sağlar, genel senaryolar için uygundur."
  },
  "step-1-256k": {
    "description": "Ultra uzun bağlam işleme yeteneklerine sahiptir, özellikle uzun belgelerin analizine uygundur."
  },
  "step-1-32k": {
    "description": "Orta uzunlukta diyalogları destekler, çeşitli uygulama senaryoları için uygundur."
  },
  "step-1-8k": {
    "description": "Küçük model, hafif görevler için uygundur."
  },
  "step-1-flash": {
    "description": "Yüksek hızlı model, gerçek zamanlı diyaloglar için uygundur."
  },
  "step-1.5v-mini": {
    "description": "Bu model, güçlü bir video anlama yeteneğine sahiptir."
  },
  "step-1o-turbo-vision": {
    "description": "Bu model, güçlü bir görüntü anlama yeteneğine sahiptir, matematik ve kod alanında 1o'dan daha üstündür. Model, 1o'dan daha küçüktür ve çıktı hızı daha yüksektir."
  },
  "step-1o-vision-32k": {
    "description": "Bu model, güçlü bir görüntü anlama yeteneğine sahiptir. Step-1v serisi modellere kıyasla daha güçlü bir görsel performansa sahiptir."
  },
  "step-1v-32k": {
    "description": "Görsel girdi desteği sunar, çok modlu etkileşim deneyimini artırır."
  },
  "step-1v-8k": {
    "description": "Küçük görsel model, temel metin ve görsel görevler için uygundur."
  },
  "step-2-16k": {
    "description": "Büyük ölçekli bağlam etkileşimlerini destekler, karmaşık diyalog senaryoları için uygundur."
  },
  "step-2-16k-exp": {
    "description": "step-2 modelinin deneysel versiyonu, en son özellikleri içerir ve sürekli güncellenmektedir. Resmi üretim ortamında kullanılması önerilmez."
  },
  "step-2-mini": {
    "description": "Yeni nesil kendi geliştirdiğimiz MFA Attention mimarisine dayanan hızlı büyük model, çok düşük maliyetle step1 ile benzer sonuçlar elde ederken, daha yüksek bir throughput ve daha hızlı yanıt süresi sağlıyor. Genel görevleri işleyebilme yeteneğine sahip olup, kodlama yeteneklerinde uzmanlık gösteriyor."
  },
  "step-r1-v-mini": {
    "description": "Bu model, güçlü görüntü anlama yeteneğine sahip bir çıkarım büyük modelidir, görüntü ve metin bilgilerini işleyebilir, derin düşünme sonrası metin oluşturma çıktısı verebilir. Bu model, görsel çıkarım alanında öne çıkarken, birinci sınıf matematik, kod ve metin çıkarım yeteneklerine de sahiptir. Bağlam uzunluğu 100k'dır."
  },
  "taichu_llm": {
    "description": "Zidong Taichu dil büyük modeli, güçlü dil anlama yeteneği ile metin oluşturma, bilgi sorgulama, kod programlama, matematik hesaplama, mantıksal akıl yürütme, duygu analizi, metin özeti gibi yeteneklere sahiptir. Yenilikçi bir şekilde büyük veri ön eğitimi ile çok kaynaklı zengin bilgiyi birleştirir, algoritma teknolojisini sürekli olarak geliştirir ve büyük metin verilerinden kelime, yapı, dil bilgisi, anlam gibi yeni bilgileri sürekli olarak edinir, modelin performansını sürekli olarak evrimleştirir. Kullanıcılara daha kolay bilgi ve hizmetler sunar ve daha akıllı bir deneyim sağlar."
  },
  "taichu_o1": {
    "description": "taichu_o1, yeni nesil çıkarım büyük modelidir, çok modlu etkileşim ve pekiştirme öğrenimi ile insan benzeri düşünme zincirleri oluşturur, karmaşık karar verme senaryolarını destekler, yüksek hassasiyetli çıktılar sunarken model çıkarım düşünce yollarını sergiler, strateji analizi ve derin düşünme gibi senaryolar için uygundur."
  },
  "taichu_vl": {
    "description": "Görüntü anlama, bilgi transferi, mantıksal çıkarım gibi yetenekleri birleştirir ve görsel-işitsel soru-cevap alanında öne çıkar."
  },
  "text-embedding-3-large": {
    "description": "En güçlü vektörleştirme modeli, İngilizce ve diğer dillerdeki görevler için uygundur."
  },
  "text-embedding-3-small": {
    "description": "Verimli ve ekonomik yeni nesil Embedding modeli, bilgi arama, RAG uygulamaları gibi senaryolar için uygundur."
  },
  "thudm/glm-4-32b": {
    "description": "GLM-4-32B-0414, kod üretimi, fonksiyon çağrıları ve ajan tabanlı görevler için optimize edilmiş 32B iki dilli (Çince ve İngilizce) açık ağırlık dil modelidir. 15T yüksek kaliteli ve yeniden akıl yürütme verisi üzerinde önceden eğitilmiştir ve insan tercihleri uyumu, reddetme örnekleme ve pekiştirmeli öğrenme ile daha da geliştirilmiştir. Bu model, karmaşık akıl yürütme, nesne üretimi ve yapılandırılmış çıktı görevlerinde mükemmel performans sergilemekte ve birçok benchmark testinde GPT-4o ve DeepSeek-V3-0324 ile karşılaştırılabilir performans göstermektedir."
  },
  "thudm/glm-4-32b:free": {
    "description": "GLM-4-32B-0414, kod üretimi, fonksiyon çağrıları ve ajan tabanlı görevler için optimize edilmiş 32B iki dilli (Çince ve İngilizce) açık ağırlık dil modelidir. 15T yüksek kaliteli ve yeniden akıl yürütme verisi üzerinde önceden eğitilmiştir ve insan tercihleri uyumu, reddetme örnekleme ve pekiştirmeli öğrenme ile daha da geliştirilmiştir. Bu model, karmaşık akıl yürütme, nesne üretimi ve yapılandırılmış çıktı görevlerinde mükemmel performans sergilemekte ve birçok benchmark testinde GPT-4o ve DeepSeek-V3-0324 ile karşılaştırılabilir performans göstermektedir."
  },
  "thudm/glm-4-9b-chat": {
    "description": "Zhi Pu AI tarafından yayınlanan GLM-4 serisinin en son nesil ön eğitim modelinin açık kaynak versiyonudur."
  },
  "thudm/glm-4-9b:free": {
    "description": "GLM-4-9B-0414, THUDM tarafından geliştirilen GLM-4 serisinin 9 milyar parametreli dil modelidir. GLM-4-9B-0414, daha büyük 32B karşılık gelen model ile aynı güçlendirilmiş öğrenme ve hizalama stratejilerini kullanarak eğitilmiştir ve ölçeğine göre yüksek performans sergileyerek hala güçlü dil anlama ve üretim yeteneklerine ihtiyaç duyan kaynak sınırlı dağıtımlar için uygundur."
  },
  "thudm/glm-z1-32b": {
    "description": "GLM-Z1-32B-0414, GLM-4-32B'nin geliştirilmiş akıl yürütme varyantıdır ve derin matematik, mantık ve kod odaklı sorun çözme için tasarlanmıştır. Karmaşık çok adımlı görevlerin performansını artırmak için genişletilmiş pekiştirmeli öğrenme (görev spesifik ve genel çift tercih tabanlı) uygular. Temel GLM-4-32B modeline kıyasla, Z1 yapılandırılmış akıl yürütme ve formel alanlardaki yetenekleri önemli ölçüde artırmıştır.\n\nBu model, ipucu mühendisliği ile 'düşünme' adımlarını zorunlu kılmayı destekler ve uzun format çıktılar için geliştirilmiş tutarlılık sağlar. Ajan iş akışları için optimize edilmiştir ve uzun bağlamı (YaRN aracılığıyla), JSON araç çağrılarını ve kararlı akıl yürütme için ince ayar örnekleme yapılandırmalarını destekler. Derin düşünme, çok adımlı akıl yürütme veya formel çıkarım gerektiren kullanım durumları için idealdir."
  },
  "thudm/glm-z1-32b:free": {
    "description": "GLM-Z1-32B-0414, GLM-4-32B'nin geliştirilmiş akıl yürütme varyantıdır ve derin matematik, mantık ve kod odaklı sorun çözme için tasarlanmıştır. Karmaşık çok adımlı görevlerin performansını artırmak için genişletilmiş pekiştirmeli öğrenme (görev spesifik ve genel çift tercih tabanlı) uygular. Temel GLM-4-32B modeline kıyasla, Z1 yapılandırılmış akıl yürütme ve formel alanlardaki yetenekleri önemli ölçüde artırmıştır.\n\nBu model, ipucu mühendisliği ile 'düşünme' adımlarını zorunlu kılmayı destekler ve uzun format çıktılar için geliştirilmiş tutarlılık sağlar. Ajan iş akışları için optimize edilmiştir ve uzun bağlamı (YaRN aracılığıyla), JSON araç çağrılarını ve kararlı akıl yürütme için ince ayar örnekleme yapılandırmalarını destekler. Derin düşünme, çok adımlı akıl yürütme veya formel çıkarım gerektiren kullanım durumları için idealdir."
  },
  "thudm/glm-z1-9b:free": {
    "description": "GLM-Z1-9B-0414, THUDM tarafından geliştirilen GLM-4 serisinin 9B parametreli dil modelidir. Daha büyük GLM-Z1 modeline uygulanan teknikleri içermekte olup, güçlendirilmiş öğrenme, çift sıralama hizalaması ve matematik, kodlama ve mantık gibi akıl yürütme yoğun görevler için eğitim almıştır. Daha küçük olmasına rağmen, genel akıl yürütme görevlerinde güçlü performans sergilemekte ve ağırlık seviyesinde birçok açık kaynak modelinden daha üstündür."
  },
  "thudm/glm-z1-rumination-32b": {
    "description": "THUDM: GLM Z1 Rumination 32B, GLM-4-Z1 serisinin 32B parametreli derin akıl yürütme modelidir ve uzun süre düşünmeyi gerektiren karmaşık, açık uçlu görevler için optimize edilmiştir. glm-4-32b-0414 temel alınarak geliştirilmiş ve ek güçlendirilmiş öğrenme aşamaları ve çok aşamalı hizalama stratejileri eklenmiştir; genişletilmiş bilişsel işleme simüle etmek için 'düşünme' yeteneği getirilmiştir. Bu, yinelemeli akıl yürütme, çok adımlı analiz ve arama, alma ve alıntı bilincine sahip sentez gibi araç artırma iş akışlarını içerir.\n\nBu model, araştırma yazımı, karşılaştırmalı analiz ve karmaşık soru-cevap konularında mükemmel performans sergiler. Arama ve navigasyon ilkelere (`search`, `click`, `open`, `finish`) yönelik işlev çağrılarını destekler, böylece ajan tabanlı boru hatlarında kullanılabilir. Düşünme davranışı, kural tabanlı ödüller ve gecikmeli karar verme mekanizması ile çok turlu döngü kontrolü ile şekillendirilir ve OpenAI iç hizalama yığını gibi derin araştırma çerçevelerine göre değerlendirilir. Bu varyant, derinlik gerektiren senaryolar için uygundur."
  },
  "tngtech/deepseek-r1t-chimera:free": {
    "description": "DeepSeek-R1T-Chimera, DeepSeek-R1 ve DeepSeek-V3 (0324) birleştirilerek oluşturulmuştur ve R1'in akıl yürütme yetenekleri ile V3'ün token verimliliği iyileştirmelerini bir araya getirir. DeepSeek-MoE Transformer mimarisine dayanır ve genel metin üretim görevleri için optimize edilmiştir.\n\nBu model, iki kaynak modelin önceden eğitilmiş ağırlıklarını birleştirerek akıl yürütme, verimlilik ve talimat takibi görevlerinin performansını dengelemektedir. MIT lisansı altında yayımlanmış olup, araştırma ve ticari kullanım için tasarlanmıştır."
  },
  "togethercomputer/StripedHyena-Nous-7B": {
    "description": "StripedHyena Nous (7B), etkili stratejiler ve model mimarisi ile artırılmış hesaplama yetenekleri sunar."
  },
  "tts-1": {
    "description": "En son metinden sese model, gerçek zamanlı senaryolar için hız optimizasyonu yapılmıştır."
  },
  "tts-1-hd": {
    "description": "En son metinden sese model, kaliteyi optimize etmek için tasarlanmıştır."
  },
  "upstage/SOLAR-10.7B-Instruct-v1.0": {
    "description": "Upstage SOLAR Instruct v1 (11B), ince ayar gerektiren talimat görevleri için uygundur ve mükemmel dil işleme yetenekleri sunar."
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnet, endüstri standartlarını yükselterek, rakip modelleri ve Claude 3 Opus'u aşan performans sergilemekte; geniş değerlendirmelerde mükemmel sonuçlar verirken, orta seviye modellerimizin hız ve maliyetine sahiptir."
  },
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "description": "Claude 3.7 sonnet, Anthropic'in en hızlı bir sonraki nesil modelidir. Claude 3 Haiku ile karşılaştırıldığında, Claude 3.7 Sonnet, tüm becerilerde iyileşmeler göstermiştir ve birçok zeka standart testinde bir önceki neslin en büyük modeli olan Claude 3 Opus'u geride bırakmıştır."
  },
  "v0-1.0-md": {
    "description": "v0-1.0-md modeli, v0 API aracılığıyla hizmet veren eski bir modeldir"
  },
  "v0-1.5-lg": {
    "description": "v0-1.5-lg modeli, ileri düzey düşünme veya muhakeme görevleri için uygundur"
  },
  "v0-1.5-md": {
    "description": "v0-1.5-md modeli, günlük görevler ve kullanıcı arayüzü (UI) oluşturma için uygundur"
  },
  "whisper-1": {
    "description": "Genel ses tanıma modeli, çok dilli ses tanıma, ses çevirisi ve dil tanıma desteği sunar."
  },
  "wizardlm2": {
    "description": "WizardLM 2, Microsoft AI tarafından sunulan bir dil modelidir, karmaşık diyaloglar, çok dilli, akıl yürütme ve akıllı asistan alanlarında özellikle başarılıdır."
  },
  "wizardlm2:8x22b": {
    "description": "WizardLM 2, Microsoft AI tarafından sunulan bir dil modelidir, karmaşık diyaloglar, çok dilli, akıl yürütme ve akıllı asistan alanlarında özellikle başarılıdır."
  },
  "x1": {
    "description": "Spark X1 modeli daha da geliştirilecek; önceki matematik görevlerinde ulusal liderlik temelinde, akıl yürütme, metin üretimi, dil anlama gibi genel görevlerde OpenAI o1 ve DeepSeek R1 ile karşılaştırılabilir sonuçlar elde edilecektir."
  },
  "yi-1.5-34b-chat": {
    "description": "Yi-1.5, Yi'nin geliştirilmiş sürümüdür. Yüksek kaliteli 500B token'lı veri kümesi üzerinde devam eden ön eğitimi ve 3M çeşitlendirilmiş ince ayar örneği üzerinde ince ayarını içerir."
  },
  "yi-large": {
    "description": "Yeni nesil yüz milyar parametreli model, güçlü soru yanıtlama ve metin üretim yetenekleri sunar."
  },
  "yi-large-fc": {
    "description": "yi-large modelinin temelinde, araç çağrısı yeteneklerini destekleyip güçlendiren bir yapı sunar, çeşitli ajan veya iş akışı kurma gereksinimleri için uygundur."
  },
  "yi-large-preview": {
    "description": "Erken sürüm, yi-large (yeni sürüm) kullanılması önerilir."
  },
  "yi-large-rag": {
    "description": "yi-large modelinin güçlü bir hizmeti, arama ve üretim teknolojilerini birleştirerek doğru yanıtlar sunar, gerçek zamanlı olarak tüm ağdan bilgi arama hizmeti sağlar."
  },
  "yi-large-turbo": {
    "description": "Son derece yüksek maliyet performansı ve mükemmel performans. Performans ve akıl yürütme hızı, maliyet açısından yüksek hassasiyetli ayarlama yapılır."
  },
  "yi-lightning": {
    "description": "En yeni yüksek performanslı model, yüksek kaliteli çıktıları garanti ederken akıl yürütme hızını büyük ölçüde artırır."
  },
  "yi-lightning-lite": {
    "description": "Hafif versiyon, yi-lightning kullanımını önerir."
  },
  "yi-medium": {
    "description": "Orta boyutlu model, dengeli yetenekler ve yüksek maliyet performansı sunar. Talimat takibi yetenekleri derinlemesine optimize edilmiştir."
  },
  "yi-medium-200k": {
    "description": "200K ultra uzun bağlam penceresi, uzun metinlerin derinlemesine anlaşılması ve üretilmesi yetenekleri sunar."
  },
  "yi-spark": {
    "description": "Küçük ama etkili, hafif ve hızlı bir modeldir. Güçlendirilmiş matematiksel işlemler ve kod yazma yetenekleri sunar."
  },
  "yi-vision": {
    "description": "Karmaşık görsel görevler için model, yüksek performanslı resim anlama ve analiz yetenekleri sunar."
  },
  "yi-vision-v2": {
    "description": "Karmaşık görsel görevler için model, birden fazla resme dayalı yüksek performanslı anlama ve analiz yetenekleri sunar."
  }
}
